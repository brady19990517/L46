{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FL Personalization Layer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-iublvTxOBh",
        "outputId": "7cb5d769-a4c9-4fcb-a4eb-79ae645e5076"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flwr==0.17.0 in /usr/local/lib/python3.7/dist-packages (0.17.0)\n",
            "Requirement already satisfied: google<3.0.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (2.0.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (1.19.5)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.12.1 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.27.2 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (1.42.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google<3.0.0,>=2.0.3->flwr==0.17.0) (4.6.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<2.0.0,>=1.27.2->flwr==0.17.0) (1.15.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'drive/MyDrive/PartIII/L46'\n",
            "/content/drive/MyDrive/PartIII/L46\n"
          ]
        }
      ],
      "source": [
        "!pip install flwr==0.17.0\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/PartIII/L46"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ9rfsQUDs2U",
        "outputId": "31fc167d-a245-454a-d85d-12074ef2871b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar-10-batches-py\tcifar.py   clients.sh  __pycache__  server.sh\n",
            "cifar-10-python.tar.gz\tclient.py  logs        server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cifar.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "from flwr_experimental.baseline.dataset.dataset import create_partitioned_dataset\n",
        "\n",
        "class PartitionedDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.X[idx], int(self.Y[idx]))\n",
        "\n",
        "\n",
        "def load_data():\n",
        "\n",
        "    \"\"\"Load CIFAR-10 (training and test set).\"\"\"\n",
        "    transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "    trainset = CIFAR10(\".\", train=True, download=True, transform=transform)\n",
        "    testset = CIFAR10(\".\", train=False, download=True, transform=transform)\n",
        "    trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "    testloader = DataLoader(testset, batch_size=32)\n",
        "    num_examples = {\"trainset\" : len(trainset), \"testset\" : len(testset)}\n",
        "    return trainset, testset, num_examples\n",
        "\n",
        "def load_local_partitioned_data(client_id, iid_fraction: float, num_partitions: int):\n",
        "    \"\"\"Creates a dataset for each worker, which is a partition of a larger dataset.\"\"\"\n",
        "    \n",
        "    # Each worker loads the entire dataset, and then selects its partition\n",
        "    # determined by its `client_id` (happens internally below)\n",
        "    trainset, testset, num_examples = load_data()\n",
        "    \n",
        "    train_loader = DataLoader(trainset, batch_size=len(trainset))\n",
        "    test_loader = DataLoader(testset, batch_size=len(testset))\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = next(iter(train_loader)), next(iter(test_loader))\n",
        "    x_train, y_train = x_train.numpy(), y_train.numpy()\n",
        "    x_test, y_test = x_test.numpy(), y_test.numpy()\n",
        "\n",
        "    (train_partitions, test_partitions), _ = create_partitioned_dataset(\n",
        "        ((x_train, y_train), (x_test, y_test)), iid_fraction, num_partitions)\n",
        " \n",
        "    x_train, y_train = train_partitions[client_id]\n",
        "    torch_partition_trainset = PartitionedDataset(torch.Tensor(x_train), y_train)\n",
        "    x_test, y_test = test_partitions[client_id]\n",
        "    torch_partition_testset = PartitionedDataset(torch.Tensor(x_test), y_test )\n",
        "    return torch_partition_trainset, torch_partition_testset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg4L1tZGxa-E",
        "outputId": "7b56effd-f7ae-42ea-8661-d66fa885ab55"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cifar.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "IUtOiG2aDp92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350d5e84-656c-4b24-ffcc-9f82d8f435c6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile client.py\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import CIFAR10\n",
        "import grpc\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cifar\n",
        "import pickle\n",
        "import flwr as fl\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train(net, trainloader, epochs):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    log_progress = True\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss, total_correct, n_samples = 0.0, 0.0, 0\n",
        "        pbar = tqdm(trainloader, desc=f'TRAIN Epoch {epoch}') if log_progress else trainloader\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1) \n",
        "            n_samples += labels.size(0)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if log_progress:\n",
        "                pbar.set_postfix({\n",
        "                    \"train_loss\": total_loss/n_samples, \n",
        "                    \"train_acc\": total_correct/n_samples\n",
        "                })\n",
        "\n",
        "        results.append((total_loss/n_samples, total_correct/n_samples))   \n",
        "    return results\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    log_progress = True\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(testloader, desc=\"TEST\") if log_progress else testloader\n",
        "        for data in pbar:\n",
        "            images, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    return loss / total, accuracy\n",
        "\n",
        "class BaseNet(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(BaseNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        \n",
        "        # self.fc2 = nn.Linear(120, 84)\n",
        "        # self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        \n",
        "        # x = F.relu(self.fc2(x))\n",
        "        # x = self.fc3(x)\n",
        "        return x\n",
        "  \n",
        "# class BaseNet2(nn.Module):\n",
        "#     def __init__(self):\n",
        "\n",
        "\n",
        "class PersonalNet(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(PersonalNet, self).__init__()\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class FullModel(nn.Module):\n",
        "    def __init__(self, base, personal) -> None:\n",
        "        super(FullModel, self).__init__()\n",
        "        self.base = base\n",
        "        self.personal = personal\n",
        "    def forward(self, x):\n",
        "        x = self.base(x)\n",
        "        x = self.personal(x)\n",
        "        return x\n",
        "    def get_weights(self):  \n",
        "        return [val.cpu().numpy() for _, val in self.state_dict().items()]\n",
        "    def set_weights(self, weights):\n",
        "        state_dict = OrderedDict(\n",
        "            {k: torch.Tensor(v) for k, v in zip(self.state_dict().keys(), weights)}\n",
        "        )\n",
        "        self.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "# trainloader, testloader, num_examples = cifar.load_data()\n",
        "\n",
        "class CifarClient(fl.client.NumPyClient):\n",
        "\n",
        "    def __init__(self, cid, base_model, personal_net, fullnet, trainset, testset):\n",
        "        self.cid = cid\n",
        "        self.base_model = base_model\n",
        "        self.personal_net = personal_net\n",
        "        self.fullnet = fullnet\n",
        "        self.trainset = trainset\n",
        "        self.testset = testset\n",
        "\n",
        "    def get_parameters(self):\n",
        "        return [val.cpu().numpy() for _, val in self.base_model.state_dict().items()]\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        params_dict = zip(self.base_model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "        self.base_model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        trainloader = DataLoader(self.trainset, batch_size=32, shuffle=True)\n",
        "        self.set_parameters(parameters)\n",
        "        train_log = train(self.fullnet, trainloader, epochs=10)\n",
        "\n",
        "        train_loss, train_acc = train_log[-1]\n",
        "        print(f'Client {self.cid}: train_loss={train_loss:.4f}, train_accuracy={train_acc:.4f}')\n",
        "        round = int(config['epoch_global']) // int(config['epochs']) + 1\n",
        "        with open(f'logs/client_{self.cid}/training_round_{round}', 'wb') as fp:\n",
        "            pickle.dump(train_log, fp)\n",
        "\n",
        "        return self.get_parameters(), len(trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "\n",
        "        testloader = DataLoader(self.testset, batch_size=32, shuffle=False)\n",
        "\n",
        "        self.set_parameters(parameters)\n",
        "        test_loss, test_acc = test(self.fullnet, testloader)\n",
        "        print(f\"Client {self.cid}: test_loss={test_loss:.4f}, test_accuracy={test_acc:.4f}\")\n",
        "        round = int(config['epoch_global']) // int(config['epochs']) + 1\n",
        "        with open(f'logs/client_{self.cid}/testing_round_{round}', 'wb') as fp:\n",
        "            pickle.dump([test_loss, test_acc], fp)\n",
        "        return float(test_loss), len(testloader), {\"accuracy\": float(test_acc)}\n",
        "\n",
        "def load_model():\n",
        "    return FullModel(BaseNet(),PersonalNet())\n",
        "\n",
        "def start_client(client_id, basenet=None, fullnet=None, personalnet=None, num_partitions=10, iid_fraction=1.0, \n",
        "                 server_address=\"localhost:8080\", log_host=None):\n",
        "    # Configure logger\n",
        "    fl.common.logger.configure(f\"client_{client_id}\", host=log_host)\n",
        "\n",
        "    print(f\"Loading data for client {client_id}\")\n",
        "    trainset, testset = cifar.load_local_partitioned_data(\n",
        "        client_id=client_id, \n",
        "        iid_fraction=iid_fraction, \n",
        "        num_partitions=num_partitions)\n",
        "    \n",
        "\n",
        "    # Start client\n",
        "    print(f\"Starting client {client_id}\")\n",
        "    client = CifarClient(client_id, basenet, personalnet, fullnet, trainset, testset)\n",
        "    # f'{exp_name}_iid-fraction_{iid_fraction}')\n",
        "\n",
        "    print(f\"Connecting to {server_address}\")\n",
        "\n",
        "    try:\n",
        "        # There's no graceful shutdown when gRPC server terminates, so we try/except\n",
        "        fl.client.start_numpy_client(server_address, client)\n",
        "    except grpc._channel._MultiThreadedRendezvous:\n",
        "        print(f\"Client {client_id}: shutdown\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    num_clients = 10\n",
        "    num_partitions = 10\n",
        "    iid_fraction = 0.1\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"Flower client\")\n",
        "    parser.add_argument(\"--cid\", type=int, required=True, help=\"Client CID (no default)\")\n",
        "\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    basenet = BaseNet().to(DEVICE)\n",
        "    personalnet = PersonalNet().to(DEVICE)\n",
        "    fullnet = FullModel(basenet, personalnet)\n",
        "    \n",
        "    # fl.client.start_numpy_client(\"localhost:8080\", client=CifarClient(100,basenet,personalnet,fullnet,0,0))\n",
        "    start_client(client_id=args.cid, basenet=basenet, fullnet=fullnet, personalnet=personalnet, num_partitions=num_partitions, iid_fraction=iid_fraction, server_address=\"localhost:24338\")\n",
        "    print(f\"Started {num_clients} clients\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2SZKAfNxkdM",
        "outputId": "15a6093c-0bf5-4ef4-ac1a-6b0856c3b68f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting client.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile server.py\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.server.grpc_server.grpc_server import start_insecure_grpc_server\n",
        "import cifar\n",
        "import client\n",
        "\n",
        "DEFAULT_SERVER_ADDRESS = \"localhost:24338\"\n",
        "\n",
        "fl.common.logger.configure(\"server\", host=None)\n",
        "\n",
        "rounds = 3\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "_, testset, _ = cifar.load_data()\n",
        "\n",
        "def get_eval_fn(testset):\n",
        "    \"\"\"Returns an evaluation function for centralized (server-side) evaluation.\"\"\"\n",
        "    def evaluate(weights: fl.common.Weights):\n",
        "        \"\"\"Use the entire CIFAR-10 test set for evaluation.\"\"\"\n",
        "        model = client.load_model()\n",
        "        model.set_weights(weights)\n",
        "        model.to(DEVICE)\n",
        "        testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
        "        loss, accuracy = client.test(net=model, testloader=testloader, device=DEVICE, log_progress=True)\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "    return evaluate\n",
        "\n",
        "def generate_config(epochs, batch_size):\n",
        "    def fit_config(round: int):\n",
        "        print(f\"Configuring round {round}...\")\n",
        "        return {\n",
        "            \"epoch_global\": str((round - 1) * epochs),\n",
        "            \"epochs\": str(epochs),\n",
        "            \"batch_size\": str(batch_size),\n",
        "        }\n",
        "    return fit_config \n",
        "\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    min_fit_clients=10,\n",
        "    min_eval_clients=10,\n",
        "    min_available_clients=10,\n",
        "    # eval_fn=get_eval_fn(testset),\n",
        "    on_fit_config_fn=generate_config(epochs, batch_size),\n",
        "    on_evaluate_config_fn=generate_config(epochs, batch_size),\n",
        ")\n",
        "\n",
        "client_manager = fl.server.SimpleClientManager()\n",
        "server = fl.server.Server(client_manager=client_manager, strategy=strategy)\n",
        "\n",
        "# fl.server.start_server(config={\"num_rounds\": 3}, strategy=strategy)\n",
        "\n",
        "print(f\"Starting gRPC server on {DEFAULT_SERVER_ADDRESS}...\")\n",
        "grpc_server = start_insecure_grpc_server(\n",
        "        client_manager=server.client_manager(),\n",
        "        server_address=DEFAULT_SERVER_ADDRESS,\n",
        "        max_message_length=fl.common.GRPC_MAX_MESSAGE_LENGTH,\n",
        "    )\n",
        "\n",
        "print(\"Fitting the model...\")\n",
        "hist = server.fit(num_rounds=3)\n",
        "# test_loss, test_metrics = server.strategy.evaluate(parameters=server.parameters)\n",
        "# print(f\"Server-side test results after training: test_loss={test_loss:.4f}, \"\n",
        "#         f\"test_accuracy={test_metrics['accuracy']:.4f}\")\n",
        "\n",
        "grpc_server.stop(None)    \n",
        "# fl.server.start_server(config={\"num_rounds\": 3})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le_BnZklxlQH",
        "outputId": "398a8265-eb30-4bce-d5e2-727a54ec38c2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile server.sh\n",
        "\n",
        "PYTHONUNBUFFERED=1 python3 server.py --rounds=3 --epochs=10 --sample_fraction=1 --min_sample_size=5  --min_num_clients=5  --server_address=\"localhost:24338\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAhC09Xexu_R",
        "outputId": "af9d23e8-bdff-4e5c-e645-282fd5411ac9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting server.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile clients.sh\n",
        "\n",
        "export PYTHONUNBUFFERED=1\n",
        "NUM_CLIENTS=10 # TODO: change the number of clients here\n",
        "\n",
        "\n",
        "echo \"Starting $NUM_CLIENTS clients.\"\n",
        "for ((i = 0; i < $NUM_CLIENTS; i++))\n",
        "do\n",
        "    echo \"Starting client(cid=$i) with partition $i out of $NUM_CLIENTS clients.\"\n",
        "    # Staggered loading of clients: clients are loaded 8s apart.\n",
        "    # At the start, each client loads the entire CIFAR-10 dataset before selecting\n",
        "    # their own partition. For a large number of clients this causes a memory usage\n",
        "    # spike that can cause client processes to get terminated. \n",
        "    # Staggered loading prevents this.\n",
        "    sleep 20s  \n",
        "    python3 client.py \\\n",
        "      --cid=$i \\\n",
        "      --num_partitions=${NUM_CLIENTS} &\n",
        "done\n",
        "echo \"Started $NUM_CLIENTS clients.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF5P2YQRVLGW",
        "outputId": "8c4b7282-834c-40de-a69f-75caf0790881"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting clients.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute this after running any of the %%writefile cells above\n",
        "!chmod +x clients.sh server.sh"
      ],
      "metadata": {
        "id": "fSwfEsOSVPbg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%killbgscripts\n",
        "!((./server.sh & sleep 8s); ./clients.sh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOLBBnJxVWzv",
        "outputId": "210ade85-77c4-44e8-9104-8d5ff0c7dfbd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All background processes were killed.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting 10 clients.\n",
            "Starting client(cid=0) with partition 0 out of 10 clients.\n",
            "Starting gRPC server on localhost:24338...\n",
            "Fitting the model...\n",
            "INFO flower 2022-01-03 15:16:28,112 | server.py:118 | Initializing global parameters\n",
            "INFO flower 2022-01-03 15:16:28,112 | server.py:304 | Requesting initial parameters from one random client\n",
            "Starting client(cid=1) with partition 1 out of 10 clients.\n",
            "Loading data for client 0\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=2) with partition 2 out of 10 clients.\n",
            "Loading data for client 1\n",
            "Files already downloaded and verified\n",
            "Starting client 0\n",
            "Connecting to localhost:24338\n",
            "DEBUG flower 2022-01-03 15:17:14,513 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:17:14,514 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2022-01-03 15:17:14,515 | app.py:61 | Opened (insecure) gRPC connection\n",
            "INFO flower 2022-01-03 15:17:14,522 | server.py:307 | Received initial parameters from one random client\n",
            "INFO flower 2022-01-03 15:17:14,522 | server.py:120 | Evaluating initial parameters\n",
            "INFO flower 2022-01-03 15:17:14,522 | server.py:133 | FL starting\n",
            "Configuring round 1...\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=3) with partition 3 out of 10 clients.\n",
            "Loading data for client 2\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting client 1\n",
            "Connecting to localhost:24338\n",
            "DEBUG flower 2022-01-03 15:17:46,959 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:17:46,960 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2022-01-03 15:17:46,965 | app.py:61 | Opened (insecure) gRPC connection\n",
            "Starting client(cid=4) with partition 4 out of 10 clients.\n",
            "Loading data for client 3\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=5) with partition 5 out of 10 clients.\n",
            "Starting client 2\n",
            "Connecting to localhost:24338\n",
            "DEBUG flower 2022-01-03 15:18:09,924 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:18:09,927 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2022-01-03 15:18:09,928 | app.py:61 | Opened (insecure) gRPC connection\n",
            "Loading data for client 4\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting client 3\n",
            "Connecting to localhost:24338\n",
            "DEBUG flower 2022-01-03 15:18:26,840 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:18:26,842 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2022-01-03 15:18:26,846 | app.py:61 | Opened (insecure) gRPC connection\n",
            "Starting client(cid=6) with partition 6 out of 10 clients.\n",
            "Loading data for client 5\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting client 4\n",
            "Connecting to localhost:24338\n",
            "DEBUG flower 2022-01-03 15:18:44,035 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:18:44,035 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2022-01-03 15:18:44,036 | app.py:61 | Opened (insecure) gRPC connection\n",
            "Starting client(cid=7) with partition 7 out of 10 clients.\n",
            "Loading data for client 6\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting client 5\n",
            "Connecting to localhost:24338\n",
            "INFO flower 2022-01-03 15:19:01,105 | app.py:61 | Opened (insecure) gRPC connection\n",
            "DEBUG flower 2022-01-03 15:19:01,109 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:19:01,109 | connection.py:36 | ChannelConnectivity.READY\n",
            "Starting client(cid=8) with partition 8 out of 10 clients.\n",
            "Loading data for client 7\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting client 6\n",
            "Connecting to localhost:24338\n",
            "DEBUG flower 2022-01-03 15:19:19,689 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:19:19,690 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2022-01-03 15:19:19,691 | app.py:61 | Opened (insecure) gRPC connection\n",
            "Starting client(cid=9) with partition 9 out of 10 clients.\n",
            "Loading data for client 8\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting client 7\n",
            "Connecting to localhost:24338\n",
            "DEBUG flower 2022-01-03 15:19:38,522 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:19:38,523 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2022-01-03 15:19:38,524 | app.py:61 | Opened (insecure) gRPC connection\n",
            "Started 10 clients.\n",
            "Loading data for client 9\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting client 8\n",
            "Connecting to localhost:24338\n",
            "INFO flower 2022-01-03 15:19:56,795 | app.py:61 | Opened (insecure) gRPC connection\n",
            "DEBUG flower 2022-01-03 15:19:56,800 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:19:56,801 | connection.py:36 | ChannelConnectivity.READY\n",
            "Starting client 9\n",
            "Connecting to localhost:24338\n",
            "DEBUG flower 2022-01-03 15:20:13,265 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:20:13,266 | connection.py:36 | ChannelConnectivity.CONNECTING\n",
            "INFO flower 2022-01-03 15:20:13,266 | app.py:61 | Opened (insecure) gRPC connection\n",
            "DEBUG flower 2022-01-03 15:20:13,267 | connection.py:36 | ChannelConnectivity.READY\n",
            "DEBUG flower 2022-01-03 15:20:13,268 | server.py:255 | fit_round: strategy sampled 10 clients (out of 10)\n",
            "TRAIN Epoch 0:  94% 147/157 [00:14<00:00, 11.43it/s, train_loss=0.0696, train_acc=0.192]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:14<00:00, 10.97it/s, train_loss=0.0704, train_acc=0.198]\n",
            "TRAIN Epoch 1:   0% 0/157 [00:00<?, ?it/s]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:14<00:00, 10.82it/s, train_loss=0.0704, train_acc=0.154]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:14<00:00, 10.77it/s, train_loss=0.0699, train_acc=0.162]\n",
            "TRAIN Epoch 0:  97% 153/157 [00:14<00:00, 11.67it/s, train_loss=0.0695, train_acc=0.194]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:14<00:00, 10.59it/s, train_loss=0.0695, train_acc=0.19]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:14<00:00, 10.58it/s, train_loss=0.0698, train_acc=0.194]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:14<00:00, 10.56it/s, train_loss=0.0691, train_acc=0.193]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:15<00:00, 10.30it/s, train_loss=0.0696, train_acc=0.168]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:12<00:00, 12.25it/s, train_loss=0.062, train_acc=0.237]\n",
            "TRAIN Epoch 1:  93% 146/157 [00:12<00:00, 12.00it/s, train_loss=0.0631, train_acc=0.202]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:12<00:00, 12.14it/s, train_loss=0.0615, train_acc=0.196]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:13<00:00, 11.74it/s, train_loss=0.0585, train_acc=0.235]\n",
            "TRAIN Epoch 2:   4% 6/157 [00:00<00:12, 12.28it/s, train_loss=0.052, train_acc=0.365]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:12<00:00, 12.15it/s, train_loss=0.0576, train_acc=0.234]\n",
            "TRAIN Epoch 2:   0% 0/157 [00:00<?, ?it/s, train_loss=0.0552, train_acc=0.156]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:13<00:00, 12.01it/s, train_loss=0.063, train_acc=0.202]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:13<00:00, 11.74it/s, train_loss=0.0596, train_acc=0.221]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:12<00:00, 12.20it/s, train_loss=0.0597, train_acc=0.223]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:12<00:00, 12.13it/s, train_loss=0.0563, train_acc=0.275]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:13<00:00, 12.01it/s, train_loss=0.0512, train_acc=0.384]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:12<00:00, 12.16it/s, train_loss=0.055, train_acc=0.302]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:13<00:00, 12.01it/s, train_loss=0.0558, train_acc=0.276]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:12<00:00, 12.10it/s, train_loss=0.0561, train_acc=0.294]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:12<00:00, 12.16it/s, train_loss=0.0531, train_acc=0.348]\n",
            "TRAIN Epoch 2:  98% 154/157 [00:12<00:00, 11.73it/s, train_loss=0.0558, train_acc=0.303]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:12<00:00, 12.27it/s, train_loss=0.056, train_acc=0.303]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:13<00:00, 12.03it/s, train_loss=0.0566, train_acc=0.239]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:13<00:00, 12.04it/s, train_loss=0.0537, train_acc=0.337]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:12<00:00, 12.57it/s, train_loss=0.0514, train_acc=0.383]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 11.83it/s, train_loss=0.0539, train_acc=0.345]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:12<00:00, 12.31it/s, train_loss=0.0537, train_acc=0.336]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 11.90it/s, train_loss=0.049, train_acc=0.436]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:12<00:00, 12.24it/s, train_loss=0.0545, train_acc=0.34]\n",
            "TRAIN Epoch 4:   4% 6/157 [00:00<00:13, 11.33it/s, train_loss=0.0497, train_acc=0.41] \n",
            "TRAIN Epoch 3: 100% 157/157 [00:12<00:00, 12.25it/s, train_loss=0.0542, train_acc=0.343]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:12<00:00, 12.13it/s, train_loss=0.0508, train_acc=0.392]\n",
            "TRAIN Epoch 4:   5% 8/157 [00:00<00:13, 11.12it/s, train_loss=0.0491, train_acc=0.388]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:12<00:00, 12.10it/s, train_loss=0.0558, train_acc=0.283]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.60it/s, train_loss=0.0489, train_acc=0.414]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.60it/s, train_loss=0.0517, train_acc=0.383]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.65it/s, train_loss=0.0527, train_acc=0.361]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.74it/s, train_loss=0.0491, train_acc=0.431]\n",
            "TRAIN Epoch 4:  99% 156/157 [00:13<00:00, 11.81it/s, train_loss=0.0519, train_acc=0.369]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.53it/s, train_loss=0.0514, train_acc=0.378]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.70it/s, train_loss=0.0519, train_acc=0.369]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.52it/s, train_loss=0.0478, train_acc=0.435]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.67it/s, train_loss=0.0495, train_acc=0.425]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.60it/s, train_loss=0.0541, train_acc=0.333]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.79it/s, train_loss=0.0468, train_acc=0.449]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.82it/s, train_loss=0.0502, train_acc=0.399]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 12.02it/s, train_loss=0.0445, train_acc=0.482]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.97it/s, train_loss=0.0473, train_acc=0.453]\n",
            "TRAIN Epoch 5:  97% 152/157 [00:13<00:00, 12.26it/s, train_loss=0.0476, train_acc=0.449]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.72it/s, train_loss=0.0511, train_acc=0.386]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.89it/s, train_loss=0.0454, train_acc=0.467]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.70it/s, train_loss=0.0495, train_acc=0.41]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.83it/s, train_loss=0.0477, train_acc=0.451]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.70it/s, train_loss=0.0519, train_acc=0.369]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 12.00it/s, train_loss=0.0444, train_acc=0.478]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 12.02it/s, train_loss=0.0451, train_acc=0.479]\n",
            "TRAIN Epoch 6:  96% 150/157 [00:13<00:00, 12.13it/s, train_loss=0.0486, train_acc=0.424]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 12.03it/s, train_loss=0.0487, train_acc=0.417]\n",
            "TRAIN Epoch 6:  97% 152/157 [00:13<00:00, 11.49it/s, train_loss=0.0435, train_acc=0.488]\n",
            "TRAIN Epoch 6:  98% 154/157 [00:13<00:00, 11.95it/s, train_loss=0.0435, train_acc=0.49] \n",
            "TRAIN Epoch 7:   5% 8/157 [00:00<00:11, 12.70it/s, train_loss=0.0421, train_acc=0.484]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.78it/s, train_loss=0.0458, train_acc=0.47]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.66it/s, train_loss=0.048, train_acc=0.429]\n",
            "TRAIN Epoch 7:   8% 12/157 [00:01<00:12, 11.76it/s, train_loss=0.0427, train_acc=0.484]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.60it/s, train_loss=0.0424, train_acc=0.513]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.88it/s, train_loss=0.0409, train_acc=0.54]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.96it/s, train_loss=0.0473, train_acc=0.438]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.98it/s, train_loss=0.048, train_acc=0.432]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.54it/s, train_loss=0.0435, train_acc=0.486]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.84it/s, train_loss=0.0424, train_acc=0.501]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.88it/s, train_loss=0.0469, train_acc=0.452]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.64it/s, train_loss=0.0472, train_acc=0.446]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.74it/s, train_loss=0.0439, train_acc=0.497]\n",
            "TRAIN Epoch 8:   6% 9/157 [00:00<00:13, 11.34it/s, train_loss=0.0485, train_acc=0.423]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.89it/s, train_loss=0.0464, train_acc=0.447]\n",
            "TRAIN Epoch 8:  94% 147/157 [00:12<00:00, 11.52it/s, train_loss=0.046, train_acc=0.457]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.91it/s, train_loss=0.0425, train_acc=0.508]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.49it/s, train_loss=0.0412, train_acc=0.523]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.70it/s, train_loss=0.0467, train_acc=0.45]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.81it/s, train_loss=0.0424, train_acc=0.517]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.71it/s, train_loss=0.0461, train_acc=0.459]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.65it/s, train_loss=0.0409, train_acc=0.526]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.60it/s, train_loss=0.046, train_acc=0.464]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.53it/s, train_loss=0.0475, train_acc=0.446]\n",
            "TRAIN Epoch 9: 100% 157/157 [00:13<00:00, 11.87it/s, train_loss=0.045, train_acc=0.471]\n",
            "Client 3: train_loss=0.0450, train_accuracy=0.4708\n",
            "TRAIN Epoch 9: 100% 157/157 [00:13<00:00, 11.95it/s, train_loss=0.0411, train_acc=0.523]\n",
            "Client 6: train_loss=0.0411, train_accuracy=0.5234\n",
            "TRAIN Epoch 9: 100% 157/157 [00:13<00:00, 11.93it/s, train_loss=0.0453, train_acc=0.478]\n",
            "Client 8: train_loss=0.0397, train_accuracy=0.5492\n",
            "Client 0: train_loss=0.0453, train_accuracy=0.4784\n",
            "\n",
            "TRAIN Epoch 9: 100% 157/157 [00:13<00:00, 11.73it/s, train_loss=0.0383, train_acc=0.57]\n",
            "Client 9: train_loss=0.0383, train_accuracy=0.5698\n",
            "TRAIN Epoch 9: 100% 157/157 [00:12<00:00, 12.21it/s, train_loss=0.0453, train_acc=0.469]\n",
            "Client 1: train_loss=0.0453, train_accuracy=0.4688\n",
            "TRAIN Epoch 9:  92% 144/157 [00:11<00:00, 16.93it/s, train_loss=0.046, train_acc=0.461] \n",
            "Client 5: train_loss=0.0408, train_accuracy=0.5366\n",
            "TRAIN Epoch 9: 100% 157/157 [00:12<00:00, 12.11it/s, train_loss=0.0391, train_acc=0.556]\n",
            "Client 7: train_loss=0.0391, train_accuracy=0.5560\n",
            "TRAIN Epoch 9: 100% 157/157 [00:12<00:00, 12.23it/s, train_loss=0.0447, train_acc=0.474]\n",
            "Client 4: train_loss=0.0447, train_accuracy=0.4744\n",
            "TRAIN Epoch 9: 100% 157/157 [00:11<00:00, 13.17it/s, train_loss=0.0463, train_acc=0.463]\n",
            "Client 2: train_loss=0.0463, train_accuracy=0.4628\n",
            "DEBUG flower 2022-01-03 15:22:27,104 | server.py:264 | fit_round received 10 results and 0 failures\n",
            "Configuring round 1...\n",
            "DEBUG flower 2022-01-03 15:22:27,111 | server.py:205 | evaluate_round: strategy sampled 10 clients (out of 10)\n",
            "TEST: 100% 32/32 [00:01<00:00, 30.07it/s]\n",
            "Client 0: test_loss=0.0467, test_accuracy=0.4590\n",
            "TEST: 100% 32/32 [00:01<00:00, 29.44it/s]\n",
            "Client 2: test_loss=0.0487, test_accuracy=0.4300\n",
            "TEST: 100% 32/32 [00:01<00:00, 25.12it/s]\n",
            "\n",
            "Client 8: test_loss=0.0420, test_accuracy=0.5470\n",
            "Client 6: test_loss=0.0444, test_accuracy=0.4750\n",
            "TEST: 100% 32/32 [00:01<00:00, 25.89it/s]\n",
            "\n",
            "Client 4: test_loss=0.0464, test_accuracy=0.4690\n",
            "Client 7: test_loss=0.0402, test_accuracy=0.5390\n",
            "TEST: 100% 32/32 [00:01<00:00, 25.11it/s]\n",
            "Client 9: test_loss=0.0477, test_accuracy=0.4620\n",
            "TEST: 100% 32/32 [00:01<00:00, 24.71it/s]\n",
            "Client 3: test_loss=0.0461, test_accuracy=0.4830\n",
            "TEST: 100% 32/32 [00:01<00:00, 24.29it/s]\n",
            "Client 5: test_loss=0.0447, test_accuracy=0.4940\n",
            "TEST: 100% 32/32 [00:01<00:00, 24.72it/s]\n",
            "Client 1: test_loss=0.0457, test_accuracy=0.4740\n",
            "DEBUG flower 2022-01-03 15:22:28,506 | server.py:214 | evaluate_round received 10 results and 0 failures\n",
            "Configuring round 2...\n",
            "DEBUG flower 2022-01-03 15:22:28,507 | server.py:255 | fit_round: strategy sampled 10 clients (out of 10)\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.62it/s, train_loss=0.0406, train_acc=0.533]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.60it/s, train_loss=0.0446, train_acc=0.485]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.52it/s, train_loss=0.0438, train_acc=0.486]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.53it/s, train_loss=0.0454, train_acc=0.473]\n",
            "TRAIN Epoch 0:  99% 156/157 [00:13<00:00, 13.12it/s, train_loss=0.0442, train_acc=0.491]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.36it/s, train_loss=0.0443, train_acc=0.491]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.43it/s, train_loss=0.039, train_acc=0.558]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.32it/s, train_loss=0.0449, train_acc=0.472]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.30it/s, train_loss=0.0386, train_acc=0.564]\n",
            "TRAIN Epoch 1:   0% 0/157 [00:00<?, ?it/s, train_loss=0.045, train_acc=0.5]   \n",
            "TRAIN Epoch 1: 100% 157/157 [00:12<00:00, 12.23it/s, train_loss=0.0419, train_acc=0.514]\n",
            "TRAIN Epoch 1:  99% 156/157 [00:13<00:00, 11.47it/s, train_loss=0.0432, train_acc=0.501]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:13<00:00, 11.89it/s, train_loss=0.0433, train_acc=0.501]\n",
            "TRAIN Epoch 2:   4% 6/157 [00:00<00:12, 12.32it/s, train_loss=0.0446, train_acc=0.547]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:13<00:00, 11.88it/s, train_loss=0.0432, train_acc=0.504]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:13<00:00, 11.75it/s, train_loss=0.0438, train_acc=0.494]\n",
            "TRAIN Epoch 2:   6% 10/157 [00:00<00:12, 11.98it/s, train_loss=0.0423, train_acc=0.534]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:13<00:00, 11.63it/s, train_loss=0.0372, train_acc=0.578]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:13<00:00, 11.70it/s, train_loss=0.0374, train_acc=0.577]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:13<00:00, 11.47it/s, train_loss=0.0428, train_acc=0.489]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:12<00:00, 12.09it/s, train_loss=0.037, train_acc=0.579]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:12<00:00, 12.36it/s, train_loss=0.0418, train_acc=0.518]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:12<00:00, 12.09it/s, train_loss=0.0419, train_acc=0.514]\n",
            "TRAIN Epoch 2:  99% 156/157 [00:12<00:00, 11.34it/s, train_loss=0.038, train_acc=0.568]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:12<00:00, 12.15it/s, train_loss=0.0382, train_acc=0.568]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:12<00:00, 12.21it/s, train_loss=0.0365, train_acc=0.591]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:13<00:00, 11.86it/s, train_loss=0.0422, train_acc=0.517]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:13<00:00, 11.93it/s, train_loss=0.0359, train_acc=0.6]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:13<00:00, 11.82it/s, train_loss=0.036, train_acc=0.598]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:13<00:00, 11.69it/s, train_loss=0.0413, train_acc=0.515]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 11.79it/s, train_loss=0.0407, train_acc=0.524]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 11.73it/s, train_loss=0.0396, train_acc=0.541]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 11.65it/s, train_loss=0.0367, train_acc=0.598]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 11.42it/s, train_loss=0.0405, train_acc=0.541]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 11.39it/s, train_loss=0.0359, train_acc=0.59]\n",
            "\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 11.75it/s, train_loss=0.0353, train_acc=0.608]\n",
            "TRAIN Epoch 4:   5% 8/157 [00:00<00:11, 12.98it/s, train_loss=0.0403, train_acc=0.517]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 11.27it/s, train_loss=0.0351, train_acc=0.608]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 11.50it/s, train_loss=0.0401, train_acc=0.528]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:12<00:00, 12.08it/s, train_loss=0.0397, train_acc=0.538]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:12<00:00, 12.15it/s, train_loss=0.0397, train_acc=0.541]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.80it/s, train_loss=0.0391, train_acc=0.541]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.80it/s, train_loss=0.0361, train_acc=0.609]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.97it/s, train_loss=0.0342, train_acc=0.622]\n",
            "TRAIN Epoch 5:   1% 2/157 [00:00<00:12, 12.58it/s, train_loss=0.0318, train_acc=0.734]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.71it/s, train_loss=0.0406, train_acc=0.534]\n",
            "TRAIN Epoch 5:   6% 10/157 [00:00<00:12, 11.87it/s, train_loss=0.0336, train_acc=0.6]\n",
            "TRAIN Epoch 5:   5% 8/157 [00:00<00:12, 11.93it/s, train_loss=0.032, train_acc=0.625]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.68it/s, train_loss=0.0397, train_acc=0.536]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 12.05it/s, train_loss=0.039, train_acc=0.545]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 12.00it/s, train_loss=0.0388, train_acc=0.553]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 12.07it/s, train_loss=0.0384, train_acc=0.561]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:12<00:00, 12.08it/s, train_loss=0.0351, train_acc=0.622]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 12.01it/s, train_loss=0.0335, train_acc=0.631]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.97it/s, train_loss=0.0394, train_acc=0.544]\n",
            "TRAIN Epoch 5:  94% 148/157 [00:12<00:00, 12.50it/s, train_loss=0.033, train_acc=0.636]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.93it/s, train_loss=0.0332, train_acc=0.637]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.60it/s, train_loss=0.0333, train_acc=0.63]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.79it/s, train_loss=0.0387, train_acc=0.547]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.98it/s, train_loss=0.0386, train_acc=0.55]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:12<00:00, 12.08it/s, train_loss=0.0376, train_acc=0.572]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.98it/s, train_loss=0.0381, train_acc=0.566]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.81it/s, train_loss=0.0329, train_acc=0.644]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.64it/s, train_loss=0.0345, train_acc=0.628]\n",
            "TRAIN Epoch 7:   8% 12/157 [00:01<00:11, 12.67it/s, train_loss=0.0367, train_acc=0.599]\n",
            "TRAIN Epoch 7:   1% 2/157 [00:00<00:11, 13.35it/s, train_loss=0.0369, train_acc=0.594]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.82it/s, train_loss=0.0325, train_acc=0.642]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.84it/s, train_loss=0.0324, train_acc=0.638]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:12<00:00, 12.08it/s, train_loss=0.0381, train_acc=0.553]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:12<00:00, 12.25it/s, train_loss=0.0374, train_acc=0.574]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.43it/s, train_loss=0.0379, train_acc=0.556]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:12<00:00, 12.20it/s, train_loss=0.0319, train_acc=0.652]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:12<00:00, 12.24it/s, train_loss=0.0333, train_acc=0.642]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.42it/s, train_loss=0.0371, train_acc=0.577]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.89it/s, train_loss=0.0321, train_acc=0.646]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.37it/s, train_loss=0.0386, train_acc=0.553]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.64it/s, train_loss=0.032, train_acc=0.653]\n",
            "TRAIN Epoch 8:  11% 18/157 [00:01<00:12, 11.38it/s, train_loss=0.0326, train_acc=0.655]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.75it/s, train_loss=0.0378, train_acc=0.553]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.55it/s, train_loss=0.037, train_acc=0.578]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.41it/s, train_loss=0.0374, train_acc=0.562]\n",
            "TRAIN Epoch 8:  99% 155/157 [00:13<00:00,  8.18it/s, train_loss=0.036, train_acc=0.591]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.58it/s, train_loss=0.0362, train_acc=0.591]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:14<00:00, 10.86it/s, train_loss=0.0313, train_acc=0.66]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:14<00:00, 11.20it/s, train_loss=0.0316, train_acc=0.656]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.25it/s, train_loss=0.0372, train_acc=0.57]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:14<00:00, 11.05it/s, train_loss=0.0308, train_acc=0.654]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:14<00:00, 10.67it/s, train_loss=0.0375, train_acc=0.573]\n",
            "TRAIN Epoch 9:   8% 13/157 [00:01<00:14,  9.81it/s, train_loss=0.031, train_acc=0.66]  \n",
            "TRAIN Epoch 9: 100% 157/157 [00:14<00:00, 11.03it/s, train_loss=0.0363, train_acc=0.583]\n",
            "Client 0: train_loss=0.0363, train_accuracy=0.5826\n",
            "TRAIN Epoch 9:  87% 137/157 [00:11<00:01, 12.13it/s, train_loss=0.0312, train_acc=0.652]\n",
            "Client 5: train_loss=0.0315, train_accuracy=0.6660\n",
            "TRAIN Epoch 9: 100% 157/157 [00:14<00:00, 11.16it/s, train_loss=0.0356, train_acc=0.592]\n",
            "Client 4: train_loss=0.0356, train_accuracy=0.5916\n",
            "TRAIN Epoch 9:  97% 152/157 [00:13<00:00, 14.42it/s, train_loss=0.0307, train_acc=0.661]\n",
            "Client 1: train_loss=0.0367, train_accuracy=0.5778\n",
            "TRAIN Epoch 9: 100% 157/157 [00:13<00:00, 11.47it/s, train_loss=0.0308, train_acc=0.673]\n",
            "Client 9: train_loss=0.0308, train_accuracy=0.6732\n",
            "TRAIN Epoch 9: 100% 157/157 [00:13<00:00, 11.47it/s, train_loss=0.0308, train_acc=0.662]\n",
            "Client 6: train_loss=0.0308, train_accuracy=0.6624\n",
            "TRAIN Epoch 9: 100% 157/157 [00:12<00:00, 12.36it/s, train_loss=0.031, train_acc=0.655]\n",
            "Client 8: train_loss=0.0310, train_accuracy=0.6554\n",
            "TRAIN Epoch 9: 100% 157/157 [00:12<00:00, 12.34it/s, train_loss=0.0367, train_acc=0.574]\n",
            "Client 3: train_loss=0.0367, train_accuracy=0.5744\n",
            "TRAIN Epoch 9: 100% 157/157 [00:12<00:00, 12.59it/s, train_loss=0.031, train_acc=0.666]\n",
            "Client 7: train_loss=0.0310, train_accuracy=0.6656\n",
            "TRAIN Epoch 9: 100% 157/157 [00:12<00:00, 12.37it/s, train_loss=0.0369, train_acc=0.581]\n",
            "Client 2: train_loss=0.0369, train_accuracy=0.5808\n",
            "DEBUG flower 2022-01-03 15:24:43,074 | server.py:264 | fit_round received 10 results and 0 failures\n",
            "Configuring round 2...\n",
            "DEBUG flower 2022-01-03 15:24:43,082 | server.py:205 | evaluate_round: strategy sampled 10 clients (out of 10)\n",
            "TEST: 100% 32/32 [00:00<00:00, 34.38it/s]\n",
            "Client 0: test_loss=0.0409, test_accuracy=0.5420\n",
            "TEST: 100% 32/32 [00:01<00:00, 29.93it/s]\n",
            "Client 5: test_loss=0.0364, test_accuracy=0.5960\n",
            "TEST:  88% 28/32 [00:01<00:00, 26.09it/s]\n",
            "Client 2: test_loss=0.0434, test_accuracy=0.4980\n",
            "TEST: 100% 32/32 [00:01<00:00, 25.96it/s]\n",
            "Client 1: test_loss=0.0406, test_accuracy=0.5420\n",
            "TEST:  88% 28/32 [00:01<00:00, 26.02it/s]\n",
            "Client 8: test_loss=0.0340, test_accuracy=0.6340\n",
            "TEST: 100% 32/32 [00:01<00:00, 27.78it/s]\n",
            "Client 3: test_loss=0.0400, test_accuracy=0.5730\n",
            "TEST: 100% 32/32 [00:01<00:00, 26.27it/s]\n",
            "Client 7: test_loss=0.0325, test_accuracy=0.6560\n",
            "TEST: 100% 32/32 [00:01<00:00, 24.99it/s]\n",
            "Client 9: test_loss=0.0390, test_accuracy=0.5880\n",
            "TEST: 100% 32/32 [00:01<00:00, 26.84it/s]\n",
            "Client 4: test_loss=0.0403, test_accuracy=0.5250\n",
            "TEST: 100% 32/32 [00:01<00:00, 25.90it/s]\n",
            "Client 6: test_loss=0.0364, test_accuracy=0.6050\n",
            "DEBUG flower 2022-01-03 15:24:44,431 | server.py:214 | evaluate_round received 10 results and 0 failures\n",
            "Configuring round 3...\n",
            "DEBUG flower 2022-01-03 15:24:44,431 | server.py:255 | fit_round: strategy sampled 10 clients (out of 10)\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.75it/s, train_loss=0.0361, train_acc=0.591]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.67it/s, train_loss=0.0364, train_acc=0.584]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.67it/s, train_loss=0.0316, train_acc=0.666]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.62it/s, train_loss=0.0314, train_acc=0.661]\n",
            "TRAIN Epoch 1:   1% 2/157 [00:00<00:12, 12.90it/s, train_loss=0.0326, train_acc=0.625]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.51it/s, train_loss=0.031, train_acc=0.662]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.34it/s, train_loss=0.031, train_acc=0.67]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.36it/s, train_loss=0.037, train_acc=0.581]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.27it/s, train_loss=0.0367, train_acc=0.578]\n",
            "TRAIN Epoch 0: 100% 157/157 [00:13<00:00, 11.22it/s, train_loss=0.0308, train_acc=0.654]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:12<00:00, 12.22it/s, train_loss=0.0361, train_acc=0.59]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:13<00:00, 11.95it/s, train_loss=0.0303, train_acc=0.671]\n",
            "TRAIN Epoch 1:  96% 150/157 [00:12<00:00, 10.61it/s, train_loss=0.0358, train_acc=0.593]\n",
            "TRAIN Epoch 2:   1% 2/157 [00:00<00:12, 12.40it/s, train_loss=0.0389, train_acc=0.5]\n",
            "TRAIN Epoch 1:  98% 154/157 [00:13<00:00, 10.64it/s, train_loss=0.0363, train_acc=0.581]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:13<00:00, 11.79it/s, train_loss=0.0366, train_acc=0.581]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:13<00:00, 11.38it/s, train_loss=0.0359, train_acc=0.596]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:13<00:00, 11.65it/s, train_loss=0.0303, train_acc=0.677]\n",
            "TRAIN Epoch 2:   1% 1/157 [00:00<00:16,  9.34it/s, train_loss=0.0477, train_acc=0.531]\n",
            "TRAIN Epoch 1: 100% 157/157 [00:13<00:00, 11.72it/s, train_loss=0.03, train_acc=0.661]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:12<00:00, 12.15it/s, train_loss=0.0292, train_acc=0.686]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:13<00:00, 12.02it/s, train_loss=0.036, train_acc=0.59]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:12<00:00, 12.09it/s, train_loss=0.0358, train_acc=0.585]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:13<00:00, 11.84it/s, train_loss=0.0294, train_acc=0.684]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:13<00:00, 11.81it/s, train_loss=0.0302, train_acc=0.684]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:13<00:00, 11.61it/s, train_loss=0.0348, train_acc=0.612]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:13<00:00, 11.75it/s, train_loss=0.0299, train_acc=0.681]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:13<00:00, 11.82it/s, train_loss=0.0291, train_acc=0.682]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:13<00:00, 11.64it/s, train_loss=0.0356, train_acc=0.588]\n",
            "TRAIN Epoch 2: 100% 157/157 [00:13<00:00, 11.54it/s, train_loss=0.0356, train_acc=0.598]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 12.03it/s, train_loss=0.03, train_acc=0.69]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 11.46it/s, train_loss=0.029, train_acc=0.69]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 11.96it/s, train_loss=0.0342, train_acc=0.615]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:12<00:00, 12.20it/s, train_loss=0.0287, train_acc=0.694]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 11.30it/s, train_loss=0.0354, train_acc=0.6]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 11.35it/s, train_loss=0.0356, train_acc=0.59]\n",
            "TRAIN Epoch 3:  94% 148/157 [00:13<00:00, 11.10it/s, train_loss=0.0351, train_acc=0.601]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 11.78it/s, train_loss=0.0287, train_acc=0.688]\n",
            "TRAIN Epoch 3: 100% 157/157 [00:13<00:00, 11.83it/s, train_loss=0.035, train_acc=0.604]\n",
            "TRAIN Epoch 4:   9% 14/157 [00:01<00:12, 11.52it/s, train_loss=0.0298, train_acc=0.69]\n",
            "TRAIN Epoch 4:  94% 148/157 [00:12<00:00, 11.45it/s, train_loss=0.0342, train_acc=0.606]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:12<00:00, 12.25it/s, train_loss=0.0349, train_acc=0.603]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.93it/s, train_loss=0.029, train_acc=0.694]\n",
            "TRAIN Epoch 4:  97% 152/157 [00:12<00:00, 12.31it/s, train_loss=0.035, train_acc=0.593]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.75it/s, train_loss=0.0286, train_acc=0.699]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.96it/s, train_loss=0.0352, train_acc=0.592]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:12<00:00, 12.13it/s, train_loss=0.0342, train_acc=0.609]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.87it/s, train_loss=0.0286, train_acc=0.687]\n",
            "TRAIN Epoch 5:   4% 6/157 [00:00<00:12, 11.99it/s, train_loss=0.0293, train_acc=0.679]\n",
            "TRAIN Epoch 4: 100% 157/157 [00:13<00:00, 11.59it/s, train_loss=0.0347, train_acc=0.599]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 12.01it/s, train_loss=0.0286, train_acc=0.701]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.67it/s, train_loss=0.0277, train_acc=0.705]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 12.00it/s, train_loss=0.0332, train_acc=0.624]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.67it/s, train_loss=0.0347, train_acc=0.606]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.86it/s, train_loss=0.0347, train_acc=0.595]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.75it/s, train_loss=0.028, train_acc=0.708]\n",
            "TRAIN Epoch 6:   4% 7/157 [00:00<00:11, 13.31it/s, train_loss=0.0352, train_acc=0.612]\n",
            "TRAIN Epoch 5:  94% 148/157 [00:12<00:00, 11.57it/s, train_loss=0.0348, train_acc=0.599]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.82it/s, train_loss=0.0275, train_acc=0.699]\n",
            "TRAIN Epoch 5: 100% 157/157 [00:13<00:00, 11.87it/s, train_loss=0.0349, train_acc=0.6]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.96it/s, train_loss=0.0282, train_acc=0.709]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.84it/s, train_loss=0.0341, train_acc=0.616]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.70it/s, train_loss=0.0334, train_acc=0.623]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.90it/s, train_loss=0.0345, train_acc=0.602]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.38it/s, train_loss=0.027, train_acc=0.714]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.64it/s, train_loss=0.0334, train_acc=0.618]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.34it/s, train_loss=0.0275, train_acc=0.712]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.41it/s, train_loss=0.027, train_acc=0.713]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.81it/s, train_loss=0.0341, train_acc=0.614]\n",
            "TRAIN Epoch 6: 100% 157/157 [00:13<00:00, 11.29it/s, train_loss=0.027, train_acc=0.712]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:12<00:00, 12.32it/s, train_loss=0.0277, train_acc=0.715]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 12.06it/s, train_loss=0.0327, train_acc=0.635]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.89it/s, train_loss=0.0339, train_acc=0.608]\n",
            "TRAIN Epoch 7:  98% 154/157 [00:12<00:00, 11.44it/s, train_loss=0.0331, train_acc=0.621]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:12<00:00, 12.10it/s, train_loss=0.0331, train_acc=0.622]\n",
            "TRAIN Epoch 8:   1% 1/157 [00:00<00:15,  9.80it/s, train_loss=0.0315, train_acc=0.625]\n",
            "TRAIN Epoch 7:  97% 153/157 [00:13<00:00, 11.06it/s, train_loss=0.0269, train_acc=0.722]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.97it/s, train_loss=0.0268, train_acc=0.714]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.49it/s, train_loss=0.027, train_acc=0.722]\n",
            "TRAIN Epoch 7: 100% 157/157 [00:13<00:00, 11.62it/s, train_loss=0.0265, train_acc=0.713]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.22it/s, train_loss=0.0272, train_acc=0.714]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.83it/s, train_loss=0.0335, train_acc=0.617]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.82it/s, train_loss=0.0329, train_acc=0.628]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:14<00:00, 11.21it/s, train_loss=0.0322, train_acc=0.64]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:12<00:00, 12.20it/s, train_loss=0.0265, train_acc=0.717]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.92it/s, train_loss=0.0331, train_acc=0.632]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.43it/s, train_loss=0.0263, train_acc=0.722]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:14<00:00, 11.19it/s, train_loss=0.0331, train_acc=0.625]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.81it/s, train_loss=0.0265, train_acc=0.723]\n",
            "TRAIN Epoch 8: 100% 157/157 [00:13<00:00, 11.82it/s, train_loss=0.0262, train_acc=0.713]\n",
            "TRAIN Epoch 9: 100% 157/157 [00:12<00:00, 12.34it/s, train_loss=0.0268, train_acc=0.722]\n",
            "Client 5: train_loss=0.0268, train_accuracy=0.7218\n",
            "TRAIN Epoch 9: 100% 157/157 [00:12<00:00, 12.44it/s, train_loss=0.0316, train_acc=0.648]\n",
            "Client 4: train_loss=0.0316, train_accuracy=0.6484\n",
            "TRAIN Epoch 9:  98% 154/157 [00:13<00:00, 14.68it/s, train_loss=0.0322, train_acc=0.639]\n",
            "Client 1: train_loss=0.0333, train_accuracy=0.6230\n",
            "TRAIN Epoch 9: 100% 157/157 [00:12<00:00, 12.53it/s, train_loss=0.0256, train_acc=0.732]\n",
            "Client 9: train_loss=0.0256, train_accuracy=0.7324\n",
            "TRAIN Epoch 9: 100% 157/157 [00:13<00:00, 11.92it/s, train_loss=0.0325, train_acc=0.638]\n",
            "Client 0: train_loss=0.0325, train_accuracy=0.6382\n",
            "TRAIN Epoch 9: 100% 157/157 [00:13<00:00, 11.91it/s, train_loss=0.0257, train_acc=0.73]\n",
            "Client 6: train_loss=0.0257, train_accuracy=0.7300\n",
            "TRAIN Epoch 9: 100% 157/157 [00:12<00:00, 12.32it/s, train_loss=0.0263, train_acc=0.725]\n",
            "Client 7: train_loss=0.0263, train_accuracy=0.7250\n",
            "TRAIN Epoch 9: 100% 157/157 [00:13<00:00, 11.95it/s, train_loss=0.0328, train_acc=0.63]\n",
            "Client 3: train_loss=0.0328, train_accuracy=0.6304\n",
            "TRAIN Epoch 9: 100% 157/157 [00:12<00:00, 12.18it/s, train_loss=0.033, train_acc=0.633]\n",
            "Client 2: train_loss=0.0330, train_accuracy=0.6330\n",
            "TRAIN Epoch 9: 100% 157/157 [00:12<00:00, 12.93it/s, train_loss=0.0257, train_acc=0.723]\n",
            "Client 8: train_loss=0.0257, train_accuracy=0.7228\n",
            "DEBUG flower 2022-01-03 15:26:58,389 | server.py:264 | fit_round received 10 results and 0 failures\n",
            "Configuring round 3...\n",
            "DEBUG flower 2022-01-03 15:26:58,403 | server.py:205 | evaluate_round: strategy sampled 10 clients (out of 10)\n",
            "TEST: 100% 32/32 [00:01<00:00, 28.56it/s]\n",
            "Client 4: test_loss=0.0383, test_accuracy=0.5740\n",
            "TEST: 100% 32/32 [00:01<00:00, 29.49it/s]\n",
            "Client 9: test_loss=0.0326, test_accuracy=0.6680\n",
            "TEST: 100% 32/32 [00:01<00:00, 29.03it/s]\n",
            "Client 6: test_loss=0.0313, test_accuracy=0.6660\n",
            "TEST: 100% 32/32 [00:01<00:00, 26.42it/s]\n",
            "Client 7: test_loss=0.0307, test_accuracy=0.6530\n",
            "TEST: 100% 32/32 [00:01<00:00, 25.23it/s]\n",
            "Client 3: test_loss=0.0370, test_accuracy=0.6030\n",
            "\n",
            "Client 1: test_loss=0.0369, test_accuracy=0.5860\n",
            "TEST: 100% 32/32 [00:01<00:00, 25.58it/s]\n",
            "Client 0: test_loss=0.0380, test_accuracy=0.5720\n",
            "TEST: 100% 32/32 [00:01<00:00, 26.06it/s]\n",
            "Client 5: test_loss=0.0304, test_accuracy=0.6800\n",
            "TEST: 100% 32/32 [00:01<00:00, 24.89it/s]\n",
            "Client 8: test_loss=0.0331, test_accuracy=0.6600\n",
            "TEST: 100% 32/32 [00:01<00:00, 25.59it/s]\n",
            "Client 2: test_loss=0.0395, test_accuracy=0.5550\n",
            "DEBUG flower 2022-01-03 15:26:59,755 | server.py:214 | evaluate_round received 10 results and 0 failures\n",
            "INFO flower 2022-01-03 15:26:59,755 | server.py:172 | FL finished in 585.2328829579992\n",
            "DEBUG flower 2022-01-03 15:26:59,759 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:26:59,759 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:26:59,767 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:26:59,768 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:26:59,769 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:26:59,766 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:26:59,771 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:26:59,772 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:26:59,773 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:26:59,766 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-03 15:26:59,962 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 9: shutdownDEBUG flower 2022-01-03 15:26:59,963 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 8: shutdown\n",
            "Started 10 clients\n",
            "\n",
            "Started 10 clients\n",
            "DEBUG flower 2022-01-03 15:26:59,969 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 3: shutdown\n",
            "Started 10 clientsDEBUG flower 2022-01-03 15:26:59,970 | connection.py:68 | Insecure gRPC channel closed\n",
            "DEBUG flower 2022-01-03 15:26:59,971 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 4: shutdownClient 5: shutdownDEBUG flower 2022-01-03 15:26:59,972 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 0: shutdown\n",
            "\n",
            "DEBUG flower 2022-01-03 15:26:59,973 | connection.py:68 | Insecure gRPC channel closed\n",
            "DEBUG flower 2022-01-03 15:26:59,973 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 7: shutdownClient 1: shutdown\n",
            "Started 10 clients\n",
            "Started 10 clientsStarted 10 clients\n",
            "\n",
            "\n",
            "Started 10 clients\n",
            "\n",
            "Started 10 clientsDEBUG flower 2022-01-03 15:26:59,975 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 2: shutdownDEBUG flower 2022-01-03 15:26:59,976 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 6: shutdown\n",
            "Started 10 clients\n",
            "\n",
            "Started 10 clients\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "num_clients = 10\n",
        "num_rounds = 3\n",
        "\n",
        "all_files = []\n",
        "for file in glob.glob(\"logs/*\"):\n",
        "    all_files.append(file)\n",
        "\n",
        "print(all_files)\n",
        "\n",
        "train_losses = [[0] * 30 for i in range(num_clients)]\n",
        "train_accs = [[0] * 30 for i in range(num_clients)]\n",
        "\n",
        "for client_id in range(num_clients):\n",
        "    for round_id in range(1, num_rounds+1):\n",
        "        with open(f'logs/client_{client_id}/training_round_{round_id}', 'rb') as fp:\n",
        "            results = np.asarray(pickle.load(fp))\n",
        "            train_losses[client_id][(round_id-1)*10:round_id*10] = results[:,0]\n",
        "            train_accs[client_id][(round_id-1)*10:round_id*10] = results[:,1]\n",
        "\n",
        "test_losses = [[0] * 3 for i in range(num_clients)]\n",
        "test_accs = [[0] * 3 for i in range(num_clients)]\n",
        "\n",
        "for client_id in range(num_clients):\n",
        "    for round_id in range(1, num_rounds+1):\n",
        "        with open(f'logs/client_{client_id}/testing_round_{round_id}', 'rb') as fp:\n",
        "            results = np.asarray(pickle.load(fp))\n",
        "            test_losses[client_id][round_id-1] = results[0]\n",
        "            test_accs[client_id][round_id-1] = results[1]"
      ],
      "metadata": {
        "id": "nqef5ZIVVY1D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8bcc9a0-8ce9-40e1-90ef-c10580ef348d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['logs/client_1', 'logs/client_2', 'logs/client_3', 'logs/client_4', 'logs/client_0', 'logs/client_5', 'logs/client_6', 'logs/client_7', 'logs/client_8', 'logs/client_9', 'logs/standard_iid_0.5', 'logs/standard_iid_0.75', 'logs/standard_iid_0.25', 'logs/standard_iid_1', 'logs/standard_iid_0.1', 'logs/reversed_model_iid_0.5', 'logs/reversed_model_iid_0.1', 'logs/small_base_iid_0.5', 'logs/large_base_iid_0.5', 'logs/medley_base_iid_0.5', 'logs/large_base_iid_0.1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_losses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfgcF2TBo0td",
        "outputId": "ef3a6953-7ff0-466b-df21-882330bca619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.06611644423007965, 0.05670306813716888, 0.050971031665802004],\n",
              " [0.07082808494567872, 0.06596984422206878, 0.0555262656211853],\n",
              " [0.06851301002502441, 0.05974188959598541, 0.05238166284561157],\n",
              " [0.06947494435310364, 0.06052490782737732, 0.052724830508232116],\n",
              " [0.06730612182617188, 0.057494162440299985, 0.05055581223964691],\n",
              " [0.06581063175201415, 0.05679802119731903, 0.0522175452709198],\n",
              " [0.06906508445739747, 0.06234287548065186, 0.056295003294944766],\n",
              " [0.06795336210727691, 0.06009175932407379, 0.054405296564102174],\n",
              " [0.067596719622612, 0.05967743170261383, 0.0533522173166275],\n",
              " [0.06556041514873505, 0.05557293677330017, 0.04950327515602112]]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9jCe0g8-o0zC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VpjmXKK9o02U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_name = 'small_base_iid_0.1'"
      ],
      "metadata": {
        "id": "DOmRq2AHo08E"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'logs/{experiment_name}/train_losses', 'wb') as fp:\n",
        "    pickle.dump(train_losses, fp)\n",
        "with open(f'logs/{experiment_name}/train_accs', 'wb') as fp:\n",
        "    pickle.dump(train_accs, fp)"
      ],
      "metadata": {
        "id": "Wp9bMKbSnh7C"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'logs/{experiment_name}/test_losses', 'wb') as fp:\n",
        "    pickle.dump(test_losses, fp)\n",
        "with open(f'logs/{experiment_name}/test_accs', 'wb') as fp:\n",
        "    pickle.dump(test_accs, fp)"
      ],
      "metadata": {
        "id": "ZBfhuKBvqhAX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gQOIaWcPrXuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overall configuration\n",
        "\n",
        "10 clients, 3 rounds, 10 epochs, lr = 0.001, SGD optimizer, momentum=0.9\n",
        "\n",
        "Standard configuration: Basenet with convolution layers and personalnet with linear layers on the top\n",
        "\n",
        "    class BaseNet(nn.Module):\n",
        "        def __init__(self) -> None:\n",
        "            super(BaseNet, self).__init__()\n",
        "            self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "            self.pool = nn.MaxPool2d(2, 2)\n",
        "            self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "            self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "            # self.fc2 = nn.Linear(120, 84)\n",
        "            # self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "        def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "            x = self.pool(F.relu(self.conv1(x)))\n",
        "            x = self.pool(F.relu(self.conv2(x)))\n",
        "            x = x.view(-1, 16 * 5 * 5)\n",
        "            x = F.relu(self.fc1(x))\n",
        "            # x = F.relu(self.fc2(x))\n",
        "            # x = self.fc3(x)\n",
        "            return x\n",
        "\n",
        "    class PersonalNet(nn.Module):\n",
        "        def __init__(self) -> None:\n",
        "            super(PersonalNet, self).__init__()\n",
        "            self.fc2 = nn.Linear(120, 84)\n",
        "            self.fc3 = nn.Linear(84, 10)\n",
        "        def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "            x = F.relu(self.fc2(x))\n",
        "            x = self.fc3(x)\n",
        "            return x\n",
        "\n",
        "\n",
        "Reversed model configuration: Basenet with linear layers on top and personal net with convolution layers\n",
        "\n",
        "Medley model configuration: Basenet with"
      ],
      "metadata": {
        "id": "6ivTW1Gdaimp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j4gc4qpP4Q2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plots"
      ],
      "metadata": {
        "id": "T0dELhXfDCqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "files = ['standard_iid_0.1', 'standard_iid_0.25', 'standard_iid_0.5', 'standard_iid_0.75', 'standard_iid_1']\n",
        "files = ['standard_iid_0.5', 'small_base_iid_0.5', 'large_base_iid_0.5', 'reversed_model_iid_0.5']\n",
        "test_accs = []\n",
        "train_losses = []\n",
        "for file in files:\n",
        "    with open(f'logs/{file}/test_accs', 'rb') as pf:\n",
        "        test_acc = pickle.load(pf)\n",
        "    with open(f'logs/{file}/test_accs', 'rb') as pf:\n",
        "        test_acc = pickle.load(pf)\n",
        "    test_accs.append(test_acc)"
      ],
      "metadata": {
        "id": "1mRR5h4ODD5D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, test_acc in enumerate(test_accs):\n",
        "    label = 'iid_fraction=' + files[i].split('_')[-1]\n",
        "    plt.plot(range(0,4), np.insert(np.asarray(test_acc).mean(axis=0), 0, 0.1), label=files[i])\n",
        "plt.legend()\n",
        "plt.xlabel('Rounds')\n",
        "plt.ylabel('Test Accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "w4SPcZ-JELvs",
        "outputId": "efa5e4b5-cb04-4059-999c-c3c7a60f4a60"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Test Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.asarray(test_accs[0]).mean(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6J1LZD-GKnq",
        "outputId": "1e4c340d-4ade-420c-f7fe-9c246b39507a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.3643, 0.4746, 0.5383])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O8wO4zKZHbga"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
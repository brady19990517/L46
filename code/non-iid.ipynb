{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqY1zAZanXBR",
        "outputId": "e738682c-3892-4a37-d832-8f4f3fda3b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flwr==0.17.0 in /usr/local/lib/python3.7/dist-packages (0.17.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (1.19.5)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.27.2 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (1.42.0)\n",
            "Requirement already satisfied: google<3.0.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (2.0.3)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.12.1 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (3.17.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google<3.0.0,>=2.0.3->flwr==0.17.0) (4.6.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<2.0.0,>=1.27.2->flwr==0.17.0) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install flwr==0.17.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cifar.py\n",
        "\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from torch import Tensor\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from flwr_experimental.baseline.dataset.dataset import create_partitioned_dataset\n",
        "\n",
        "import flwr as fl\n",
        "\n",
        "class Net(nn.Module):\n",
        "    \"\"\"Simple CNN adapted from 'PyTorch: A 60 Minute Blitz'.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Compute forward pass.\"\"\"\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def get_weights(self) -> fl.common.Weights:\n",
        "        \"\"\"Get model weights as a list of NumPy ndarrays.\"\"\"\n",
        "        return [val.cpu().numpy() for _, val in self.state_dict().items()]\n",
        "\n",
        "    def set_weights(self, weights: fl.common.Weights) -> None:\n",
        "        \"\"\"Set model weights from a list of NumPy ndarrays.\"\"\"\n",
        "        state_dict = OrderedDict(\n",
        "            {k: torch.Tensor(v) for k, v in zip(self.state_dict().keys(), weights)}\n",
        "        )\n",
        "        self.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def load_model():\n",
        "    return Net()\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Loads CIFAR-10 (training and test set).\"\"\"\n",
        "    data_root = \"/content/data/cifar-10\"\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "    trainset = torchvision.datasets.CIFAR10(root=data_root, train=True, download=True, transform=transform)\n",
        "    testset = torchvision.datasets.CIFAR10(root=data_root, train=False, download=True, transform=transform)\n",
        "    return trainset, testset\n",
        "\n",
        "class PartitionedDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.X[idx], int(self.Y[idx]))\n",
        "\n",
        "\n",
        "def load_local_partitioned_data(client_id, iid_fraction: float, num_partitions: int):\n",
        "    \"\"\"Creates a dataset for each worker, which is a partition of a larger dataset.\"\"\"\n",
        "    \n",
        "    # Each worker loads the entire dataset, and then selects its partition\n",
        "    # determined by its `client_id` (happens internally below)\n",
        "    trainset, testset = load_data()\n",
        "    [global_trainset, local_trainset] = torch.utils.data.random_split(trainset, [int(trainset.data.shape[0] * x) for x in [0.2,0.8]])\n",
        "    \n",
        "    train_loader = DataLoader(local_trainset, batch_size=len(local_trainset))\n",
        "    test_loader = DataLoader(testset, batch_size=len(testset))\n",
        "    global_train_loader = DataLoader(global_trainset, batch_size=len(global_trainset))\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test), (global_x_train, global_y_train) = next(iter(train_loader)), next(iter(test_loader)), next(iter(global_train_loader))\n",
        "    x_train, y_train = x_train.numpy(), y_train.numpy()\n",
        "    x_test, y_test = x_test.numpy(), y_test.numpy()\n",
        "    global_x_train, global_y_train = global_x_train.numpy(), global_y_train.numpy()\n",
        "\n",
        "    #TODO: Create my own train_partitions\n",
        "    (_, test_partitions), _ = create_partitioned_dataset(\n",
        "        ((x_train, y_train), (x_test, y_test)), iid_fraction, num_partitions)\n",
        "\n",
        "\n",
        "    train_partitions = []\n",
        "    for label in np.unique(y_train):\n",
        "      result = np.where(y_train == label)[0]\n",
        "      train_partitions.append([[x_train[i] for i in result],[label] * len(result)])\n",
        "\n",
        "    global_idx = list(range(0, len(global_x_train)))\n",
        "    random.shuffle(global_idx)\n",
        "    global_partition = []\n",
        "\n",
        "    ####\n",
        "    beta = 0.2\n",
        "    alpha = 0.5\n",
        "    ####\n",
        "\n",
        "    temp1 = []\n",
        "    temp2 = []\n",
        "\n",
        "    for g_partition in np.split(np.asarray(global_idx),10):\n",
        "        temp1.append([global_x_train[i] for i in g_partition])\n",
        "        temp2.append([global_y_train[i] for i in g_partition])\n",
        "        \n",
        "\n",
        "    for i, partition in enumerate(train_partitions):\n",
        "        global_partition.append((temp1[i][:int(len(partition[0])*beta)],temp2[i][:int(len(partition[0])*beta)]))\n",
        "        train_partitions[i][0] = np.concatenate((partition[0], np.asarray(temp1[i][:int(len(partition[0])*beta*alpha)])))\n",
        "        train_partitions[i][1] = np.concatenate((partition[1], np.asarray(temp2[i][:int(len(partition[0])*beta*alpha)])))\n",
        "      \n",
        "    x_train, y_train = train_partitions[client_id]\n",
        "    torch_partition_trainset = PartitionedDataset(torch.Tensor(x_train), y_train)\n",
        "    x_test, y_test = test_partitions[client_id]\n",
        "    torch_partition_testset = PartitionedDataset(torch.Tensor(x_test), y_test )\n",
        "    global_x_train, global_y_train = global_partition[client_id]\n",
        "    torch_partition_global_trainset = PartitionedDataset(torch.Tensor(np.asarray(global_x_train)), global_y_train)\n",
        "    return torch_partition_trainset, torch_partition_testset,torch_partition_global_trainset\n",
        "\n",
        "def get_partitionedDataset(train_partitions, test_partitions, global_partition, client_id):\n",
        "      [x_train, y_train] = train_partitions[client_id]\n",
        "      torch_partition_trainset = PartitionedDataset(torch.Tensor(x_train), y_train)\n",
        "      x_test, y_test = test_partitions[client_id]\n",
        "      torch_partition_testset = PartitionedDataset(torch.Tensor(x_test), y_test)\n",
        "      global_x_train, global_y_train = global_partition[client_id]\n",
        "      torch_partition_global_trainset = PartitionedDataset(torch.Tensor(global_x_train), global_y_train)\n",
        "      return torch_partition_trainset, torch_partition_testset, torch_partition_global_trainset\n",
        "\n",
        "\n",
        "def train(\n",
        "    net: Net,\n",
        "    trainloader: torch.utils.data.DataLoader,\n",
        "    device: torch.device,\n",
        "    start_epoch: int,\n",
        "    end_epoch: int,\n",
        "    log_progress: bool = True):\n",
        "    \"\"\"Trains a network on provided data from `start_epoch` to `end_epoch` incl. (the training loop).\"\"\"\n",
        "\n",
        "    # Define loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    print(f\"Training from epoch(s) {start_epoch} to {end_epoch} w/ {len(trainloader)} batches each.\", flush=True)\n",
        "    results = []\n",
        "\n",
        "    # Train the network\n",
        "    for epoch in range(start_epoch, end_epoch+1):  # loop over the dataset multiple times, last epoch inclusive\n",
        "        total_loss, total_correct, n_samples = 0.0, 0.0, 0\n",
        "        pbar = tqdm(trainloader, desc=f'TRAIN Epoch {epoch}') if log_progress else trainloader\n",
        "        for data in pbar:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Collected training loss and accuracy statistics\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1) \n",
        "            n_samples += labels.size(0)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if log_progress:\n",
        "                pbar.set_postfix({\n",
        "                    \"train_loss\": total_loss/n_samples, \n",
        "                    \"train_acc\": total_correct/n_samples\n",
        "                })\n",
        "            \n",
        "        results.append((total_loss/n_samples, total_correct/n_samples))    \n",
        "        \n",
        "    return results      \n",
        "    \n",
        "def test(\n",
        "    net: Net,\n",
        "    testloader: torch.utils.data.DataLoader,\n",
        "    device: torch.device,\n",
        "    log_progress: bool = True):\n",
        "    \"\"\"Evaluates the network on test data.\"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    total_loss, total_correct, n_samples = 0.0, 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(testloader, desc=\"TEST\") if log_progress else testloader\n",
        "        for data in pbar:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = net(images)\n",
        "\n",
        "            # Collected testing loss and accuracy statistics\n",
        "            total_loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1) \n",
        "            n_samples += labels.size(0)\n",
        "            total_correct += (predicted == labels).sum().item() \n",
        "    \n",
        "    return (total_loss/n_samples, total_correct/n_samples)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8s3X7yznfMY",
        "outputId": "2f998836-a292-4fc8-ce01-27cf34dd83df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cifar.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile client.py\n",
        "import argparse\n",
        "import grpc\n",
        "import timeit\n",
        "import torch\n",
        "import torchvision\n",
        "import flwr as fl\n",
        "import random\n",
        "\n",
        "from collections import OrderedDict\n",
        "from typing import Optional\n",
        "from torch.utils.data import DataLoader\n",
        "from flwr.common import EvaluateIns, EvaluateRes, FitIns, FitRes, ParametersRes, Weights\n",
        "import time\n",
        "\n",
        "\n",
        "import cifar\n",
        "\n",
        "DEFAULT_SERVER_ADDRESS = \"localhost:8099\"\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "\n",
        "class CifarClient(fl.client.Client):\n",
        "    \"\"\"Flower client implementing CIFAR-10 image classification using PyTorch.\"\"\"\n",
        "    def __init__(\n",
        "        self, cid,\n",
        "        model: cifar.Net,\n",
        "        trainset: torchvision.datasets.CIFAR10,\n",
        "        testset: torchvision.datasets.CIFAR10,\n",
        "        exp_name: Optional[str],\n",
        "        iid_fraction: Optional[float]):\n",
        "        self.cid = cid\n",
        "        self.model = model\n",
        "        self.trainset = trainset\n",
        "        self.testset = testset\n",
        "        self.exp_name = exp_name or 'federated_unspecified'\n",
        "        print(f\"Client {self.cid} running experiment {self.exp_name}\")\n",
        "\n",
        "\n",
        "    def get_parameters(self) -> ParametersRes:\n",
        "        print(f\"Client {self.cid}: get_parameters\")\n",
        "\n",
        "        weights: Weights = self.model.get_weights()\n",
        "        parameters = fl.common.weights_to_parameters(weights)\n",
        "        return ParametersRes(parameters=parameters)\n",
        "\n",
        "    def fit(self, ins: FitIns) -> FitRes:\n",
        "        print(f\"Client {self.cid}: fit\")\n",
        "        config = ins.config\n",
        "        weights: Weights = fl.common.parameters_to_weights(ins.parameters)\n",
        "\n",
        "        # Get training config\n",
        "        epochs = int(config[\"epochs\"])\n",
        "        batch_size = int(config[\"batch_size\"])\n",
        "        epoch_global = int(config[\"epoch_global\"])\n",
        "\n",
        "        # Set model parameters\n",
        "        self.model.set_weights(weights)\n",
        "\n",
        "        # Train the model\n",
        "        trainloader = DataLoader(self.trainset, batch_size=batch_size, shuffle=True)\n",
        "        \n",
        "        start_epoch = epoch_global + 1\n",
        "        end_epoch = start_epoch + epochs - 1\n",
        "\n",
        "        fit_begin = timeit.default_timer()\n",
        "        training_log = cifar.train(net=self.model, trainloader=trainloader, device=DEVICE, \n",
        "                                   start_epoch=start_epoch, end_epoch=end_epoch, log_progress=True)\n",
        "        fit_duration = timeit.default_timer() - fit_begin\n",
        "\n",
        "        train_loss, train_acc = training_log[-1]\n",
        "        print(f'Client {self.cid}: train_loss={train_loss:.4f}, train_accuracy={train_acc:.4f}')\n",
        "\n",
        "        # Return the refined weights and the number of examples used for training\n",
        "        weights_prime: Weights = self.model.get_weights()\n",
        "        params_prime = fl.common.weights_to_parameters(weights_prime)\n",
        "        num_examples_train = len(self.trainset)\n",
        "        return FitRes(\n",
        "            parameters=params_prime,\n",
        "            num_examples=num_examples_train,\n",
        "            num_examples_ceil=num_examples_train,\n",
        "            fit_duration=fit_duration,\n",
        "        )\n",
        "\n",
        "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
        "        print(f\"Client {self.cid}: evaluate\")\n",
        "        config = ins.config\n",
        "        epoch_global = int(config[\"epoch_global\"])\n",
        "        \n",
        "        # Use provided weights to update the local model\n",
        "        weights = fl.common.parameters_to_weights(ins.parameters)\n",
        "        self.model.set_weights(weights)\n",
        "\n",
        "        # Evaluate the updated model on the local dataset\n",
        "        testloader = DataLoader(self.testset, batch_size=32, shuffle=False)\n",
        "        test_loss, test_acc = cifar.test(net=self.model, testloader=testloader, \n",
        "                                         device=DEVICE, log_progress=False)\n",
        "        print(f\"Client {self.cid}: test_loss={test_loss:.4f}, test_accuracy={test_acc:.4f}\")\n",
        "\n",
        "        # Return the number of evaluation examples and the evaluation result (loss)\n",
        "        return EvaluateRes(\n",
        "            num_examples=len(self.testset), loss=test_loss, accuracy=test_acc\n",
        "        )\n",
        "\n",
        "def start_client(client_id, num_partitions, iid_fraction=1.0, \n",
        "                 server_address=DEFAULT_SERVER_ADDRESS, log_host=None, exp_name=None):\n",
        "    # Configure logger\n",
        "    fl.common.logger.configure(f\"client_{client_id}\", host=log_host)\n",
        "\n",
        "    # Load model and data\n",
        "    model = cifar.load_model()\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    \n",
        "    trainset, testset,globalset = cifar.load_local_partitioned_data(\n",
        "        client_id=client_id, \n",
        "        iid_fraction=iid_fraction, \n",
        "        num_partitions=num_partitions)\n",
        "\n",
        "    print(f\"start global traning on Client {client_id}\")\n",
        "    globalloader = DataLoader(globalset, batch_size=32, shuffle=True)\n",
        "    cifar.train(model,globalloader,DEVICE,0,10)\n",
        "\n",
        "    testloader = DataLoader(testset, batch_size=32, shuffle=True)\n",
        "    loss,acc = cifar.test(model,testloader,DEVICE)\n",
        "    print(f\"global traning accuracy {acc}\")\n",
        "\n",
        "    \n",
        "   \n",
        "\n",
        "\n",
        "    # Start client\n",
        "    print(f\"Starting client {client_id}\")\n",
        "    client = CifarClient(client_id, model, trainset, testset, \n",
        "        f'{exp_name}_iid-fraction_{iid_fraction}', iid_fraction)\n",
        "\n",
        "    print(f\"Connecting to {server_address}\")\n",
        "\n",
        "    try:\n",
        "        # There's no graceful shutdown when gRPC server terminates, so we try/except\n",
        "        fl.client.start_client(server_address, client)\n",
        "    except grpc._channel._MultiThreadedRendezvous:\n",
        "        print(f\"Client {client_id}: shutdown\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Flower client\")\n",
        "    parser.add_argument(\"--server_address\", type=str, default=DEFAULT_SERVER_ADDRESS,\n",
        "        help=f\"gRPC server address (default: {DEFAULT_SERVER_ADDRESS})\")\n",
        "    parser.add_argument(\"--cid\", type=int, required=True, help=\"Client CID (no default)\")\n",
        "    parser.add_argument(\"--num_partitions\", type=int, required=True, \n",
        "        help=\"Total number of clients participating in training\")\n",
        "    parser.add_argument(\"--iid_fraction\", type=float, nargs=\"?\", const=1.0, \n",
        "        help=\"Fraction of data [0,1] that is independent and identically distributed.\")\n",
        "    parser.add_argument(\"--log_host\", type=str, help=\"Log server address\")\n",
        "    parser.add_argument(\"--exp_name\", type=str, help=\"Friendly experiment name\")\n",
        "\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    start_client(args.cid, 10, 0.5, DEFAULT_SERVER_ADDRESS)\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_66rm1UmnjnL",
        "outputId": "1ce7c748-3c11-4929-9730-75ca18c66935"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting client.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile server.py\n",
        "\n",
        "import argparse\n",
        "from typing import Callable, Dict, Optional, Tuple\n",
        "\n",
        "from logging import INFO\n",
        "from flwr.common.logger import log\n",
        "from flwr.server.grpc_server.grpc_server import start_insecure_grpc_server\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import flwr as fl\n",
        "import cifar\n",
        "\n",
        "DEFAULT_SERVER_ADDRESS = \"localhost:8099\"\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "def start_server(exp_name=None, \n",
        "                 server_address=DEFAULT_SERVER_ADDRESS, \n",
        "                 rounds=1,\n",
        "                 epochs=10,\n",
        "                 batch_size=32,\n",
        "                 sample_fraction=1.0,\n",
        "                 min_sample_size=2,\n",
        "                 min_num_clients=2,\n",
        "                 log_host=None):\n",
        "\n",
        "    if not exp_name:\n",
        "        exp_name = f\"federated_rounds_{rounds}_\" \\\n",
        "                   f\"epochs_{epochs}_\" \\\n",
        "                   f\"min_num_clients_{min_num_clients}_\" \\\n",
        "                   f\"min_sample_size_{min_sample_size}_\" \\\n",
        "                   f\"sample_fraction_{sample_fraction}\"\n",
        "\n",
        "    # Configure logger\n",
        "    fl.common.logger.configure(\"server\", host=log_host)\n",
        "\n",
        "    # Load evaluation data\n",
        "    _, testset = cifar.load_data()\n",
        "    \n",
        "    # Create client_manager, strategy, and server\n",
        "    client_manager = fl.server.SimpleClientManager()\n",
        "\n",
        "    strategy = fl.server.strategy.FedAvg(\n",
        "        fraction_fit=sample_fraction,\n",
        "        min_fit_clients=min_sample_size,\n",
        "        min_eval_clients=min_sample_size,\n",
        "        min_available_clients=min_num_clients,\n",
        "        eval_fn=get_eval_fn(testset),\n",
        "        on_fit_config_fn=generate_config(epochs, batch_size),\n",
        "        on_evaluate_config_fn=generate_config(epochs, batch_size)\n",
        "    )\n",
        "    server = fl.server.Server(client_manager=client_manager, strategy=strategy)\n",
        "\n",
        "    # Run server \n",
        "    print(f\"Starting gRPC server on {server_address}...\")\n",
        "    grpc_server = start_insecure_grpc_server(\n",
        "        client_manager=server.client_manager(),\n",
        "        server_address=server_address,\n",
        "        max_message_length=fl.common.GRPC_MAX_MESSAGE_LENGTH,\n",
        "    )\n",
        "    \n",
        "    # Fit model\n",
        "    print(\"Fitting the model...\")\n",
        "    hist = server.fit(num_rounds=rounds)\n",
        " \n",
        "    log(INFO, f\"app_fit: losses_centralized={hist.losses_centralized}\")\n",
        "    log(INFO, f\"app_fit: accuracies_centralized={hist.metrics_centralized['accuracy']}\")\n",
        "\n",
        "    # Evaluate the final accuracy on the server\n",
        "    test_loss, test_metrics = server.strategy.evaluate(parameters=server.parameters)\n",
        "    print(f\"Server-side test results after training: test_loss={test_loss:.4f}, \"\n",
        "          f\"test_accuracy={test_metrics['accuracy']:.4f}\")\n",
        "\n",
        "    # Now, apply temporary workaround to force distributed evaluation\n",
        "    server.strategy.eval_fn = None\n",
        "\n",
        "    # Evaluate the final trained model\n",
        "    res = server.evaluate_round(rnd=-1)\n",
        "    if res is not None:\n",
        "        loss_aggregated, metrics_aggregated, (results, failures) = res\n",
        "        log(INFO, f\"app_evaluate: federated loss: {loss_aggregated}\")\n",
        "        log(INFO, f\"app_evaluate: metrics: {metrics_aggregated}\")\n",
        "        log(INFO, f\"app_evaluate: results {[(res[0].cid, res[1]) for res in results]}\")\n",
        "        log(INFO, f\"app_evaluate: failures {failures}\")\n",
        "    else:\n",
        "        log(INFO, f\"app_evaluate: no evaluation result\")\n",
        "\n",
        "    # Stop the gRPC server\n",
        "    grpc_server.stop(None)    \n",
        "\n",
        "\n",
        "def generate_config(epochs, batch_size):\n",
        "    def fit_config(round: int) -> Dict[str, str]:\n",
        "        print(f\"Configuring round {round}...\")\n",
        "        return {\n",
        "            \"epoch_global\": str((round - 1) * epochs),\n",
        "            \"epochs\": str(epochs),\n",
        "            \"batch_size\": str(batch_size),\n",
        "        }\n",
        "    \n",
        "    return fit_config \n",
        "\n",
        "\n",
        "def get_eval_fn(testset: torchvision.datasets.CIFAR10):\n",
        "    \"\"\"Returns an evaluation function for centralized (server-side) evaluation.\"\"\"\n",
        "    def evaluate(weights: fl.common.Weights):\n",
        "        \"\"\"Use the entire CIFAR-10 test set for evaluation.\"\"\"\n",
        "        model = cifar.load_model()\n",
        "        model.set_weights(weights)\n",
        "        model.to(DEVICE)\n",
        "        testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
        "        loss, accuracy = cifar.test(net=model, testloader=testloader, device=DEVICE, log_progress=False)\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "    return evaluate\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Flower server\")\n",
        "    parser.add_argument(\"--server_address\", type=str, default=DEFAULT_SERVER_ADDRESS,\n",
        "        help=f\"gRPC server address (default: {DEFAULT_SERVER_ADDRESS})\")\n",
        "    parser.add_argument(\"--rounds\", type=int, default=1,\n",
        "        help=\"Number of rounds of federated learning (default: 1)\")\n",
        "    parser.add_argument(\"--sample_fraction\", type=float, default=1.0,\n",
        "        help=\"Fraction of available clients used for fit/evaluate (default: 1.0)\")\n",
        "    parser.add_argument(\"--min_sample_size\", type=int, default=2,\n",
        "        help=\"Minimum number of clients used for fit/evaluate (default: 2)\")\n",
        "    parser.add_argument(\"--min_num_clients\", type=int, default=2,\n",
        "        help=\"Minimum number of available clients needed for sampling (default: 2)\")\n",
        "    parser.add_argument(\"--log_host\", type=str, help=\"Log server address (no default)\")\n",
        "    parser.add_argument(\"--epochs\", type=int, default=10,\n",
        "        help=\"Number of epochs each client will train for (default: 10)\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32,\n",
        "        help=\"Number of samples per batch each client will use (default: 32)\")   \n",
        "    parser.add_argument(\"--exp_name\", type=str,\n",
        "        help=\"Name of the experiment you are running (no default)\")\n",
        "    args, _ = parser.parse_known_args()\n",
        "    \n",
        "    start_server(exp_name=args.exp_name,\n",
        "                 server_address=args.server_address,\n",
        "                 rounds=args.rounds,\n",
        "                 epochs=args.epochs,\n",
        "                 batch_size=args.batch_size,\n",
        "                 sample_fraction=args.sample_fraction,\n",
        "                 min_sample_size=args.min_sample_size,\n",
        "                 min_num_clients=args.min_num_clients,\n",
        "                 log_host=args.log_host)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw5PO4qQDc0u",
        "outputId": "5c5b2dff-376e-4393-ce6f-da955010fbd8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile server.sh\n",
        "PYTHONUNBUFFERED=1 python3 server.py \\\n",
        "  --rounds=1 \\\n",
        "  --epochs=10 \\\n",
        "  --sample_fraction=1 \\\n",
        "  --min_sample_size=5 \\\n",
        "  --min_num_clients=5 \\\n",
        "  --server_address=\"localhost:8099\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okyLEn5U8n00",
        "outputId": "b14454fc-7ff0-41f3-e4f2-9bccc47dd7ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting server.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile clients.sh\n",
        "export PYTHONUNBUFFERED=1\n",
        "NUM_CLIENTS=10 # TODO: change the number of clients here\n",
        "\n",
        "\n",
        "echo \"Starting $NUM_CLIENTS clients.\"\n",
        "for ((i = 0; i < $NUM_CLIENTS; i++))\n",
        "do\n",
        "    echo \"Starting client(cid=$i) with partition $i out of $NUM_CLIENTS clients.\"\n",
        "    # Staggered loading of clients: clients are loaded 8s apart.\n",
        "    # At the start, each client loads the entire CIFAR-10 dataset before selecting\n",
        "    # their own partition. For a large number of clients this causes a memory usage\n",
        "    # spike that can cause client processes to get terminated. \n",
        "    # Staggered loading prevents this.\n",
        "    sleep 8s  \n",
        "    python3 client.py \\\n",
        "      --cid=$i \\\n",
        "      --num_partitions=${NUM_CLIENTS} \\\n",
        "      --iid_fraction=0.5 \\\n",
        "      --server_address=\"localhost:8099\" \\\n",
        "      --exp_name=\"federated_${NUM_CLIENTS}_clients\" &\n",
        "done\n",
        "echo \"Started $NUM_CLIENTS clients.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz1vsplG9M7s",
        "outputId": "f4046549-5e29-48a5-d8d4-0ae8509751a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting clients.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x clients.sh server.sh"
      ],
      "metadata": {
        "id": "XhhUR5jgFmfS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%killbgscripts\n",
        "!((./server.sh & sleep 5s); ./clients.sh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9sbudoNDuNo",
        "outputId": "e5fad8e1-1f1d-4135-fa2f-e645c281eb14"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All background processes were killed.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting gRPC server on localhost:8099...\n",
            "Fitting the model...\n",
            "INFO flower 2021-12-25 20:16:50,390 | server.py:118 | Initializing global parameters\n",
            "INFO flower 2021-12-25 20:16:50,390 | server.py:304 | Requesting initial parameters from one random client\n",
            "Starting 10 clients.\n",
            "Starting client(cid=0) with partition 0 out of 10 clients.\n",
            "Starting client(cid=1) with partition 1 out of 10 clients.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=2) with partition 2 out of 10 clients.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=3) with partition 3 out of 10 clients.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=4) with partition 4 out of 10 clients.\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=5) with partition 5 out of 10 clients.\n",
            "Files already downloaded and verified\n",
            "start global traning on Client 0\n",
            "Training from epoch(s) 0 to 10 w/ 26 batches each.\n",
            "TRAIN Epoch 0: 100% 26/26 [00:01<00:00, 23.60it/s, train_loss=0.0742, train_acc=0.0953]\n",
            "TRAIN Epoch 1: 100% 26/26 [00:01<00:00, 24.65it/s, train_loss=0.0742, train_acc=0.104]\n",
            "TRAIN Epoch 2: 100% 26/26 [00:01<00:00, 23.32it/s, train_loss=0.0741, train_acc=0.119]\n",
            "TRAIN Epoch 3: 100% 26/26 [00:01<00:00, 25.10it/s, train_loss=0.0741, train_acc=0.116]\n",
            "TRAIN Epoch 4:  88% 23/26 [00:00<00:00, 26.75it/s, train_loss=0.072, train_acc=0.121]Starting client(cid=6) with partition 6 out of 10 clients.\n",
            "TRAIN Epoch 4: 100% 26/26 [00:00<00:00, 26.55it/s, train_loss=0.0741, train_acc=0.119]\n",
            "TRAIN Epoch 5:  54% 14/26 [00:00<00:00, 21.80it/s, train_loss=0.0719, train_acc=0.121]Files already downloaded and verified\n",
            "TRAIN Epoch 5: 100% 26/26 [00:01<00:00, 21.57it/s, train_loss=0.0741, train_acc=0.119]\n",
            "TRAIN Epoch 6: 100% 26/26 [00:01<00:00, 21.63it/s, train_loss=0.0741, train_acc=0.119]\n",
            "TRAIN Epoch 7: 100% 26/26 [00:01<00:00, 21.79it/s, train_loss=0.074, train_acc=0.119]\n",
            "TRAIN Epoch 8: 100% 26/26 [00:01<00:00, 24.18it/s, train_loss=0.074, train_acc=0.119]\n",
            "TRAIN Epoch 9: 100% 26/26 [00:01<00:00, 22.50it/s, train_loss=0.074, train_acc=0.119]\n",
            "TRAIN Epoch 10:   0% 0/26 [00:00<?, ?it/s]Files already downloaded and verified\n",
            "TRAIN Epoch 10: 100% 26/26 [00:01<00:00, 21.77it/s, train_loss=0.074, train_acc=0.119]\n",
            "TEST: 100% 32/32 [00:00<00:00, 43.21it/s]\n",
            "global traning accuracy 0.05\n",
            "Starting client 0\n",
            "Client 0 running experiment None_iid-fraction_0.5\n",
            "Connecting to localhost:8099\n",
            "DEBUG flower 2021-12-25 20:17:47,133 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:17:47,134 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2021-12-25 20:17:47,150 | app.py:61 | Opened (insecure) gRPC connection\n",
            "Client 0: get_parameters\n",
            "INFO flower 2021-12-25 20:17:47,162 | server.py:307 | Received initial parameters from one random client\n",
            "INFO flower 2021-12-25 20:17:47,162 | server.py:120 | Evaluating initial parameters\n",
            "Starting client(cid=7) with partition 7 out of 10 clients.\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=8) with partition 8 out of 10 clients.\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=9) with partition 9 out of 10 clients.\n",
            "Files already downloaded and verified\n",
            "Started 10 clients.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "INFO flower 2021-12-25 20:18:18,290 | server.py:127 | initial parameters (loss, other metrics): 0.07205711369514466, {'accuracy': 0.1}\n",
            "INFO flower 2021-12-25 20:18:18,294 | server.py:133 | FL starting\n",
            "Configuring round 1...\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "start global traning on Client 1\n",
            "Training from epoch(s) 0 to 10 w/ 25 batches each.\n",
            "TRAIN Epoch 0: 100% 25/25 [00:02<00:00, 12.34it/s, train_loss=0.0724, train_acc=0.111]\n",
            "TRAIN Epoch 1: 100% 25/25 [00:01<00:00, 13.34it/s, train_loss=0.0723, train_acc=0.109]\n",
            "TRAIN Epoch 2: 100% 25/25 [00:01<00:00, 14.51it/s, train_loss=0.0723, train_acc=0.109]\n",
            "TRAIN Epoch 3: 100% 25/25 [00:01<00:00, 14.07it/s, train_loss=0.0723, train_acc=0.109]\n",
            "TRAIN Epoch 4: 100% 25/25 [00:01<00:00, 14.06it/s, train_loss=0.0722, train_acc=0.112]\n",
            "TRAIN Epoch 5: 100% 25/25 [00:01<00:00, 13.57it/s, train_loss=0.0722, train_acc=0.146]\n",
            "TRAIN Epoch 6: 100% 25/25 [00:01<00:00, 14.01it/s, train_loss=0.0721, train_acc=0.186]\n",
            "TRAIN Epoch 7: 100% 25/25 [00:01<00:00, 14.15it/s, train_loss=0.0721, train_acc=0.179]\n",
            "TRAIN Epoch 8: 100% 25/25 [00:01<00:00, 13.69it/s, train_loss=0.0721, train_acc=0.16]\n",
            "TRAIN Epoch 9: 100% 25/25 [00:01<00:00, 13.64it/s, train_loss=0.0721, train_acc=0.145]\n",
            "TRAIN Epoch 10: 100% 25/25 [00:01<00:00, 14.19it/s, train_loss=0.072, train_acc=0.142]\n",
            "TEST: 100% 32/32 [00:01<00:00, 29.78it/s]\n",
            "global traning accuracy 0.052\n",
            "Starting client 1\n",
            "Client 1 running experiment None_iid-fraction_0.5\n",
            "Connecting to localhost:8099\n",
            "DEBUG flower 2021-12-25 20:19:09,933 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:19:09,938 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2021-12-25 20:19:09,945 | app.py:61 | Opened (insecure) gRPC connection\n",
            "start global traning on Client 2\n",
            "Training from epoch(s) 0 to 10 w/ 25 batches each.\n",
            "TRAIN Epoch 0: 100% 25/25 [00:01<00:00, 13.45it/s, train_loss=0.0725, train_acc=0.108]\n",
            "TRAIN Epoch 1: 100% 25/25 [00:01<00:00, 15.24it/s, train_loss=0.0725, train_acc=0.119]\n",
            "TRAIN Epoch 2: 100% 25/25 [00:01<00:00, 15.12it/s, train_loss=0.0725, train_acc=0.121]\n",
            "TRAIN Epoch 3: 100% 25/25 [00:01<00:00, 15.18it/s, train_loss=0.0725, train_acc=0.124]\n",
            "TRAIN Epoch 4: 100% 25/25 [00:01<00:00, 15.32it/s, train_loss=0.0725, train_acc=0.121]\n",
            "TRAIN Epoch 5: 100% 25/25 [00:01<00:00, 15.03it/s, train_loss=0.0725, train_acc=0.121]\n",
            "TRAIN Epoch 6: 100% 25/25 [00:01<00:00, 15.22it/s, train_loss=0.0724, train_acc=0.12]\n",
            "TRAIN Epoch 7: 100% 25/25 [00:01<00:00, 15.34it/s, train_loss=0.0724, train_acc=0.121]\n",
            "TRAIN Epoch 8: 100% 25/25 [00:01<00:00, 14.82it/s, train_loss=0.0724, train_acc=0.121]\n",
            "TRAIN Epoch 9: 100% 25/25 [00:01<00:00, 15.14it/s, train_loss=0.0724, train_acc=0.121]\n",
            "TRAIN Epoch 10: 100% 25/25 [00:01<00:00, 15.60it/s, train_loss=0.0724, train_acc=0.121]\n",
            "TEST: 100% 32/32 [00:01<00:00, 29.24it/s]\n",
            "global traning accuracy 0.052\n",
            "Starting client 2\n",
            "Client 2 running experiment None_iid-fraction_0.5\n",
            "Connecting to localhost:8099\n",
            "DEBUG flower 2021-12-25 20:19:50,167 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:19:50,171 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2021-12-25 20:19:50,174 | app.py:61 | Opened (insecure) gRPC connection\n",
            "start global traning on Client 3\n",
            "Training from epoch(s) 0 to 10 w/ 26 batches each.\n",
            "TRAIN Epoch 0: 100% 26/26 [00:01<00:00, 16.82it/s, train_loss=0.0742, train_acc=0.099]\n",
            "TRAIN Epoch 1: 100% 26/26 [00:01<00:00, 21.61it/s, train_loss=0.0742, train_acc=0.0978]\n",
            "TRAIN Epoch 2: 100% 26/26 [00:01<00:00, 20.66it/s, train_loss=0.0742, train_acc=0.0978]\n",
            "TRAIN Epoch 3: 100% 26/26 [00:01<00:00, 20.52it/s, train_loss=0.0741, train_acc=0.0978]\n",
            "TRAIN Epoch 4: 100% 26/26 [00:01<00:00, 20.71it/s, train_loss=0.0741, train_acc=0.0978]\n",
            "TRAIN Epoch 5: 100% 26/26 [00:01<00:00, 23.61it/s, train_loss=0.0741, train_acc=0.099]\n",
            "TRAIN Epoch 6: 100% 26/26 [00:01<00:00, 20.52it/s, train_loss=0.0741, train_acc=0.0978]\n",
            "TRAIN Epoch 7: 100% 26/26 [00:01<00:00, 21.17it/s, train_loss=0.0741, train_acc=0.1]\n",
            "TRAIN Epoch 8: 100% 26/26 [00:01<00:00, 21.26it/s, train_loss=0.074, train_acc=0.108]\n",
            "TRAIN Epoch 9: 100% 26/26 [00:01<00:00, 22.30it/s, train_loss=0.074, train_acc=0.134]\n",
            "TRAIN Epoch 10: 100% 26/26 [00:01<00:00, 23.21it/s, train_loss=0.074, train_acc=0.151]\n",
            "TEST: 100% 32/32 [00:00<00:00, 44.27it/s]\n",
            "global traning accuracy 0.187\n",
            "Starting client 3\n",
            "Client 3 running experiment None_iid-fraction_0.5\n",
            "Connecting to localhost:8099\n",
            "DEBUG flower 2021-12-25 20:20:13,995 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:20:13,997 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2021-12-25 20:20:14,007 | app.py:61 | Opened (insecure) gRPC connection\n",
            "start global traning on Client 5\n",
            "Training from epoch(s) 0 to 10 w/ 25 batches each.\n",
            "TRAIN Epoch 0: 100% 25/25 [00:01<00:00, 21.25it/s, train_loss=0.0719, train_acc=0.101]\n",
            "TRAIN Epoch 1: 100% 25/25 [00:01<00:00, 23.13it/s, train_loss=0.0719, train_acc=0.101]\n",
            "TRAIN Epoch 2: 100% 25/25 [00:00<00:00, 26.72it/s, train_loss=0.0718, train_acc=0.104]\n",
            "TRAIN Epoch 3: 100% 25/25 [00:00<00:00, 27.59it/s, train_loss=0.0718, train_acc=0.117]\n",
            "TRAIN Epoch 4: 100% 25/25 [00:00<00:00, 25.09it/s, train_loss=0.0718, train_acc=0.128]\n",
            "TRAIN Epoch 5:  96% 24/25 [00:01<00:00, 22.81it/s, train_loss=0.0718, train_acc=0.141]start global traning on Client 6\n",
            "Training from epoch(s) 0 to 10 w/ 26 batches each.\n",
            "TRAIN Epoch 5: 100% 25/25 [00:01<00:00, 23.38it/s, train_loss=0.0718, train_acc=0.141]\n",
            "TRAIN Epoch 6: 100% 25/25 [00:01<00:00, 24.01it/s, train_loss=0.0718, train_acc=0.145]\n",
            "TRAIN Epoch 0: 100% 26/26 [00:01<00:00, 21.70it/s, train_loss=0.0748, train_acc=0.0999]\n",
            "TRAIN Epoch 7: 100% 25/25 [00:00<00:00, 25.53it/s, train_loss=0.0718, train_acc=0.154]\n",
            "TRAIN Epoch 1: 100% 26/26 [00:01<00:00, 22.73it/s, train_loss=0.0748, train_acc=0.0999]\n",
            "TRAIN Epoch 8: 100% 25/25 [00:01<00:00, 23.17it/s, train_loss=0.0717, train_acc=0.158]\n",
            "TRAIN Epoch 2: 100% 26/26 [00:01<00:00, 23.82it/s, train_loss=0.0747, train_acc=0.0999]\n",
            "TRAIN Epoch 9: 100% 25/25 [00:01<00:00, 21.32it/s, train_loss=0.0717, train_acc=0.159]\n",
            "TRAIN Epoch 3: 100% 26/26 [00:01<00:00, 22.13it/s, train_loss=0.0747, train_acc=0.0999]\n",
            "TRAIN Epoch 10:  36% 9/25 [00:00<00:00, 20.96it/s, train_loss=0.0718, train_acc=0.153]start global traning on Client 7\n",
            "TRAIN Epoch 10:  36% 9/25 [00:00<00:00, 20.96it/s, train_loss=0.0718, train_acc=0.161]Training from epoch(s) 0 to 10 w/ 25 batches each.\n",
            "TRAIN Epoch 10: 100% 25/25 [00:01<00:00, 23.40it/s, train_loss=0.0717, train_acc=0.16]\n",
            "TRAIN Epoch 4: 100% 26/26 [00:01<00:00, 23.94it/s, train_loss=0.0748, train_acc=0.104]\n",
            "TRAIN Epoch 0: 100% 25/25 [00:01<00:00, 22.57it/s, train_loss=0.0726, train_acc=0.115]\n",
            "TEST: 100% 32/32 [00:00<00:00, 46.68it/s]\n",
            "global traning accuracy 0.201\n",
            "Starting client 5\n",
            "Client 5 running experiment None_iid-fraction_0.5\n",
            "Connecting to localhost:8099\n",
            "TRAIN Epoch 5:  23% 6/26 [00:00<00:00, 22.52it/s, train_loss=0.072, train_acc=0.105]DEBUG flower 2021-12-25 20:20:30,294 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:20:30,298 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2021-12-25 20:20:30,303 | app.py:61 | Opened (insecure) gRPC connection\n",
            "DEBUG flower 2021-12-25 20:20:30,305 | server.py:255 | fit_round: strategy sampled 5 clients (out of 5)\n",
            "TRAIN Epoch 5:  23% 6/26 [00:00<00:00, 22.52it/s, train_loss=0.0719, train_acc=0.111]Client 1: fit\n",
            "TRAIN Epoch 5:  35% 9/26 [00:00<00:00, 23.01it/s, train_loss=0.0719, train_acc=0.111]Training from epoch(s) 1 to 10 w/ 137 batches each.\n",
            "Client 5: fit\n",
            "TRAIN Epoch 1:   0% 0/137 [00:00<?, ?it/s]Training from epoch(s) 1 to 10 w/ 138 batches each.\n",
            "TRAIN Epoch 1:   0% 0/138 [00:00<?, ?it/s]Client 3: fit\n",
            "TRAIN Epoch 1:  12% 3/25 [00:00<00:00, 23.44it/s, train_loss=0.0723, train_acc=0.0938]Training from epoch(s) 1 to 10 w/ 139 batches each.Client 2: fit\n",
            "\n",
            "TRAIN Epoch 1:   0% 0/139 [00:00<?, ?it/s]Training from epoch(s) 1 to 10 w/ 137 batches each.\n",
            "TRAIN Epoch 1:   0% 0/137 [00:00<?, ?it/s]Client 0: fit\n",
            "TRAIN Epoch 5:  35% 9/26 [00:00<00:00, 23.01it/s, train_loss=0.0719, train_acc=0.109]Training from epoch(s) 1 to 10 w/ 139 batches each.\n",
            "TRAIN Epoch 5: 100% 26/26 [00:01<00:00, 14.88it/s, train_loss=0.0748, train_acc=0.115]\n",
            "TRAIN Epoch 1: 100% 25/25 [00:01<00:00, 13.74it/s, train_loss=0.0726, train_acc=0.126]\n",
            "TRAIN Epoch 6: 100% 26/26 [00:01<00:00, 13.41it/s, train_loss=0.0747, train_acc=0.121]\n",
            "TRAIN Epoch 2: 100% 25/25 [00:01<00:00, 13.16it/s, train_loss=0.0726, train_acc=0.127]\n",
            "TRAIN Epoch 7: 100% 26/26 [00:01<00:00, 13.21it/s, train_loss=0.0746, train_acc=0.127]\n",
            "TRAIN Epoch 3: 100% 25/25 [00:01<00:00, 13.56it/s, train_loss=0.0726, train_acc=0.113]\n",
            "TRAIN Epoch 1:  54% 74/137 [00:06<00:04, 12.74it/s, train_loss=0.0631, train_acc=0.671]start global traning on Client 8\n",
            "Training from epoch(s) 0 to 10 w/ 25 batches each.\n",
            "TRAIN Epoch 8: 100% 26/26 [00:01<00:00, 13.78it/s, train_loss=0.0746, train_acc=0.132]\n",
            "TRAIN Epoch 4: 100% 25/25 [00:01<00:00, 13.33it/s, train_loss=0.0726, train_acc=0.121]\n",
            "TRAIN Epoch 0: 100% 25/25 [00:02<00:00, 11.70it/s, train_loss=0.0721, train_acc=0.0951]\n",
            "TRAIN Epoch 9: 100% 26/26 [00:01<00:00, 13.59it/s, train_loss=0.0747, train_acc=0.116]\n",
            "TRAIN Epoch 5: 100% 25/25 [00:01<00:00, 13.30it/s, train_loss=0.0725, train_acc=0.129]\n",
            "TRAIN Epoch 1: 100% 25/25 [00:01<00:00, 13.09it/s, train_loss=0.0721, train_acc=0.0876]\n",
            "TRAIN Epoch 1: 100% 137/137 [00:10<00:00, 13.02it/s, train_loss=0.0412, train_acc=0.81]\n",
            "TRAIN Epoch 1: 100% 138/138 [00:10<00:00, 12.99it/s, train_loss=0.0419, train_acc=0.808]\n",
            "TRAIN Epoch 1: 100% 137/137 [00:10<00:00, 12.73it/s, train_loss=0.0477, train_acc=0.781]\n",
            "TRAIN Epoch 1: 100% 139/139 [00:10<00:00, 12.80it/s, train_loss=0.0493, train_acc=0.745]\n",
            "TRAIN Epoch 1: 100% 139/139 [00:10<00:00, 12.83it/s, train_loss=0.0373, train_acc=0.822]\n",
            "TRAIN Epoch 6: 100% 25/25 [00:01<00:00, 13.81it/s, train_loss=0.0725, train_acc=0.11]\n",
            "TRAIN Epoch 2:   3% 4/137 [00:00<00:09, 13.45it/s, train_loss=0.0173, train_acc=0.896]\n",
            "TRAIN Epoch 2: 100% 25/25 [00:01<00:00, 13.50it/s, train_loss=0.072, train_acc=0.0914]\n",
            "TEST: 100% 32/32 [00:01<00:00, 26.30it/s]\n",
            "global traning accuracy 0.157\n",
            "Starting client 6\n",
            "Client 6 running experiment None_iid-fraction_0.5\n",
            "Connecting to localhost:8099\n",
            "TRAIN Epoch 7:  64% 16/25 [00:01<00:00, 12.77it/s, train_loss=0.0719, train_acc=0.118]DEBUG flower 2021-12-25 20:20:42,607 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:20:42,612 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2021-12-25 20:20:42,618 | app.py:61 | Opened (insecure) gRPC connection\n",
            "TRAIN Epoch 7: 100% 25/25 [00:01<00:00, 13.59it/s, train_loss=0.0725, train_acc=0.112]\n",
            "TRAIN Epoch 2:  24% 33/138 [00:02<00:07, 14.75it/s, train_loss=0.0153, train_acc=0.912]start global traning on Client 9\n",
            "TRAIN Epoch 2:  25% 35/138 [00:02<00:06, 15.09it/s, train_loss=0.0153, train_acc=0.912]Training from epoch(s) 0 to 10 w/ 25 batches each.\n",
            "TRAIN Epoch 2:  34% 46/137 [00:03<00:05, 15.94it/s, train_loss=0.0138, train_acc=0.919]\n",
            "TRAIN Epoch 8: 100% 25/25 [00:01<00:00, 16.32it/s, train_loss=0.0725, train_acc=0.116]\n",
            "TRAIN Epoch 0: 100% 25/25 [00:02<00:00, 12.23it/s, train_loss=0.0723, train_acc=0.0841]\n",
            "TRAIN Epoch 4: 100% 25/25 [00:01<00:00, 15.33it/s, train_loss=0.072, train_acc=0.13]\n",
            "TRAIN Epoch 9: 100% 25/25 [00:01<00:00, 14.87it/s, train_loss=0.0725, train_acc=0.117]\n",
            "TRAIN Epoch 1: 100% 25/25 [00:01<00:00, 15.37it/s, train_loss=0.0723, train_acc=0.0816]\n",
            "TRAIN Epoch 5: 100% 25/25 [00:01<00:00, 15.36it/s, train_loss=0.0719, train_acc=0.13]\n",
            "TRAIN Epoch 10: 100% 25/25 [00:01<00:00, 16.00it/s, train_loss=0.0725, train_acc=0.119]\n",
            "TRAIN Epoch 2: 100% 25/25 [00:01<00:00, 16.03it/s, train_loss=0.0723, train_acc=0.104]\n",
            "TEST: 100% 32/32 [00:01<00:00, 31.98it/s]\n",
            "global traning accuracy 0.141\n",
            "Starting client 7\n",
            "Client 7 running experiment None_iid-fraction_0.5\n",
            "Connecting to localhost:8099\n",
            "TRAIN Epoch 6:  96% 24/25 [00:01<00:00, 15.59it/s, train_loss=0.0719, train_acc=0.13] DEBUG flower 2021-12-25 20:20:49,080 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:20:49,081 | connection.py:36 | ChannelConnectivity.CONNECTING\n",
            "TRAIN Epoch 6: 100% 25/25 [00:01<00:00, 15.07it/s, train_loss=0.0719, train_acc=0.13]DEBUG flower 2021-12-25 20:20:49,085 | connection.py:36 | ChannelConnectivity.READY\n",
            "TRAIN Epoch 3:   8% 2/25 [00:00<00:01, 14.56it/s, train_loss=0.0722, train_acc=0.109] \n",
            "TRAIN Epoch 2:  83% 114/137 [00:07<00:01, 15.93it/s, train_loss=0.0156, train_acc=0.917]INFO flower 2021-12-25 20:20:49,102 | app.py:61 | Opened (insecure) gRPC connection\n",
            "TRAIN Epoch 2: 100% 137/137 [00:09<00:00, 15.16it/s, train_loss=0.0137, train_acc=0.919]\n",
            "TRAIN Epoch 2: 100% 138/138 [00:09<00:00, 15.02it/s, train_loss=0.0143, train_acc=0.918]\n",
            "TRAIN Epoch 2: 100% 137/137 [00:09<00:00, 15.09it/s, train_loss=0.0152, train_acc=0.919]\n",
            "TRAIN Epoch 2:  98% 136/139 [00:09<00:00, 17.54it/s, train_loss=0.0148, train_acc=0.918]\n",
            "TRAIN Epoch 2: 100% 139/139 [00:09<00:00, 15.16it/s, train_loss=0.0148, train_acc=0.918]\n",
            "TRAIN Epoch 7: 100% 25/25 [00:01<00:00, 17.36it/s, train_loss=0.0719, train_acc=0.13]\n",
            "TRAIN Epoch 2: 100% 139/139 [00:09<00:00, 15.04it/s, train_loss=0.0139, train_acc=0.917]\n",
            "TRAIN Epoch 4: 100% 25/25 [00:01<00:00, 17.28it/s, train_loss=0.0722, train_acc=0.12]\n",
            "TRAIN Epoch 8: 100% 25/25 [00:01<00:00, 17.77it/s, train_loss=0.0719, train_acc=0.13]\n",
            "TRAIN Epoch 5: 100% 25/25 [00:01<00:00, 17.62it/s, train_loss=0.0722, train_acc=0.12]\n",
            "TRAIN Epoch 9: 100% 25/25 [00:01<00:00, 16.51it/s, train_loss=0.0719, train_acc=0.13]\n",
            "TRAIN Epoch 6: 100% 25/25 [00:01<00:00, 16.86it/s, train_loss=0.0722, train_acc=0.12]\n",
            "TRAIN Epoch 10: 100% 25/25 [00:01<00:00, 17.32it/s, train_loss=0.0718, train_acc=0.13]\n",
            "TEST: 100% 32/32 [00:00<00:00, 35.16it/s]\n",
            "global traning accuracy 0.159\n",
            "Starting client 8\n",
            "Client 8 running experiment None_iid-fraction_0.5\n",
            "Connecting to localhost:8099\n",
            "TRAIN Epoch 3:  64% 89/139 [00:05<00:02, 16.89it/s, train_loss=0.0133, train_acc=0.919]DEBUG flower 2021-12-25 20:20:55,856 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:20:55,858 | connection.py:36 | ChannelConnectivity.READY\n",
            "TRAIN Epoch 3:  65% 90/139 [00:05<00:02, 17.43it/s, train_loss=0.0144, train_acc=0.919]INFO flower 2021-12-25 20:20:55,865 | app.py:61 | Opened (insecure) gRPC connection\n",
            "TRAIN Epoch 7: 100% 25/25 [00:01<00:00, 17.24it/s, train_loss=0.0722, train_acc=0.12]\n",
            "TRAIN Epoch 8: 100% 25/25 [00:01<00:00, 19.89it/s, train_loss=0.0722, train_acc=0.12]\n",
            "TRAIN Epoch 3: 100% 137/137 [00:07<00:00, 17.94it/s, train_loss=0.0133, train_acc=0.919]\n",
            "TRAIN Epoch 3: 100% 138/138 [00:07<00:00, 17.72it/s, train_loss=0.014, train_acc=0.918]\n",
            "TRAIN Epoch 3: 100% 137/137 [00:07<00:00, 17.62it/s, train_loss=0.0149, train_acc=0.919]\n",
            "TRAIN Epoch 3: 100% 139/139 [00:07<00:00, 18.04it/s, train_loss=0.0145, train_acc=0.918]\n",
            "TRAIN Epoch 3: 100% 139/139 [00:07<00:00, 17.95it/s, train_loss=0.0135, train_acc=0.917]\n",
            "TRAIN Epoch 9: 100% 25/25 [00:01<00:00, 19.73it/s, train_loss=0.0721, train_acc=0.12]\n",
            "TRAIN Epoch 10: 100% 25/25 [00:01<00:00, 19.35it/s, train_loss=0.0721, train_acc=0.12]\n",
            "TRAIN Epoch 4:  39% 54/137 [00:02<00:04, 19.20it/s, train_loss=0.0158, train_acc=0.911]\n",
            "global traning accuracy 0.147\n",
            "Starting client 9\n",
            "Client 9 running experiment None_iid-fraction_0.5\n",
            "Connecting to localhost:8099\n",
            "TRAIN Epoch 4:  46% 63/137 [00:03<00:03, 20.03it/s, train_loss=0.0122, train_acc=0.925]DEBUG flower 2021-12-25 20:21:00,783 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:21:00,786 | connection.py:36 | ChannelConnectivity.READY\n",
            "TRAIN Epoch 4:  40% 55/139 [00:02<00:04, 19.28it/s, train_loss=0.0136, train_acc=0.923]INFO flower 2021-12-25 20:21:00,795 | app.py:61 | Opened (insecure) gRPC connection\n",
            "TRAIN Epoch 4: 100% 137/137 [00:06<00:00, 21.63it/s, train_loss=0.0131, train_acc=0.919]\n",
            "TRAIN Epoch 4: 100% 137/137 [00:05<00:00, 23.13it/s, train_loss=0.0145, train_acc=0.919]\n",
            "TRAIN Epoch 4: 100% 138/138 [00:06<00:00, 22.04it/s, train_loss=0.0138, train_acc=0.918]\n",
            "TRAIN Epoch 4: 100% 139/139 [00:06<00:00, 22.81it/s, train_loss=0.0142, train_acc=0.918]\n",
            "TRAIN Epoch 4: 100% 139/139 [00:06<00:00, 22.39it/s, train_loss=0.0133, train_acc=0.917]\n",
            "TRAIN Epoch 5: 100% 137/137 [00:05<00:00, 24.32it/s, train_loss=0.0128, train_acc=0.919]\n",
            "TRAIN Epoch 5: 100% 137/137 [00:05<00:00, 24.44it/s, train_loss=0.0145, train_acc=0.919]\n",
            "TRAIN Epoch 5: 100% 139/139 [00:05<00:00, 25.76it/s, train_loss=0.0141, train_acc=0.918]\n",
            "TRAIN Epoch 5: 100% 138/138 [00:05<00:00, 25.17it/s, train_loss=0.0137, train_acc=0.918]\n",
            "TRAIN Epoch 5: 100% 139/139 [00:05<00:00, 24.80it/s, train_loss=0.0132, train_acc=0.917]\n",
            "TRAIN Epoch 6: 100% 137/137 [00:05<00:00, 24.14it/s, train_loss=0.0126, train_acc=0.919]\n",
            "TRAIN Epoch 7:   0% 0/137 [00:00<?, ?it/s, train_loss=0.00933, train_acc=0.938]\n",
            "TRAIN Epoch 6: 100% 137/137 [00:05<00:00, 23.94it/s, train_loss=0.0143, train_acc=0.919]\n",
            "TRAIN Epoch 6: 100% 139/139 [00:05<00:00, 24.24it/s, train_loss=0.014, train_acc=0.918]\n",
            "TRAIN Epoch 6: 100% 139/139 [00:05<00:00, 23.66it/s, train_loss=0.0131, train_acc=0.917]\n",
            "TRAIN Epoch 7: 100% 138/138 [00:05<00:00, 24.31it/s, train_loss=0.0136, train_acc=0.918]\n",
            "TRAIN Epoch 7: 100% 137/137 [00:05<00:00, 23.84it/s, train_loss=0.0124, train_acc=0.919]\n",
            "TRAIN Epoch 7: 100% 137/137 [00:05<00:00, 24.21it/s, train_loss=0.0143, train_acc=0.919]\n",
            "TRAIN Epoch 7: 100% 139/139 [00:05<00:00, 23.75it/s, train_loss=0.0139, train_acc=0.918]\n",
            "TRAIN Epoch 7: 100% 139/139 [00:06<00:00, 23.04it/s, train_loss=0.0131, train_acc=0.917]\n",
            "TRAIN Epoch 8: 100% 138/138 [00:05<00:00, 26.08it/s, train_loss=0.0135, train_acc=0.918]\n",
            "TRAIN Epoch 8: 100% 137/137 [00:05<00:00, 24.17it/s, train_loss=0.0122, train_acc=0.919]\n",
            "TRAIN Epoch 8: 100% 137/137 [00:05<00:00, 23.66it/s, train_loss=0.0143, train_acc=0.919]\n",
            "TRAIN Epoch 8: 100% 139/139 [00:05<00:00, 24.12it/s, train_loss=0.0138, train_acc=0.918]\n",
            "TRAIN Epoch 8: 100% 139/139 [00:05<00:00, 23.82it/s, train_loss=0.0131, train_acc=0.917]\n",
            "TRAIN Epoch 9: 100% 138/138 [00:05<00:00, 24.71it/s, train_loss=0.0134, train_acc=0.918]\n",
            "TRAIN Epoch 9: 100% 137/137 [00:05<00:00, 23.99it/s, train_loss=0.0121, train_acc=0.919]\n",
            "TRAIN Epoch 9: 100% 137/137 [00:05<00:00, 23.82it/s, train_loss=0.0142, train_acc=0.919]\n",
            "TRAIN Epoch 9: 100% 139/139 [00:05<00:00, 23.51it/s, train_loss=0.0137, train_acc=0.918]\n",
            "TRAIN Epoch 9: 100% 139/139 [00:06<00:00, 23.16it/s, train_loss=0.013, train_acc=0.917]\n",
            "TRAIN Epoch 10: 100% 138/138 [00:05<00:00, 23.87it/s, train_loss=0.0133, train_acc=0.918]\n",
            "Client 5: train_loss=0.0133, train_accuracy=0.9184\n",
            "TRAIN Epoch 10: 100% 137/137 [00:05<00:00, 25.06it/s, train_loss=0.012, train_acc=0.919]\n",
            "Client 1: train_loss=0.0120, train_accuracy=0.9195\n",
            "TRAIN Epoch 10: 100% 137/137 [00:05<00:00, 24.61it/s, train_loss=0.0142, train_acc=0.919]\n",
            "Client 2: train_loss=0.0142, train_accuracy=0.9193\n",
            "TRAIN Epoch 10: 100% 139/139 [00:05<00:00, 25.71it/s, train_loss=0.0137, train_acc=0.918]\n",
            "Client 3: train_loss=0.0137, train_accuracy=0.9179\n",
            "TRAIN Epoch 10: 100% 139/139 [00:04<00:00, 29.16it/s, train_loss=0.013, train_acc=0.917]\n",
            "Client 0: train_loss=0.0130, train_accuracy=0.9170\n",
            "DEBUG flower 2021-12-25 20:21:38,618 | server.py:264 | fit_round received 5 results and 0 failures\n",
            "INFO flower 2021-12-25 20:21:42,480 | server.py:154 | fit progress: (1, 0.07297969717979431, {'accuracy': 0.1527}, 204.18470079299732)\n",
            "INFO flower 2021-12-25 20:21:42,480 | server.py:199 | evaluate_round: no clients selected, cancel\n",
            "INFO flower 2021-12-25 20:21:42,480 | server.py:172 | FL finished in 204.18511244399997\n",
            "INFO flower 2021-12-25 20:21:42,481 | server.py:70 | app_fit: losses_centralized=[(0, 0.07205711369514466), (1, 0.07297969717979431)]\n",
            "INFO flower 2021-12-25 20:21:42,481 | server.py:71 | app_fit: accuracies_centralized=[(0, 0.1), (1, 0.1527)]\n",
            "Server-side test results after training: test_loss=0.0730, test_accuracy=0.1527\n",
            "Configuring round -1...\n",
            "DEBUG flower 2021-12-25 20:21:46,239 | server.py:205 | evaluate_round: strategy sampled 9 clients (out of 9)\n",
            "Client 1: evaluate\n",
            "Client 0: evaluate\n",
            "Client 2: evaluate\n",
            "Client 3: evaluate\n",
            "Client 5: evaluate\n",
            "Client 6: evaluate\n",
            "Client 7: evaluate\n",
            "Client 8: evaluate\n",
            "Client 9: evaluate\n",
            "Client 1: test_loss=0.0723, test_accuracy=0.2120\n",
            "Client 3: test_loss=0.0726, test_accuracy=0.1820\n",
            "Client 2: test_loss=0.0724, test_accuracy=0.2310\n",
            "Client 0: test_loss=0.0727, test_accuracy=0.2030\n",
            "Client 7: test_loss=0.0768, test_accuracy=0.1080\n",
            "Client 8: test_loss=0.0771, test_accuracy=0.0950\n",
            "Client 5: test_loss=0.0770, test_accuracy=0.1020\n",
            "Client 6: test_loss=0.0768, test_accuracy=0.0940\n",
            "Client 9: test_loss=0.0766, test_accuracy=0.0940\n",
            "DEBUG flower 2021-12-25 20:21:47,387 | server.py:214 | evaluate_round received 9 results and 0 failures\n",
            "INFO flower 2021-12-25 20:21:47,387 | server.py:85 | app_evaluate: federated loss: 0.07491406053304672\n",
            "INFO flower 2021-12-25 20:21:47,387 | server.py:86 | app_evaluate: metrics: {}\n",
            "INFO flower 2021-12-25 20:21:47,388 | server.py:87 | app_evaluate: results [('ipv4:127.0.0.1:47866', EvaluateRes(loss=0.07265352457761765, num_examples=1000, accuracy=0.2029999941587448, metrics={})), ('ipv4:127.0.0.1:48218', EvaluateRes(loss=0.07225301861763, num_examples=1000, accuracy=0.21199999749660492, metrics={})), ('ipv4:127.0.0.1:48446', EvaluateRes(loss=0.07239441573619843, num_examples=1000, accuracy=0.23100000619888306, metrics={})), ('ipv4:127.0.0.1:48612', EvaluateRes(loss=0.07263049483299255, num_examples=1000, accuracy=0.18199999630451202, metrics={})), ('ipv4:127.0.0.1:48742', EvaluateRes(loss=0.07704015076160431, num_examples=1000, accuracy=0.10199999809265137, metrics={})), ('ipv4:127.0.0.1:48886', EvaluateRes(loss=0.07680224627256393, num_examples=1000, accuracy=0.09399999678134918, metrics={})), ('ipv4:127.0.0.1:48954', EvaluateRes(loss=0.07680785655975342, num_examples=1000, accuracy=0.1080000028014183, metrics={})), ('ipv4:127.0.0.1:49042', EvaluateRes(loss=0.0770854502916336, num_examples=1000, accuracy=0.0949999988079071, metrics={})), ('ipv4:127.0.0.1:49088', EvaluateRes(loss=0.0765593871474266, num_examples=1000, accuracy=0.09399999678134918, metrics={}))]\n",
            "INFO flower 2021-12-25 20:21:47,388 | server.py:88 | app_evaluate: failures []\n",
            "DEBUG flower 2021-12-25 20:21:47,394 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 0: shutdown\n",
            "DEBUG flower 2021-12-25 20:21:47,395 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:21:47,397 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:21:47,397 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:21:47,397 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:21:47,406 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:21:47,406 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:21:47,396 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:21:47,397 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2021-12-25 20:21:47,599 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 2: shutdown\n",
            "DEBUG flower 2021-12-25 20:21:47,602 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 7: shutdownDEBUG flower 2021-12-25 20:21:47,603 | connection.py:68 | Insecure gRPC channel closed\n",
            "DEBUG flower 2021-12-25 20:21:47,603 | connection.py:68 | Insecure gRPC channel closed\n",
            "DEBUG flower 2021-12-25 20:21:47,603 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 8: shutdownClient 6: shutdown\n",
            "Client 1: shutdown\n",
            "\n",
            "\n",
            "DEBUG flower 2021-12-25 20:21:47,607 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 5: shutdown\n",
            "DEBUG flower 2021-12-25 20:21:47,608 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 9: shutdown\n",
            "DEBUG flower 2021-12-25 20:21:47,609 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 3: shutdown\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Server-side test results after training: test_loss=0.0734, test_accuracy=0.1000\n",
        "Server-side test results after training: test_loss=0.0730, test_accuracy=0.1527"
      ],
      "metadata": {
        "id": "FmAQi52wIOcs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
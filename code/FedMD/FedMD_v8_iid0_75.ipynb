{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FedMD-v8-iid0.75.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install flwr==0.17.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox6LThsZqEOp",
        "outputId": "bca7ac87-1a4c-48c1-f06c-e1280ebdb789"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flwr==0.17.0\n",
            "  Downloading flwr-0.17.0-py3-none-any.whl (229 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 34.3 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 30 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 40 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 51 kB 18.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 61 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 71 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 81 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 92 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 102 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 112 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 122 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 133 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 143 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 153 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 163 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 174 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 184 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 194 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 204 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 215 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 225 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 229 kB 13.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0.0,>=1.27.2 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (1.43.0)\n",
            "Requirement already satisfied: google<3.0.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (2.0.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (1.19.5)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.12.1 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (3.17.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google<3.0.0,>=2.0.3->flwr==0.17.0) (4.6.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<2.0.0,>=1.27.2->flwr==0.17.0) (1.15.0)\n",
            "Installing collected packages: flwr\n",
            "Successfully installed flwr-0.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f59qPirLpmMI",
        "outputId": "ade31982-c671-4b84-e721-a2b8b282c9f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Neural_Networks.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile Neural_Networks.py\n",
        "from tensorflow.keras.models import Model, Sequential, clone_model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, add, concatenate, Conv2D,Dropout,\\\n",
        "BatchNormalization, Flatten, MaxPooling2D, AveragePooling2D, Activation, Dropout, Reshape\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "  \n",
        "# def cnn_2layer_fc_model(n_classes,n1 = 128, n2=256, dropout_rate = 0.2,input_shape = (28,28)):\n",
        "#    model_A, x = None, None\n",
        "\n",
        "def cnn_2layer_fc_model(n_classes,n1 = 128, n2=256, dropout_rate = 0.2,input_shape = (32, 32, 3)):\n",
        "    model_A, x = None, None\n",
        "    input_shape = (32, 32, 3)\n",
        "    x = Input((32, 32, 3))\n",
        "    if len(input_shape)==2: \n",
        "        y = Reshape((input_shape[0], input_shape[1], 1))(x)\n",
        "    else:\n",
        "        y = Reshape(input_shape)(x)\n",
        "    y = Conv2D(filters = 6, kernel_size = 5)(y)\n",
        "    # y = BatchNormalization()(y)\n",
        "    y = Activation(\"relu\")(y)\n",
        "    # y = Dropout(dropout_rate)(y)\n",
        "    y = MaxPooling2D(2,2)(y)\n",
        "\n",
        "\n",
        "    y = Conv2D(filters = 16, kernel_size = 5)(y)\n",
        "    # y = BatchNormalization()(y)\n",
        "    y = Activation(\"relu\")(y)\n",
        "    # y = Dropout(dropout_rate)(y)\n",
        "    #y = AveragePooling2D(pool_size = (2,2), strides = 2, padding = \"valid\")(y)\n",
        "    y = MaxPooling2D(2,2)(y)\n",
        "\n",
        "    y = Flatten()(y)\n",
        "    y = Dense(120)(y)\n",
        "    y = Dense(84)(y)\n",
        "    y = Dense(10)(y)\n",
        "    y = Activation(\"softmax\")(y)\n",
        "\n",
        "\n",
        "    model_A = Model(inputs = x, outputs = y)\n",
        "\n",
        "    model_A.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-3), \n",
        "                        loss = \"sparse_categorical_crossentropy\",\n",
        "                        metrics = [\"accuracy\"])\n",
        "    return model_A\n",
        "\n",
        "\n",
        "def remove_last_layer(model, loss = \"mean_absolute_error\"):\n",
        "    \"\"\"\n",
        "    Input: Keras model, a classification model whose last layer is a softmax activation\n",
        "    Output: Keras model, the same model with the last softmax activation layer removed,\n",
        "        while keeping the same parameters \n",
        "    \"\"\"\n",
        "    \n",
        "    new_model = Model(inputs = model.inputs, outputs = model.layers[-2].output)\n",
        "    new_model.set_weights(model.get_weights())\n",
        "    new_model.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-3), \n",
        "                      loss = loss)\n",
        "    \n",
        "    return new_model\n",
        "\n",
        "\n",
        "\n",
        "def train_models(models, X_train, y_train, X_test, y_test, \n",
        "                 save_dir = \"./\", save_names = None,\n",
        "                 early_stopping = True, min_delta = 0.001, patience = 3, \n",
        "                 batch_size = 128, epochs = 10, is_shuffle=True, verbose = 1\n",
        "                ):\n",
        "    '''\n",
        "    Train an array of models on the same dataset. \n",
        "    We use early termination to speed up training. \n",
        "    '''\n",
        "    \n",
        "    resulting_val_acc = []\n",
        "    record_result = []\n",
        "    for n, model in enumerate(models):\n",
        "        print(\"Training model \", n)\n",
        "        \n",
        "        if early_stopping:\n",
        "            model.fit(X_train, y_train, \n",
        "                      validation_data = [X_test, y_test],\n",
        "                      callbacks=[EarlyStopping(monitor='val_accuracy', min_delta=min_delta, patience=patience)],\n",
        "                      batch_size = batch_size, epochs = epochs, shuffle=is_shuffle, verbose = verbose\n",
        "                     )\n",
        "        else:\n",
        "            model.fit(X_train, y_train, \n",
        "                      validation_data = [X_test, y_test],\n",
        "                      batch_size = batch_size, epochs = epochs, shuffle=is_shuffle, verbose = verbose\n",
        "                     )\n",
        "        '''\n",
        "        model.fit(X_train, y_train, validation_data = [X_test, y_test], \n",
        "                  batch_size = batch_size, epochs = epochs, shuffle=is_shuffle, verbose = verbose)\n",
        "        '''          \n",
        "        resulting_val_acc.append(model.history.history[\"val_accuracy\"][-1])\n",
        "        record_result.append({\"train_acc\": model.history.history[\"accuracy\"], \n",
        "                              \"val_acc\": model.history.history[\"val_accuracy\"],\n",
        "                              \"train_loss\": model.history.history[\"loss\"], \n",
        "                              \"val_loss\": model.history.history[\"val_loss\"]})\n",
        "        \n",
        "        if save_dir is not None:\n",
        "            save_dir_path = os.path.abspath(save_dir)\n",
        "            #make dir\n",
        "            try:\n",
        "                os.makedirs(save_dir_path)\n",
        "            except OSError as e:\n",
        "                if e.errno != errno.EEXIST:\n",
        "                    raise    \n",
        "\n",
        "            if save_names is None:\n",
        "                file_name = save_dir + \"model_{0}\".format(n) + \".h5\"\n",
        "            else:\n",
        "                file_name = save_dir + save_names[n] + \".h5\"\n",
        "            model.save(file_name)\n",
        "    \n",
        "    print(\"pre-train accuracy: \")\n",
        "    print(resulting_val_acc)\n",
        "        \n",
        "    return record_result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_utils.py\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "from typing import List, Tuple, Union, cast\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Tuple\n",
        "import tensorflow as tf\n",
        "import flwr as fl\n",
        "from flwr_experimental.baseline.dataset.dataset import (\n",
        "    XY,\n",
        "    PartitionedDataset,\n",
        "    create_partitioned_dataset,\n",
        "    log_distribution,\n",
        ")\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "def generate_alignment_data(X, y, N_alignment = 3000):\n",
        "    \n",
        "    split = StratifiedShuffleSplit(n_splits=1, train_size= N_alignment)\n",
        "    if N_alignment == \"all\":\n",
        "        alignment_data = {}\n",
        "        alignment_data[\"idx\"] = np.arange(y.shape[0])\n",
        "        alignment_data[\"X\"] = X\n",
        "        alignment_data[\"y\"] = y\n",
        "        return alignment_data\n",
        "    for train_index, _ in split.split(X, y):\n",
        "        X_alignment = X[train_index]\n",
        "        y_alignment = y[train_index]\n",
        "    alignment_data = {}\n",
        "    alignment_data[\"idx\"] = train_index\n",
        "    alignment_data[\"X\"] = X_alignment\n",
        "    alignment_data[\"y\"] = y_alignment\n",
        "    \n",
        "    return alignment_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6yRm3__pq6b",
        "outputId": "5d2506df-1f68-44b4-ef04-9ea9d6d262df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile FedMD.py\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import clone_model, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "from data_utils import generate_alignment_data\n",
        "from Neural_Networks import remove_last_layer\n",
        "\n",
        "class FedMD():\n",
        "    def __init__(self, parties, public_dataset, \n",
        "                 private_data, total_private_data,  \n",
        "                 private_test_data, N_alignment,\n",
        "                 N_rounds, \n",
        "                 N_logits_matching_round, logits_matching_batchsize, \n",
        "                 N_private_training_round, private_training_batchsize):\n",
        "        \n",
        "        self.N_parties = len(parties)\n",
        "        self.public_dataset = public_dataset\n",
        "        self.private_data = private_data\n",
        "        self.private_test_data = private_test_data\n",
        "        self.N_alignment = N_alignment\n",
        "        \n",
        "        self.N_rounds = N_rounds\n",
        "        self.N_logits_matching_round = N_logits_matching_round\n",
        "        self.logits_matching_batchsize = logits_matching_batchsize\n",
        "        self.N_private_training_round = N_private_training_round\n",
        "        self.private_training_batchsize = private_training_batchsize\n",
        "        \n",
        "        self.collaborative_parties = []\n",
        "        self.init_result = []\n",
        "        \n",
        "        print(\"start model initialization: \")\n",
        "        for i in range(self.N_parties):\n",
        "            print(\"model \", i)\n",
        "            model_A_twin = None\n",
        "            model_A_twin = clone_model(parties[i])\n",
        "            model_A_twin.set_weights(parties[i].get_weights())\n",
        "            model_A_twin.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-3), \n",
        "                                 loss = \"sparse_categorical_crossentropy\",\n",
        "                                 metrics = [\"accuracy\"])\n",
        "            \n",
        "            print(\"start full stack training ... \")        \n",
        "            \n",
        "            model_A_twin.fit(private_data[i][\"X\"], private_data[i][\"y\"],\n",
        "                             batch_size = 32, epochs = 10, shuffle=True, verbose = 1,\n",
        "                             validation_data = [private_test_data[\"X\"], private_test_data[\"y\"]],\n",
        "                             callbacks=[EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=10)])\n",
        "            \n",
        "            print(\"full stack training done\")\n",
        "            \n",
        "            model_A = remove_last_layer(model_A_twin, loss=\"mean_absolute_error\")\n",
        "            \n",
        "            self.collaborative_parties.append({\"model_logits\": model_A, \n",
        "                                               \"model_classifier\": model_A_twin,\n",
        "                                               \"model_weights\": model_A_twin.get_weights()})\n",
        "            \n",
        "            self.init_result.append({\"val_acc\": model_A_twin.history.history['val_accuracy'],\n",
        "                                     \"train_acc\": model_A_twin.history.history['accuracy'],\n",
        "                                     \"val_loss\": model_A_twin.history.history['val_loss'],\n",
        "                                     \"train_loss\": model_A_twin.history.history['loss'],\n",
        "                                    })\n",
        "            \n",
        "            del model_A, model_A_twin\n",
        "        #END FOR LOOP\n",
        "        '''\n",
        "        print(\"calculate the theoretical upper bounds for participants: \")\n",
        "        \n",
        "        self.upper_bounds = []\n",
        "        self.pooled_train_result = []\n",
        "        for model in parties:\n",
        "            model_ub = clone_model(model)\n",
        "            model_ub.set_weights(model.get_weights())\n",
        "            model_ub.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-3),\n",
        "                             loss = \"sparse_categorical_crossentropy\", \n",
        "                             metrics = [\"accuracy\"])\n",
        "            \n",
        "            model_ub.fit(total_private_data[\"X\"], total_private_data[\"y\"],\n",
        "                         batch_size = 32, epochs = 10, shuffle=True, verbose = 1, \n",
        "                         validation_data = [private_test_data[\"X\"], private_test_data[\"y\"]],\n",
        "                         callbacks=[EarlyStopping(monitor=\"val_accuracy\", min_delta=0.001, patience=10)])\n",
        "            \n",
        "            self.upper_bounds.append(model_ub.history.history[\"val_accuracy\"][-1])\n",
        "            self.pooled_train_result.append({\"val_acc\": model_ub.history.history[\"val_accuracy\"], \n",
        "                                             \"acc\": model_ub.history.history[\"accuracy\"]})\n",
        "            \n",
        "            del model_ub    \n",
        "        print(\"the upper bounds are:\", self.upper_bounds)\n",
        "        '''\n",
        "\n",
        "    def collaborative_training(self):\n",
        "        # start collaborating training    \n",
        "        collaboration_performance = {i: [] for i in range(self.N_parties)}\n",
        "        r = 0\n",
        "        while True:\n",
        "            # At beginning of each round, generate new alignment dataset\n",
        "            alignment_data = generate_alignment_data(self.public_dataset[\"X\"], \n",
        "                                                     self.public_dataset[\"y\"],\n",
        "                                                     self.N_alignment)\n",
        "            \n",
        "            print(\"round \", r)\n",
        "            \n",
        "            print(\"update logits ... \")\n",
        "            # update logits\n",
        "            logits = 0\n",
        "            for d in self.collaborative_parties:\n",
        "                d[\"model_logits\"].set_weights(d[\"model_weights\"])\n",
        "                logits += d[\"model_logits\"].predict(alignment_data[\"X\"], verbose = 1)\n",
        "                # print(\"d[model_weights]:\", d[\"model_weights\"])\n",
        "                # print(\"d[model_weights].shape:\", len(d[\"model_weights\"]))\n",
        "                # print(\"alignment_data[X]:\", alignment_data[\"X\"])\n",
        "                # print(\"alignment_data[X].shape:\", alignment_data[\"X\"].shape)\n",
        "                \n",
        "            logits /= self.N_parties\n",
        "\n",
        "            # print(\"logits:\", logits)\n",
        "            # print(\"logits.shape:\", logits.shape)\n",
        "            \n",
        "            # test performance\n",
        "            print(\"test performance ... \")\n",
        "            \n",
        "            for index, d in enumerate(self.collaborative_parties):\n",
        "                y_pred = d[\"model_classifier\"].predict(self.private_test_data[\"X\"], verbose = 0).argmax(axis = 1)\n",
        "                collaboration_performance[index].append(np.mean(self.private_test_data[\"y\"] == y_pred))\n",
        "                \n",
        "                print(collaboration_performance[index][-1])\n",
        "                del y_pred\n",
        "                \n",
        "                \n",
        "            r+= 1\n",
        "            if r > self.N_rounds:\n",
        "                break\n",
        "                \n",
        "                \n",
        "            print(\"updates models ...\")\n",
        "            for index, d in enumerate(self.collaborative_parties):\n",
        "                print(\"model {0} starting alignment with public logits... \".format(index))\n",
        "                \n",
        "                \n",
        "                weights_to_use = None\n",
        "                weights_to_use = d[\"model_weights\"]\n",
        "\n",
        "                d[\"model_logits\"].set_weights(weights_to_use)\n",
        "                d[\"model_logits\"].fit(alignment_data[\"X\"], logits, \n",
        "                                      batch_size = self.logits_matching_batchsize,  \n",
        "                                      epochs = self.N_logits_matching_round, \n",
        "                                      shuffle=True, verbose = 1)\n",
        "                d[\"model_weights\"] = d[\"model_logits\"].get_weights()\n",
        "                print(\"model {0} done alignment\".format(index))\n",
        "\n",
        "                print(\"model {0} starting training with private data... \".format(index))\n",
        "                weights_to_use = None\n",
        "                weights_to_use = d[\"model_weights\"]\n",
        "                d[\"model_classifier\"].set_weights(weights_to_use)\n",
        "                d[\"model_classifier\"].fit(self.private_data[index][\"X\"], \n",
        "                                          self.private_data[index][\"y\"],       \n",
        "                                          batch_size = self.private_training_batchsize, \n",
        "                                          epochs = self.N_private_training_round, \n",
        "                                          shuffle=True, verbose = 1)\n",
        "\n",
        "                d[\"model_weights\"] = d[\"model_classifier\"].get_weights()\n",
        "                print(\"model {0} done private training. \\n\".format(index))\n",
        "            #END FOR LOOP\n",
        "        \n",
        "        #END WHILE LOOP\n",
        "        return collaboration_performance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyW4bywvptNy",
        "outputId": "7e1d976c-7cf6-48b3-c4ea-6f76e455264c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing FedMD.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CIFAR_noniid.py\n",
        "\n",
        "import os\n",
        "import errno\n",
        "import argparse\n",
        "import sys\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# from data_utils import load_MNIST_data, load_EMNIST_data, generate_EMNIST_writer_based_data, generate_partial_data\n",
        "from FedMD import FedMD\n",
        "from Neural_Networks import train_models, cnn_2layer_fc_model\n",
        "\n",
        "from flwr_experimental.baseline.dataset.dataset import create_partitioned_dataset, XY, XYList, shuffle, sort_by_label_repeating, split_at_fraction, shift, partition, combine_partitions, adjust_xy_shape,sort_by_label\n",
        "\n",
        "\n",
        "def parseArg():\n",
        "    parser = argparse.ArgumentParser(description='FedMD, a federated learning framework. \\\n",
        "    Participants are training collaboratively. ')\n",
        "    parser.add_argument('-conf', metavar='conf_file', nargs=1, \n",
        "                        help='the config file for FedMD.'\n",
        "                       )\n",
        "\n",
        "    conf_file = os.path.abspath(\"conf/EMNIST_imbalance_conf.json\")\n",
        "    \n",
        "    if len(sys.argv) > 1:\n",
        "        args = parser.parse_args(sys.argv[1:])\n",
        "        if args.conf:\n",
        "            conf_file = args.conf[0]\n",
        "    return conf_file\n",
        "\n",
        "CANDIDATE_MODELS = {\"2_layer_CNN\": cnn_2layer_fc_model} \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    conf_file =  parseArg()\n",
        "    with open(conf_file, \"r\") as f:\n",
        "        conf_dict = eval(f.read())\n",
        "        \n",
        "        # n_classes = conf_dict[\"n_classes\"]\n",
        "        model_config = conf_dict[\"models\"]\n",
        "        pre_train_params = conf_dict[\"pre_train_params\"]\n",
        "        model_saved_dir = conf_dict[\"model_saved_dir\"]\n",
        "        model_saved_names = conf_dict[\"model_saved_names\"]\n",
        "        is_early_stopping = conf_dict[\"early_stopping\"]\n",
        "        public_classes = conf_dict[\"public_classes\"]\n",
        "        private_classes = conf_dict[\"private_classes\"]\n",
        "        n_classes = len(public_classes) + len(private_classes)\n",
        "        \n",
        "        emnist_data_dir = conf_dict[\"EMNIST_dir\"]    \n",
        "        N_parties = conf_dict[\"N_parties\"]\n",
        "        N_samples_per_class = conf_dict[\"N_samples_per_class\"]\n",
        "        \n",
        "        N_rounds = conf_dict[\"N_rounds\"]\n",
        "        N_alignment = conf_dict[\"N_alignment\"]\n",
        "        N_private_training_round = conf_dict[\"N_private_training_round\"]\n",
        "        private_training_batchsize = conf_dict[\"private_training_batchsize\"]\n",
        "        N_logits_matching_round = conf_dict[\"N_logits_matching_round\"]\n",
        "        logits_matching_batchsize = conf_dict[\"logits_matching_batchsize\"]\n",
        "        \n",
        "        \n",
        "        result_save_dir = conf_dict[\"result_save_dir\"]\n",
        "\n",
        "    \n",
        "    del conf_dict, conf_file\n",
        "    \n",
        "    (trainset_x, trainset_y), (testset_x, testset_y) = tf.keras.datasets.cifar10.load_data()\n",
        "    # print(trainset_x[0])\n",
        "    global_fraction = 0.2\n",
        "    g_trainset, l_trainset =  (trainset_x[:10000], trainset_y[:10000]), (trainset_x[10000:],trainset_y[10000:])\n",
        "    g_testset, l_testset =  (testset_x[:2000], testset_y[:2000]), (testset_x[2000:],testset_y[2000:])\n",
        "    private_data = (l_trainset, l_testset)\n",
        "    # print(\"local_data\", private_data)\n",
        "\n",
        "    X_train_CIFAR, y_train_CIFAR = g_trainset\n",
        "    X_test_CIFAR, y_test_CIFAR = g_testset\n",
        "    y_train_CIFAR = np.squeeze(y_train_CIFAR)\n",
        "    y_test_CIFAR = np.squeeze(y_test_CIFAR)\n",
        "    public_dataset = {\"X\": X_train_CIFAR, \"y\": y_train_CIFAR}\n",
        "    # print(\"public_dataset[y].shape\", public_dataset[\"y\"].shape)\n",
        "\n",
        "    iid_fraction = 0.75\n",
        "    num_partitions = 10\n",
        "    (l_train_partitions, l_test_partitions), _ = create_partitioned_dataset(private_data, iid_fraction, num_partitions)\n",
        "\n",
        "    private_data = []\n",
        "    total_private_data = {}\n",
        "    total_private_data[\"X\"] = np.array([])\n",
        "    total_private_data[\"y\"] = np.array([])\n",
        "    \n",
        "    private_test_data = {}\n",
        "    private_test_data[\"X\"] = np.array([])\n",
        "    private_test_data[\"y\"] = np.array([])\n",
        "    \n",
        "    # print(\"private_test_data\", private_test_data)\n",
        "    for i in range(num_partitions):\n",
        "        l_x_train, l_y_train = l_train_partitions[i]\n",
        "        l_x_test, l_y_test = l_test_partitions[i]\n",
        "        private_data.append({\"X\": l_x_train, \"y\": l_y_train})\n",
        "        if i == 0:\n",
        "          total_private_data[\"X\"] = l_x_train\n",
        "          total_private_data[\"y\"] = l_y_train\n",
        "          private_test_data[\"X\"] = l_x_test\n",
        "          private_test_data[\"y\"] = l_y_test\n",
        "        # total_private_data[\"X\"].append(l_x_train)\n",
        "        # total_private_data[\"y\"].append(l_y_train)\n",
        "        # private_test_data[\"X\"].append(l_x_test)\n",
        "        # private_test_data[\"y\"].append(l_y_test)\n",
        "        else:\n",
        "          total_private_data[\"X\"] = np.vstack((total_private_data[\"X\"],l_x_train))\n",
        "          total_private_data[\"y\"] = np.hstack((total_private_data[\"y\"],l_y_train))\n",
        "          private_test_data[\"X\"] = np.vstack((private_test_data[\"X\"],l_x_test))\n",
        "          private_test_data[\"y\"] = np.hstack((private_test_data[\"y\"],l_y_test))\n",
        "\n",
        "    # print(\"total_private_data\", total_private_data)\n",
        "    # print(\"private_test_data:\", private_test_data)\n",
        "    # print(\"private_test_data[X].shape:\", private_test_data[\"X\"].shape)\n",
        "    \n",
        "    parties = []\n",
        "    if model_saved_dir is None:\n",
        "        for i, item in enumerate(model_config):\n",
        "            model_name = item[\"model_type\"]\n",
        "            model_params = item[\"params\"]\n",
        "            tmp = CANDIDATE_MODELS[model_name](n_classes=n_classes, \n",
        "                                               input_shape=(28,28),\n",
        "                                               **model_params)\n",
        "            print(\"model {0} : {1}\".format(i, model_saved_names[i]))\n",
        "            print(tmp.summary())\n",
        "            parties.append(tmp)\n",
        "            \n",
        "            del model_name, model_params, tmp\n",
        "        #END FOR LOOP\n",
        "        pre_train_result = train_models(parties, \n",
        "                                        X_train_CIFAR, y_train_CIFAR, \n",
        "                                        X_test_CIFAR, y_test_CIFAR,\n",
        "                                        save_dir = model_saved_dir, save_names = model_saved_names,\n",
        "                                        early_stopping = is_early_stopping,\n",
        "                                        **pre_train_params\n",
        "                                       )\n",
        "    else:\n",
        "        dpath = os.path.abspath(model_saved_dir)\n",
        "        model_names = os.listdir(dpath)\n",
        "        for name in model_names:\n",
        "            tmp = None\n",
        "            tmp = load_model(os.path.join(dpath ,name))\n",
        "            parties.append(tmp)\n",
        "    \n",
        "    \n",
        "    fedmd = FedMD(parties, \n",
        "                  public_dataset = public_dataset,\n",
        "                  private_data = private_data, \n",
        "                  total_private_data = total_private_data,\n",
        "                  private_test_data = private_test_data,\n",
        "                  N_rounds = N_rounds,\n",
        "                  N_alignment = N_alignment, \n",
        "                  N_logits_matching_round = N_logits_matching_round,\n",
        "                  logits_matching_batchsize = logits_matching_batchsize, \n",
        "                  N_private_training_round = N_private_training_round, \n",
        "                  private_training_batchsize = private_training_batchsize)\n",
        "    \n",
        "    initialization_result = fedmd.init_result\n",
        "    # pooled_train_result = fedmd.pooled_train_result\n",
        "    \n",
        "    collaboration_performance = fedmd.collaborative_training()\n",
        "    \n",
        "    if result_save_dir is not None:\n",
        "        save_dir_path = os.path.abspath(result_save_dir)\n",
        "        #make dir\n",
        "        try:\n",
        "            os.makedirs(save_dir_path)\n",
        "        except OSError as e:\n",
        "            if e.errno != errno.EEXIST:\n",
        "                raise    \n",
        "    \n",
        "    \n",
        "    with open(os.path.join(save_dir_path, 'pre_train_result.pkl'), 'wb') as f:\n",
        "        pickle.dump(pre_train_result, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    with open(os.path.join(save_dir_path, 'init_result.pkl'), 'wb') as f:\n",
        "        pickle.dump(initialization_result, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    # with open(os.path.join(save_dir_path, 'pooled_train_result.pkl'), 'wb') as f:\n",
        "    #     pickle.dump(pooled_train_result, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    with open(os.path.join(save_dir_path, 'col_performance.pkl'), 'wb') as f:\n",
        "        pickle.dump(collaboration_performance, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dpvobrIp07z",
        "outputId": "59f57b2a-6465-4566-ea19-07233c980636"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing CIFAR_noniid.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CIFAR_noniid_conf.json\n",
        "{\n",
        "    \"models\": [{\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 128, \"n2\": 256, \"dropout_rate\": 0.2}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 128, \"n2\": 384, \"dropout_rate\": 0.2}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 128, 'n2': 512, \"dropout_rate\": 0.2}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 256, \"n2\": 256, \"dropout_rate\": 0.3}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 256, \"n2\": 512, \"dropout_rate\": 0.4}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 64, \"n2\": 128, \"dropout_rate\": 0.2}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 64, \"n2\": 128, \"dropout_rate\": 0.2}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 128, \"n2\": 192, \"dropout_rate\": 0.2}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 128, \"n2\": 128, \"dropout_rate\": 0.3}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 128, \"n2\": 128, \"dropout_rate\": 0.3}}\n",
        "              ],\n",
        "    \"pre_train_params\": {\"min_delta\": 0.001, \"patience\": 3,\n",
        "                     \"batch_size\": 128, \"epochs\": 3, \"is_shuffle\": True, \n",
        "                     \"verbose\": 1},\n",
        "    \"model_saved_dir\": None,\n",
        "    \"model_saved_names\" : [\"CNN_128_256\", \"CNN_128_384\", \"CNN_128_512\", \"CNN_256_256\", \"CNN_256_512\", \n",
        "                    \"CNN_64_128_256\", \"CNN_64_128_192\", \"CNN_128_192_256\", \"CNN_128_128_128\", \"CNN_128_128_192\"],\n",
        "    \"early_stopping\" : False,\n",
        "    \"N_parties\": 10,\n",
        "    \"N_samples_per_class\": 3,\n",
        "    \"N_alignment\": 5000, \n",
        "    \"private_classes\": [10, 11, 12, 13, 14, 15], \n",
        "    \"public_classes\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
        "    \"is_show\": False,\n",
        "    \"N_rounds\": 3,\n",
        "    \"N_logits_matching_round\": 1, \n",
        "    \"N_private_training_round\": 3,\n",
        "    \"private_training_batchsize\" : 5, \n",
        "    \"logits_matching_batchsize\": 256, \n",
        "    \"EMNIST_dir\": \"emnist-letters.mat\",\n",
        "    \"result_save_dir\": \"./result_FEMNIST_imbalanced/\"\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeN0_H9Ip8ld",
        "outputId": "f0e7b55a-a1cd-4856-a77f-f5fe324e3750"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing CIFAR_noniid_conf.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python CIFAR_noniid.py -conf CIFAR_noniid_conf.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7CUE8H5qB2W",
        "outputId": "dd5ed906-4c5a-4421-ac98-494bb1cd7317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "170508288/170498071 [==============================] - 6s 0us/step\n",
            "2022-01-12 08:44:46.644576: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "model 0 : CNN_128_256\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 28, 28, 6)         0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 10, 10, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 1 : CNN_128_384\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 28, 28, 6)         0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 10, 10, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 2 : CNN_128_512\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 28, 28, 6)         0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 14, 14, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 10, 10, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 3 : CNN_256_256\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_3 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 28, 28, 6)         0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 14, 14, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 10, 10, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 4 : CNN_256_512\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_4 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 28, 28, 6)         0         \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 14, 14, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 10, 10, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 5 : CNN_64_128_256\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_5 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 28, 28, 6)         0         \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 10, 10, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 6 : CNN_64_128_192\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_6 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 28, 28, 6)         0         \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 10, 10, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_20 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 7 : CNN_128_192_256\n",
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_7 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 28, 28, 6)         0         \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 10, 10, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 8 : CNN_128_128_128\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_8 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 28, 28, 6)         0         \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 10, 10, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 9 : CNN_128_128_192\n",
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_9 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 28, 28, 6)         0         \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 10, 10, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training model  0\n",
            "Epoch 1/3\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 7.3921 - accuracy: 0.1170 - val_loss: 2.3320 - val_accuracy: 0.1155\n",
            "Epoch 2/3\n",
            "43/79 [===============>..............] - ETA: 3s - loss: 2.3275 - accuracy: 0.1166"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FedMD-v5-2:00.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install flwr==0.17.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox6LThsZqEOp",
        "outputId": "967d93a8-01c1-4b60-add1-2bb664b2f151"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flwr==0.17.0 in /usr/local/lib/python3.7/dist-packages (0.17.0)\n",
            "Requirement already satisfied: google<3.0.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (2.0.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (1.19.5)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.27.2 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (1.43.0)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.12.1 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (3.17.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google<3.0.0,>=2.0.3->flwr==0.17.0) (4.6.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<2.0.0,>=1.27.2->flwr==0.17.0) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f59qPirLpmMI",
        "outputId": "0185ef0c-5b46-4655-f646-93268de61152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Neural_Networks.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile Neural_Networks.py\n",
        "from tensorflow.keras.models import Model, Sequential, clone_model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, add, concatenate, Conv2D,Dropout,\\\n",
        "BatchNormalization, Flatten, MaxPooling2D, AveragePooling2D, Activation, Dropout, Reshape\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "  \n",
        "# def cnn_2layer_fc_model(n_classes,n1 = 128, n2=256, dropout_rate = 0.2,input_shape = (28,28)):\n",
        "#    model_A, x = None, None\n",
        "\n",
        "def cnn_2layer_fc_model(n_classes,n1 = 128, n2=256, dropout_rate = 0.2,input_shape = (32, 32, 3)):\n",
        "    model_A, x = None, None\n",
        "    input_shape = (32, 32, 3)\n",
        "    x = Input((32, 32, 3))\n",
        "    if len(input_shape)==2: \n",
        "        y = Reshape((input_shape[0], input_shape[1], 1))(x)\n",
        "    else:\n",
        "        y = Reshape(input_shape)(x)\n",
        "    y = Conv2D(filters = 6, kernel_size = 5)(y)\n",
        "    # y = BatchNormalization()(y)\n",
        "    # y = Activation(\"relu\")(y)\n",
        "    # y = Dropout(dropout_rate)(y)\n",
        "    y = MaxPooling2D(2,2)(y)\n",
        "\n",
        "\n",
        "    y = Conv2D(filters = 16, kernel_size = 5)(y)\n",
        "    # y = BatchNormalization()(y)\n",
        "    # y = Activation(\"relu\")(y)\n",
        "    # y = Dropout(dropout_rate)(y)\n",
        "    #y = AveragePooling2D(pool_size = (2,2), strides = 2, padding = \"valid\")(y)\n",
        "    y = MaxPooling2D(2,2)(y)\n",
        "\n",
        "    y = Flatten()(y)\n",
        "    y = Dense(120)(y)\n",
        "    y = Dense(84)(y)\n",
        "    y = Dense(10)(y)\n",
        "    # y = Activation(\"softmax\")(y)\n",
        "\n",
        "\n",
        "    model_A = Model(inputs = x, outputs = y)\n",
        "\n",
        "    model_A.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-3), \n",
        "                        loss = \"sparse_categorical_crossentropy\",\n",
        "                        metrics = [\"accuracy\"])\n",
        "    return model_A\n",
        "\n",
        "\n",
        "def remove_last_layer(model, loss = \"mean_absolute_error\"):\n",
        "    \"\"\"\n",
        "    Input: Keras model, a classification model whose last layer is a softmax activation\n",
        "    Output: Keras model, the same model with the last softmax activation layer removed,\n",
        "        while keeping the same parameters \n",
        "    \"\"\"\n",
        "    \n",
        "    # new_model = Model(inputs = model.inputs, outputs = model.layers[-2].output)\n",
        "    # new_model.set_weights(model.get_weights())\n",
        "    # new_model.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-3), \n",
        "    #                  loss = loss)\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def train_models(models, X_train, y_train, X_test, y_test, \n",
        "                 save_dir = \"./\", save_names = None,\n",
        "                 early_stopping = True, min_delta = 0.001, patience = 3, \n",
        "                 batch_size = 128, epochs = 2, is_shuffle=True, verbose = 1\n",
        "                ):\n",
        "    '''\n",
        "    Train an array of models on the same dataset. \n",
        "    We use early termination to speed up training. \n",
        "    '''\n",
        "    \n",
        "    resulting_val_acc = []\n",
        "    record_result = []\n",
        "    for n, model in enumerate(models):\n",
        "        print(\"Training model \", n)\n",
        "        \n",
        "        if early_stopping:\n",
        "            model.fit(X_train, y_train, \n",
        "                      validation_data = [X_test, y_test],\n",
        "                      callbacks=[EarlyStopping(monitor='val_accuracy', min_delta=min_delta, patience=patience)],\n",
        "                      batch_size = batch_size, epochs = epochs, shuffle=is_shuffle, verbose = verbose\n",
        "                     )\n",
        "        else:\n",
        "            model.fit(X_train, y_train, \n",
        "                      validation_data = [X_test, y_test],\n",
        "                      batch_size = batch_size, epochs = epochs, shuffle=is_shuffle, verbose = verbose\n",
        "                     )\n",
        "        '''\n",
        "        model.fit(X_train, y_train, validation_data = [X_test, y_test], \n",
        "                  batch_size = batch_size, epochs = epochs, shuffle=is_shuffle, verbose = verbose)\n",
        "        '''          \n",
        "        resulting_val_acc.append(model.history.history[\"val_accuracy\"][-1])\n",
        "        record_result.append({\"train_acc\": model.history.history[\"accuracy\"], \n",
        "                              \"val_acc\": model.history.history[\"val_accuracy\"],\n",
        "                              \"train_loss\": model.history.history[\"loss\"], \n",
        "                              \"val_loss\": model.history.history[\"val_loss\"]})\n",
        "        \n",
        "        if save_dir is not None:\n",
        "            save_dir_path = os.path.abspath(save_dir)\n",
        "            #make dir\n",
        "            try:\n",
        "                os.makedirs(save_dir_path)\n",
        "            except OSError as e:\n",
        "                if e.errno != errno.EEXIST:\n",
        "                    raise    \n",
        "\n",
        "            if save_names is None:\n",
        "                file_name = save_dir + \"model_{0}\".format(n) + \".h5\"\n",
        "            else:\n",
        "                file_name = save_dir + save_names[n] + \".h5\"\n",
        "            model.save(file_name)\n",
        "    \n",
        "    print(\"pre-train accuracy: \")\n",
        "    print(resulting_val_acc)\n",
        "        \n",
        "    return record_result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_utils.py\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "from typing import List, Tuple, Union, cast\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Tuple\n",
        "import tensorflow as tf\n",
        "import flwr as fl\n",
        "from flwr_experimental.baseline.dataset.dataset import (\n",
        "    XY,\n",
        "    PartitionedDataset,\n",
        "    create_partitioned_dataset,\n",
        "    log_distribution,\n",
        ")\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "def generate_alignment_data(X, y, N_alignment = 3000):\n",
        "    \n",
        "    split = StratifiedShuffleSplit(n_splits=1, train_size= N_alignment)\n",
        "    if N_alignment == \"all\":\n",
        "        alignment_data = {}\n",
        "        alignment_data[\"idx\"] = np.arange(y.shape[0])\n",
        "        alignment_data[\"X\"] = X\n",
        "        alignment_data[\"y\"] = y\n",
        "        return alignment_data\n",
        "    for train_index, _ in split.split(X, y):\n",
        "        X_alignment = X[train_index]\n",
        "        y_alignment = y[train_index]\n",
        "    alignment_data = {}\n",
        "    alignment_data[\"idx\"] = train_index\n",
        "    alignment_data[\"X\"] = X_alignment\n",
        "    alignment_data[\"y\"] = y_alignment\n",
        "    \n",
        "    return alignment_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6yRm3__pq6b",
        "outputId": "9c08b5d6-96b5-4bb9-8387-5fdb34022f3b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting data_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile FedMD.py\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import clone_model, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "from data_utils import generate_alignment_data\n",
        "from Neural_Networks import remove_last_layer\n",
        "\n",
        "class FedMD():\n",
        "    def __init__(self, parties, public_dataset, \n",
        "                 private_data, total_private_data,  \n",
        "                 private_test_data, N_alignment,\n",
        "                 N_rounds, \n",
        "                 N_logits_matching_round, logits_matching_batchsize, \n",
        "                 N_private_training_round, private_training_batchsize):\n",
        "        \n",
        "        self.N_parties = len(parties)\n",
        "        self.public_dataset = public_dataset\n",
        "        self.private_data = private_data\n",
        "        self.private_test_data = private_test_data\n",
        "        self.N_alignment = N_alignment\n",
        "        \n",
        "        self.N_rounds = N_rounds\n",
        "        self.N_logits_matching_round = N_logits_matching_round\n",
        "        self.logits_matching_batchsize = logits_matching_batchsize\n",
        "        self.N_private_training_round = N_private_training_round\n",
        "        self.private_training_batchsize = private_training_batchsize\n",
        "        \n",
        "        self.collaborative_parties = []\n",
        "        self.init_result = []\n",
        "        \n",
        "        print(\"start model initialization: \")\n",
        "        for i in range(self.N_parties):\n",
        "            print(\"model \", i)\n",
        "            model_A_twin = None\n",
        "            model_A_twin = clone_model(parties[i])\n",
        "            model_A_twin.set_weights(parties[i].get_weights())\n",
        "            model_A_twin.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-3), \n",
        "                                 loss = \"sparse_categorical_crossentropy\",\n",
        "                                 metrics = [\"accuracy\"])\n",
        "            \n",
        "            print(\"start full stack training ... \")        \n",
        "            \n",
        "            model_A_twin.fit(private_data[i][\"X\"], private_data[i][\"y\"],\n",
        "                             batch_size = 32, epochs = 2, shuffle=True, verbose = 1,\n",
        "                             validation_data = [private_test_data[\"X\"], private_test_data[\"y\"]],\n",
        "                             callbacks=[EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=10)])\n",
        "            \n",
        "            print(\"full stack training done\")\n",
        "            \n",
        "            model_A = remove_last_layer(model_A_twin, loss=\"mean_absolute_error\")\n",
        "            \n",
        "            self.collaborative_parties.append({\"model_logits\": model_A, \n",
        "                                               \"model_classifier\": model_A_twin,\n",
        "                                               \"model_weights\": model_A_twin.get_weights()})\n",
        "            \n",
        "            self.init_result.append({\"val_acc\": model_A_twin.history.history['val_accuracy'],\n",
        "                                     \"train_acc\": model_A_twin.history.history['accuracy'],\n",
        "                                     \"val_loss\": model_A_twin.history.history['val_loss'],\n",
        "                                     \"train_loss\": model_A_twin.history.history['loss'],\n",
        "                                    })\n",
        "            \n",
        "            del model_A, model_A_twin\n",
        "        #END FOR LOOP\n",
        "        '''\n",
        "        print(\"calculate the theoretical upper bounds for participants: \")\n",
        "        \n",
        "        self.upper_bounds = []\n",
        "        self.pooled_train_result = []\n",
        "        for model in parties:\n",
        "            model_ub = clone_model(model)\n",
        "            model_ub.set_weights(model.get_weights())\n",
        "            model_ub.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-3),\n",
        "                             loss = \"sparse_categorical_crossentropy\", \n",
        "                             metrics = [\"accuracy\"])\n",
        "            \n",
        "            model_ub.fit(total_private_data[\"X\"], total_private_data[\"y\"],\n",
        "                         batch_size = 32, epochs = 10, shuffle=True, verbose = 1, \n",
        "                         validation_data = [private_test_data[\"X\"], private_test_data[\"y\"]],\n",
        "                         callbacks=[EarlyStopping(monitor=\"val_accuracy\", min_delta=0.001, patience=10)])\n",
        "            \n",
        "            self.upper_bounds.append(model_ub.history.history[\"val_accuracy\"][-1])\n",
        "            self.pooled_train_result.append({\"val_acc\": model_ub.history.history[\"val_accuracy\"], \n",
        "                                             \"acc\": model_ub.history.history[\"accuracy\"]})\n",
        "            \n",
        "            del model_ub    \n",
        "        print(\"the upper bounds are:\", self.upper_bounds)\n",
        "        '''\n",
        "\n",
        "    def collaborative_training(self):\n",
        "        # start collaborating training    \n",
        "        collaboration_performance = {i: [] for i in range(self.N_parties)}\n",
        "        r = 0\n",
        "        while True:\n",
        "            # At beginning of each round, generate new alignment dataset\n",
        "            alignment_data = generate_alignment_data(self.public_dataset[\"X\"], \n",
        "                                                     self.public_dataset[\"y\"],\n",
        "                                                     self.N_alignment)\n",
        "            \n",
        "            print(\"round \", r)\n",
        "            \n",
        "            print(\"update logits ... \")\n",
        "            # update logits\n",
        "            logits = 0\n",
        "            for d in self.collaborative_parties:\n",
        "                d[\"model_logits\"].set_weights(d[\"model_weights\"])\n",
        "                logits += d[\"model_logits\"].predict(alignment_data[\"X\"], verbose = 1)\n",
        "                print(\"d[model_weights]\", d[\"model_weights\"])\n",
        "                print(\"d[model_weights].shape\", d[\"model_weights\"].shape)\n",
        "                print(\"alignment_data[X].shape\", alignment_data[\"X\"].shape)\n",
        "                \n",
        "            logits /= self.N_parties\n",
        "\n",
        "            print(\"logits:\", logits)\n",
        "            print(\"logits.shape:\", logits.shape)\n",
        "            \n",
        "            # test performance\n",
        "            print(\"test performance ... \")\n",
        "            \n",
        "            for index, d in enumerate(self.collaborative_parties):\n",
        "                y_pred = d[\"model_classifier\"].predict(self.private_test_data[\"X\"], verbose = 0).argmax(axis = 1)\n",
        "                collaboration_performance[index].append(np.mean(self.private_test_data[\"y\"] == y_pred))\n",
        "                \n",
        "                print(collaboration_performance[index][-1])\n",
        "                del y_pred\n",
        "                \n",
        "                \n",
        "            r+= 1\n",
        "            if r > self.N_rounds:\n",
        "                break\n",
        "                \n",
        "                \n",
        "            print(\"updates models ...\")\n",
        "            for index, d in enumerate(self.collaborative_parties):\n",
        "                print(\"model {0} starting alignment with public logits... \".format(index))\n",
        "                \n",
        "                \n",
        "                weights_to_use = None\n",
        "                weights_to_use = d[\"model_weights\"]\n",
        "\n",
        "                d[\"model_logits\"].set_weights(weights_to_use)\n",
        "                d[\"model_logits\"].fit(alignment_data[\"X\"], logits, \n",
        "                                      batch_size = self.logits_matching_batchsize,  \n",
        "                                      epochs = self.N_logits_matching_round, \n",
        "                                      shuffle=True, verbose = 1)\n",
        "                d[\"model_weights\"] = d[\"model_logits\"].get_weights()\n",
        "                print(\"model {0} done alignment\".format(index))\n",
        "\n",
        "                print(\"model {0} starting training with private data... \".format(index))\n",
        "                weights_to_use = None\n",
        "                weights_to_use = d[\"model_weights\"]\n",
        "                d[\"model_classifier\"].set_weights(weights_to_use)\n",
        "                d[\"model_classifier\"].fit(self.private_data[index][\"X\"], \n",
        "                                          self.private_data[index][\"y\"],       \n",
        "                                          batch_size = self.private_training_batchsize, \n",
        "                                          epochs = self.N_private_training_round, \n",
        "                                          shuffle=True, verbose = 1)\n",
        "\n",
        "                d[\"model_weights\"] = d[\"model_classifier\"].get_weights()\n",
        "                print(\"model {0} done private training. \\n\".format(index))\n",
        "            #END FOR LOOP\n",
        "        \n",
        "        #END WHILE LOOP\n",
        "        return collaboration_performance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyW4bywvptNy",
        "outputId": "e324ef76-df18-4042-e1c5-ab55f170af17"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting FedMD.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CIFAR_noniid.py\n",
        "\n",
        "import os\n",
        "import errno\n",
        "import argparse\n",
        "import sys\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# from data_utils import load_MNIST_data, load_EMNIST_data, generate_EMNIST_writer_based_data, generate_partial_data\n",
        "from FedMD import FedMD\n",
        "from Neural_Networks import train_models, cnn_2layer_fc_model\n",
        "\n",
        "from flwr_experimental.baseline.dataset.dataset import create_partitioned_dataset, XY, XYList, shuffle, sort_by_label_repeating, split_at_fraction, shift, partition, combine_partitions, adjust_xy_shape,sort_by_label\n",
        "\n",
        "\n",
        "def parseArg():\n",
        "    parser = argparse.ArgumentParser(description='FedMD, a federated learning framework. \\\n",
        "    Participants are training collaboratively. ')\n",
        "    parser.add_argument('-conf', metavar='conf_file', nargs=1, \n",
        "                        help='the config file for FedMD.'\n",
        "                       )\n",
        "\n",
        "    conf_file = os.path.abspath(\"conf/EMNIST_imbalance_conf.json\")\n",
        "    \n",
        "    if len(sys.argv) > 1:\n",
        "        args = parser.parse_args(sys.argv[1:])\n",
        "        if args.conf:\n",
        "            conf_file = args.conf[0]\n",
        "    return conf_file\n",
        "\n",
        "CANDIDATE_MODELS = {\"2_layer_CNN\": cnn_2layer_fc_model} \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    conf_file =  parseArg()\n",
        "    with open(conf_file, \"r\") as f:\n",
        "        conf_dict = eval(f.read())\n",
        "        \n",
        "        # n_classes = conf_dict[\"n_classes\"]\n",
        "        model_config = conf_dict[\"models\"]\n",
        "        pre_train_params = conf_dict[\"pre_train_params\"]\n",
        "        model_saved_dir = conf_dict[\"model_saved_dir\"]\n",
        "        model_saved_names = conf_dict[\"model_saved_names\"]\n",
        "        is_early_stopping = conf_dict[\"early_stopping\"]\n",
        "        public_classes = conf_dict[\"public_classes\"]\n",
        "        private_classes = conf_dict[\"private_classes\"]\n",
        "        n_classes = len(public_classes) + len(private_classes)\n",
        "        \n",
        "        emnist_data_dir = conf_dict[\"EMNIST_dir\"]    \n",
        "        N_parties = conf_dict[\"N_parties\"]\n",
        "        N_samples_per_class = conf_dict[\"N_samples_per_class\"]\n",
        "        \n",
        "        N_rounds = conf_dict[\"N_rounds\"]\n",
        "        N_alignment = conf_dict[\"N_alignment\"]\n",
        "        N_private_training_round = conf_dict[\"N_private_training_round\"]\n",
        "        private_training_batchsize = conf_dict[\"private_training_batchsize\"]\n",
        "        N_logits_matching_round = conf_dict[\"N_logits_matching_round\"]\n",
        "        logits_matching_batchsize = conf_dict[\"logits_matching_batchsize\"]\n",
        "        \n",
        "        \n",
        "        result_save_dir = conf_dict[\"result_save_dir\"]\n",
        "\n",
        "    \n",
        "    del conf_dict, conf_file\n",
        "    \n",
        "    (trainset_x, trainset_y), (testset_x, testset_y) = tf.keras.datasets.cifar10.load_data()\n",
        "    print(trainset_x[0])\n",
        "    global_fraction = 0.2\n",
        "    g_trainset, l_trainset =  (trainset_x[:10000], trainset_y[:10000]), (trainset_x[10000:],trainset_y[10000:])\n",
        "    g_testset, l_testset =  (testset_x[:2000], testset_y[:2000]), (testset_x[2000:],testset_y[2000:])\n",
        "    private_data = (l_trainset, l_testset)\n",
        "    # print(\"local_data\", private_data)\n",
        "\n",
        "    X_train_CIFAR, y_train_CIFAR = g_trainset\n",
        "    X_test_CIFAR, y_test_CIFAR = g_testset\n",
        "    public_dataset = {\"X\": X_train_CIFAR, \"y\": y_train_CIFAR}\n",
        "    # print(\"public_dataset\", public_dataset)\n",
        "\n",
        "    iid_fraction = 1.0\n",
        "    num_partitions = 10\n",
        "    (l_train_partitions, l_test_partitions), _ = create_partitioned_dataset(private_data, iid_fraction, num_partitions)\n",
        "\n",
        "    private_data = []\n",
        "    total_private_data = {}\n",
        "    total_private_data[\"X\"] = np.array([])\n",
        "    total_private_data[\"y\"] = np.array([])\n",
        "    \n",
        "    private_test_data = {}\n",
        "    private_test_data[\"X\"] = np.array([])\n",
        "    private_test_data[\"y\"] = np.array([])\n",
        "    \n",
        "    # print(\"private_test_data\", private_test_data)\n",
        "    for i in range(num_partitions):\n",
        "        l_x_train, l_y_train = l_train_partitions[i]\n",
        "        l_x_test, l_y_test = l_test_partitions[i]\n",
        "        private_data.append({\"X\": l_x_train, \"y\": l_y_train})\n",
        "        if i == 0:\n",
        "          total_private_data[\"X\"] = l_x_train\n",
        "          total_private_data[\"y\"] = l_y_train\n",
        "          private_test_data[\"X\"] = l_x_test\n",
        "          private_test_data[\"y\"] = l_y_test\n",
        "        # total_private_data[\"X\"].append(l_x_train)\n",
        "        # total_private_data[\"y\"].append(l_y_train)\n",
        "        # private_test_data[\"X\"].append(l_x_test)\n",
        "        # private_test_data[\"y\"].append(l_y_test)\n",
        "        else:\n",
        "          total_private_data[\"X\"] = np.vstack((total_private_data[\"X\"],l_x_train))\n",
        "          total_private_data[\"y\"] = np.hstack((total_private_data[\"y\"],l_y_train))\n",
        "          private_test_data[\"X\"] = np.vstack((private_test_data[\"X\"],l_x_test))\n",
        "          private_test_data[\"y\"] = np.hstack((private_test_data[\"y\"],l_y_test))\n",
        "\n",
        "    print(\"total_private_data\", total_private_data)\n",
        "    print(\"private_test_data:\", private_test_data)\n",
        "    print(\"private_test_data[X].shape:\", private_test_data[\"X\"].shape)\n",
        "    \n",
        "    parties = []\n",
        "    if model_saved_dir is None:\n",
        "        for i, item in enumerate(model_config):\n",
        "            model_name = item[\"model_type\"]\n",
        "            model_params = item[\"params\"]\n",
        "            tmp = CANDIDATE_MODELS[model_name](n_classes=n_classes, \n",
        "                                               input_shape=(28,28),\n",
        "                                               **model_params)\n",
        "            print(\"model {0} : {1}\".format(i, model_saved_names[i]))\n",
        "            print(tmp.summary())\n",
        "            parties.append(tmp)\n",
        "            \n",
        "            del model_name, model_params, tmp\n",
        "        #END FOR LOOP\n",
        "        pre_train_result = train_models(parties, \n",
        "                                        X_train_CIFAR, y_train_CIFAR, \n",
        "                                        X_test_CIFAR, y_test_CIFAR,\n",
        "                                        save_dir = model_saved_dir, save_names = model_saved_names,\n",
        "                                        early_stopping = is_early_stopping,\n",
        "                                        **pre_train_params\n",
        "                                       )\n",
        "    else:\n",
        "        dpath = os.path.abspath(model_saved_dir)\n",
        "        model_names = os.listdir(dpath)\n",
        "        for name in model_names:\n",
        "            tmp = None\n",
        "            tmp = load_model(os.path.join(dpath ,name))\n",
        "            parties.append(tmp)\n",
        "    \n",
        "    \n",
        "    fedmd = FedMD(parties, \n",
        "                  public_dataset = public_dataset,\n",
        "                  private_data = private_data, \n",
        "                  total_private_data = total_private_data,\n",
        "                  private_test_data = private_test_data,\n",
        "                  N_rounds = N_rounds,\n",
        "                  N_alignment = N_alignment, \n",
        "                  N_logits_matching_round = N_logits_matching_round,\n",
        "                  logits_matching_batchsize = logits_matching_batchsize, \n",
        "                  N_private_training_round = N_private_training_round, \n",
        "                  private_training_batchsize = private_training_batchsize)\n",
        "    \n",
        "    initialization_result = fedmd.init_result\n",
        "    # pooled_train_result = fedmd.pooled_train_result\n",
        "    \n",
        "    collaboration_performance = fedmd.collaborative_training()\n",
        "    \n",
        "    if result_save_dir is not None:\n",
        "        save_dir_path = os.path.abspath(result_save_dir)\n",
        "        #make dir\n",
        "        try:\n",
        "            os.makedirs(save_dir_path)\n",
        "        except OSError as e:\n",
        "            if e.errno != errno.EEXIST:\n",
        "                raise    \n",
        "    \n",
        "    \n",
        "    with open(os.path.join(save_dir_path, 'pre_train_result.pkl'), 'wb') as f:\n",
        "        pickle.dump(pre_train_result, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    with open(os.path.join(save_dir_path, 'init_result.pkl'), 'wb') as f:\n",
        "        pickle.dump(initialization_result, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    # with open(os.path.join(save_dir_path, 'pooled_train_result.pkl'), 'wb') as f:\n",
        "    #     pickle.dump(pooled_train_result, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    with open(os.path.join(save_dir_path, 'col_performance.pkl'), 'wb') as f:\n",
        "        pickle.dump(collaboration_performance, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dpvobrIp07z",
        "outputId": "efe534ee-4cf0-488f-9da3-629f63a5bb20"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting CIFAR_noniid.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CIFAR_noniid_conf.json\n",
        "{\n",
        "    \"models\": [{\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 128, \"n2\": 256, \"dropout_rate\": 0.2}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 128, \"n2\": 384, \"dropout_rate\": 0.2}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 128, 'n2': 512, \"dropout_rate\": 0.2}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 256, \"n2\": 256, \"dropout_rate\": 0.3}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 256, \"n2\": 512, \"dropout_rate\": 0.4}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 64, \"n2\": 128, \"dropout_rate\": 0.2}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 64, \"n2\": 128, \"dropout_rate\": 0.2}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 128, \"n2\": 192, \"dropout_rate\": 0.2}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 128, \"n2\": 128, \"dropout_rate\": 0.3}},\n",
        "               {\"model_type\": \"2_layer_CNN\", \"params\": {\"n1\": 128, \"n2\": 128, \"dropout_rate\": 0.3}}\n",
        "              ],\n",
        "    \"pre_train_params\": {\"min_delta\": 0.001, \"patience\": 3,\n",
        "                     \"batch_size\": 128, \"epochs\": 2, \"is_shuffle\": True, \n",
        "                     \"verbose\": 1},\n",
        "    \"model_saved_dir\": None,\n",
        "    \"model_saved_names\" : [\"CNN_128_256\", \"CNN_128_384\", \"CNN_128_512\", \"CNN_256_256\", \"CNN_256_512\", \n",
        "                    \"CNN_64_128_256\", \"CNN_64_128_192\", \"CNN_128_192_256\", \"CNN_128_128_128\", \"CNN_128_128_192\"],\n",
        "    \"early_stopping\" : False,\n",
        "    \"N_parties\": 10,\n",
        "    \"N_samples_per_class\": 3,\n",
        "    \"N_alignment\": 5000, \n",
        "    \"private_classes\": [10, 11, 12, 13, 14, 15], \n",
        "    \"public_classes\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
        "    \"is_show\": False,\n",
        "    \"N_rounds\": 3,\n",
        "    \"N_logits_matching_round\": 1, \n",
        "    \"N_private_training_round\": 4,\n",
        "    \"private_training_batchsize\" : 5, \n",
        "    \"logits_matching_batchsize\": 256, \n",
        "    \"EMNIST_dir\": \"emnist-letters.mat\",\n",
        "    \"result_save_dir\": \"./result_FEMNIST_imbalanced/\"\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeN0_H9Ip8ld",
        "outputId": "f6a8033b-b754-4abe-c660-b52bafe624c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting CIFAR_noniid_conf.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python CIFAR_noniid.py -conf CIFAR_noniid_conf.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7CUE8H5qB2W",
        "outputId": "a47fdc14-e5e2-4b6e-b46e-1aacb436bff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 59  62  63]\n",
            "  [ 43  46  45]\n",
            "  [ 50  48  43]\n",
            "  ...\n",
            "  [158 132 108]\n",
            "  [152 125 102]\n",
            "  [148 124 103]]\n",
            "\n",
            " [[ 16  20  20]\n",
            "  [  0   0   0]\n",
            "  [ 18   8   0]\n",
            "  ...\n",
            "  [123  88  55]\n",
            "  [119  83  50]\n",
            "  [122  87  57]]\n",
            "\n",
            " [[ 25  24  21]\n",
            "  [ 16   7   0]\n",
            "  [ 49  27   8]\n",
            "  ...\n",
            "  [118  84  50]\n",
            "  [120  84  50]\n",
            "  [109  73  42]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[208 170  96]\n",
            "  [201 153  34]\n",
            "  [198 161  26]\n",
            "  ...\n",
            "  [160 133  70]\n",
            "  [ 56  31   7]\n",
            "  [ 53  34  20]]\n",
            "\n",
            " [[180 139  96]\n",
            "  [173 123  42]\n",
            "  [186 144  30]\n",
            "  ...\n",
            "  [184 148  94]\n",
            "  [ 97  62  34]\n",
            "  [ 83  53  34]]\n",
            "\n",
            " [[177 144 116]\n",
            "  [168 129  94]\n",
            "  [179 142  87]\n",
            "  ...\n",
            "  [216 184 140]\n",
            "  [151 118  84]\n",
            "  [123  92  72]]]\n",
            "total_private_data {'X': array([[[[126, 179, 220],\n",
            "         [126, 178, 218],\n",
            "         [126, 179, 219],\n",
            "         ...,\n",
            "         [123, 175, 219],\n",
            "         [123, 175, 219],\n",
            "         [123, 175, 216]],\n",
            "\n",
            "        [[129, 182, 222],\n",
            "         [128, 181, 221],\n",
            "         [128, 182, 222],\n",
            "         ...,\n",
            "         [126, 179, 219],\n",
            "         [122, 179, 221],\n",
            "         [123, 178, 219]],\n",
            "\n",
            "        [[128, 181, 221],\n",
            "         [127, 180, 220],\n",
            "         [127, 180, 220],\n",
            "         ...,\n",
            "         [123, 167, 195],\n",
            "         [122, 176, 216],\n",
            "         [123, 176, 219]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 33,  49,  29],\n",
            "         [ 43,  61,  50],\n",
            "         [ 78, 100, 103],\n",
            "         ...,\n",
            "         [130, 180, 207],\n",
            "         [ 87, 118, 107],\n",
            "         [ 53,  72,  25]],\n",
            "\n",
            "        [[ 44,  59,  45],\n",
            "         [ 37,  53,  45],\n",
            "         [ 47,  61,  63],\n",
            "         ...,\n",
            "         [124, 175, 195],\n",
            "         [ 88, 120,  96],\n",
            "         [ 51,  71,  22]],\n",
            "\n",
            "        [[ 38,  51,  42],\n",
            "         [ 14,  24,  18],\n",
            "         [ 26,  33,  32],\n",
            "         ...,\n",
            "         [100, 143, 144],\n",
            "         [ 57,  83,  46],\n",
            "         [ 44,  58,  29]]],\n",
            "\n",
            "\n",
            "       [[[205, 208, 222],\n",
            "         [186, 191, 207],\n",
            "         [172, 179, 197],\n",
            "         ...,\n",
            "         [ 62,  45,  39],\n",
            "         [ 63,  46,  39],\n",
            "         [ 62,  45,  38]],\n",
            "\n",
            "        [[233, 233, 239],\n",
            "         [219, 221, 229],\n",
            "         [203, 207, 217],\n",
            "         ...,\n",
            "         [ 64,  47,  40],\n",
            "         [ 64,  46,  39],\n",
            "         [ 63,  46,  39]],\n",
            "\n",
            "        [[240, 237, 237],\n",
            "         [232, 232, 233],\n",
            "         [217, 218, 221],\n",
            "         ...,\n",
            "         [ 65,  48,  41],\n",
            "         [ 64,  48,  41],\n",
            "         [ 63,  46,  39]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[197, 181, 169],\n",
            "         [198, 182, 170],\n",
            "         [206, 190, 178],\n",
            "         ...,\n",
            "         [230, 214, 208],\n",
            "         [225, 209, 203],\n",
            "         [216, 199, 193]],\n",
            "\n",
            "        [[185, 171, 161],\n",
            "         [194, 181, 171],\n",
            "         [181, 167, 157],\n",
            "         ...,\n",
            "         [225, 207, 198],\n",
            "         [224, 206, 196],\n",
            "         [221, 203, 194]],\n",
            "\n",
            "        [[150, 139, 131],\n",
            "         [170, 159, 151],\n",
            "         [153, 141, 134],\n",
            "         ...,\n",
            "         [213, 197, 185],\n",
            "         [221, 204, 192],\n",
            "         [219, 203, 191]]],\n",
            "\n",
            "\n",
            "       [[[ 46,  54,  33],\n",
            "         [ 38,  45,  30],\n",
            "         [ 35,  42,  26],\n",
            "         ...,\n",
            "         [ 76,  88,  50],\n",
            "         [ 95, 101,  66],\n",
            "         [120, 121,  87]],\n",
            "\n",
            "        [[ 42,  49,  30],\n",
            "         [ 31,  38,  23],\n",
            "         [ 30,  37,  19],\n",
            "         ...,\n",
            "         [ 88,  93,  57],\n",
            "         [114, 120,  84],\n",
            "         [117, 124,  88]],\n",
            "\n",
            "        [[ 37,  44,  26],\n",
            "         [ 26,  32,  17],\n",
            "         [ 33,  41,  20],\n",
            "         ...,\n",
            "         [103, 104,  70],\n",
            "         [116, 122,  86],\n",
            "         [103, 114,  77]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[152, 160, 160],\n",
            "         [145, 151, 155],\n",
            "         [137, 143, 149],\n",
            "         ...,\n",
            "         [ 94,  99,  86],\n",
            "         [114, 115, 105],\n",
            "         [132, 132, 124]],\n",
            "\n",
            "        [[126, 130, 124],\n",
            "         [144, 147, 146],\n",
            "         [157, 159, 163],\n",
            "         ...,\n",
            "         [106, 109, 106],\n",
            "         [115, 114, 112],\n",
            "         [116, 118, 116]],\n",
            "\n",
            "        [[151, 152, 139],\n",
            "         [132, 131, 125],\n",
            "         [124, 122, 122],\n",
            "         ...,\n",
            "         [131, 131, 139],\n",
            "         [133, 130, 137],\n",
            "         [129, 133, 137]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[209, 207, 209],\n",
            "         [204, 204, 202],\n",
            "         [212, 207, 204],\n",
            "         ...,\n",
            "         [211, 204, 207],\n",
            "         [209, 198, 199],\n",
            "         [205, 202, 195]],\n",
            "\n",
            "        [[214, 222, 227],\n",
            "         [204, 214, 214],\n",
            "         [207, 212, 212],\n",
            "         ...,\n",
            "         [190, 198, 200],\n",
            "         [179, 180, 179],\n",
            "         [181, 183, 176]],\n",
            "\n",
            "        [[237, 234, 232],\n",
            "         [206, 206, 199],\n",
            "         [197, 192, 184],\n",
            "         ...,\n",
            "         [183, 192, 178],\n",
            "         [170, 172, 156],\n",
            "         [169, 174, 152]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[222, 204, 181],\n",
            "         [213, 198, 174],\n",
            "         [212, 191, 169],\n",
            "         ...,\n",
            "         [204, 187, 155],\n",
            "         [213, 194, 165],\n",
            "         [219, 195, 172]],\n",
            "\n",
            "        [[225, 207, 182],\n",
            "         [215, 199, 174],\n",
            "         [211, 191, 167],\n",
            "         ...,\n",
            "         [222, 202, 174],\n",
            "         [225, 203, 176],\n",
            "         [229, 204, 180]],\n",
            "\n",
            "        [[230, 207, 182],\n",
            "         [222, 201, 176],\n",
            "         [223, 198, 174],\n",
            "         ...,\n",
            "         [231, 208, 183],\n",
            "         [230, 206, 182],\n",
            "         [233, 206, 183]]],\n",
            "\n",
            "\n",
            "       [[[139, 161, 194],\n",
            "         [140, 162, 194],\n",
            "         [144, 164, 194],\n",
            "         ...,\n",
            "         [143, 169, 202],\n",
            "         [136, 168, 204],\n",
            "         [131, 169, 208]],\n",
            "\n",
            "        [[136, 168, 206],\n",
            "         [137, 168, 203],\n",
            "         [139, 169, 204],\n",
            "         ...,\n",
            "         [154, 169, 193],\n",
            "         [151, 169, 194],\n",
            "         [145, 168, 200]],\n",
            "\n",
            "        [[144, 167, 200],\n",
            "         [144, 167, 197],\n",
            "         [141, 169, 202],\n",
            "         ...,\n",
            "         [149, 165, 189],\n",
            "         [150, 165, 188],\n",
            "         [148, 164, 188]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 83,  85,  88],\n",
            "         [ 80,  82,  85],\n",
            "         [ 79,  81,  85],\n",
            "         ...,\n",
            "         [ 77,  79,  81],\n",
            "         [ 77,  78,  81],\n",
            "         [ 77,  78,  80]],\n",
            "\n",
            "        [[ 68,  71,  77],\n",
            "         [ 66,  70,  75],\n",
            "         [ 67,  70,  75],\n",
            "         ...,\n",
            "         [ 77,  79,  81],\n",
            "         [ 77,  78,  80],\n",
            "         [ 75,  76,  79]],\n",
            "\n",
            "        [[ 60,  64,  72],\n",
            "         [ 60,  64,  71],\n",
            "         [ 61,  66,  71],\n",
            "         ...,\n",
            "         [ 76,  77,  80],\n",
            "         [ 75,  76,  80],\n",
            "         [ 73,  74,  78]]],\n",
            "\n",
            "\n",
            "       [[[200, 217, 224],\n",
            "         [196, 213, 220],\n",
            "         [196, 213, 220],\n",
            "         ...,\n",
            "         [ 92, 165, 193],\n",
            "         [ 93, 156, 178],\n",
            "         [ 31,  77,  90]],\n",
            "\n",
            "        [[204, 218, 228],\n",
            "         [201, 215, 226],\n",
            "         [200, 214, 225],\n",
            "         ...,\n",
            "         [ 99, 171, 189],\n",
            "         [ 89, 150, 162],\n",
            "         [ 19,  53,  56]],\n",
            "\n",
            "        [[204, 217, 230],\n",
            "         [206, 218, 232],\n",
            "         [205, 217, 231],\n",
            "         ...,\n",
            "         [120, 180, 190],\n",
            "         [ 59, 105, 109],\n",
            "         [  5,  25,  22]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[188, 192, 182],\n",
            "         [194, 195, 187],\n",
            "         [201, 200, 191],\n",
            "         ...,\n",
            "         [104, 110, 108],\n",
            "         [ 55,  61,  59],\n",
            "         [ 28,  34,  32]],\n",
            "\n",
            "        [[182, 188, 179],\n",
            "         [188, 191, 184],\n",
            "         [193, 195, 189],\n",
            "         ...,\n",
            "         [ 32,  38,  36],\n",
            "         [ 28,  34,  32],\n",
            "         [ 26,  32,  30]],\n",
            "\n",
            "        [[184, 189, 181],\n",
            "         [191, 194, 187],\n",
            "         [199, 200, 195],\n",
            "         ...,\n",
            "         [ 30,  35,  34],\n",
            "         [ 26,  31,  29],\n",
            "         [ 23,  28,  27]]]], dtype=uint8), 'y': array([0, 1, 1, ..., 7, 9, 9], dtype=uint8)}\n",
            "private_test_data: {'X': array([[[[190, 185, 181],\n",
            "         [188, 183, 179],\n",
            "         [188, 183, 179],\n",
            "         ...,\n",
            "         [193, 196, 193],\n",
            "         [193, 195, 192],\n",
            "         [191, 194, 190]],\n",
            "\n",
            "        [[193, 188, 184],\n",
            "         [192, 187, 183],\n",
            "         [192, 187, 183],\n",
            "         ...,\n",
            "         [194, 196, 192],\n",
            "         [194, 196, 192],\n",
            "         [192, 194, 191]],\n",
            "\n",
            "        [[191, 186, 182],\n",
            "         [191, 186, 182],\n",
            "         [192, 187, 183],\n",
            "         ...,\n",
            "         [192, 193, 188],\n",
            "         [192, 193, 188],\n",
            "         [190, 191, 187]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[206, 173, 130],\n",
            "         [206, 173, 130],\n",
            "         [207, 174, 131],\n",
            "         ...,\n",
            "         [214, 182, 142],\n",
            "         [214, 182, 142],\n",
            "         [214, 182, 142]],\n",
            "\n",
            "        [[207, 174, 134],\n",
            "         [207, 174, 134],\n",
            "         [207, 174, 134],\n",
            "         ...,\n",
            "         [216, 184, 142],\n",
            "         [216, 185, 142],\n",
            "         [216, 184, 143]],\n",
            "\n",
            "        [[195, 164, 126],\n",
            "         [195, 163, 126],\n",
            "         [192, 160, 122],\n",
            "         ...,\n",
            "         [213, 183, 139],\n",
            "         [214, 183, 139],\n",
            "         [213, 182, 139]]],\n",
            "\n",
            "\n",
            "       [[[243, 247, 249],\n",
            "         [229, 233, 235],\n",
            "         [234, 237, 238],\n",
            "         ...,\n",
            "         [233, 236, 237],\n",
            "         [233, 235, 236],\n",
            "         [240, 241, 240]],\n",
            "\n",
            "        [[191, 201, 208],\n",
            "         [117, 135, 149],\n",
            "         [127, 144, 157],\n",
            "         ...,\n",
            "         [142, 155, 166],\n",
            "         [138, 150, 159],\n",
            "         [179, 181, 183]],\n",
            "\n",
            "        [[184, 193, 200],\n",
            "         [101, 120, 136],\n",
            "         [110, 127, 141],\n",
            "         ...,\n",
            "         [117, 133, 148],\n",
            "         [113, 129, 139],\n",
            "         [160, 164, 173]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[247, 246, 247],\n",
            "         [232, 232, 232],\n",
            "         [233, 235, 235],\n",
            "         ...,\n",
            "         [234, 238, 238],\n",
            "         [233, 237, 236],\n",
            "         [239, 241, 240]],\n",
            "\n",
            "        [[255, 255, 255],\n",
            "         [254, 254, 255],\n",
            "         [255, 255, 254],\n",
            "         ...,\n",
            "         [255, 254, 254],\n",
            "         [255, 254, 254],\n",
            "         [255, 254, 254]],\n",
            "\n",
            "        [[255, 255, 255],\n",
            "         [254, 254, 254],\n",
            "         [255, 255, 255],\n",
            "         ...,\n",
            "         [255, 255, 255],\n",
            "         [255, 255, 255],\n",
            "         [255, 255, 255]]],\n",
            "\n",
            "\n",
            "       [[[122, 127, 140],\n",
            "         [122, 127, 141],\n",
            "         [122, 127, 144],\n",
            "         ...,\n",
            "         [112, 120, 138],\n",
            "         [109, 117, 136],\n",
            "         [108, 116, 135]],\n",
            "\n",
            "        [[131, 135, 147],\n",
            "         [129, 133, 147],\n",
            "         [133, 136, 152],\n",
            "         ...,\n",
            "         [125, 132, 149],\n",
            "         [122, 129, 147],\n",
            "         [120, 127, 145]],\n",
            "\n",
            "        [[134, 137, 148],\n",
            "         [133, 136, 148],\n",
            "         [138, 140, 155],\n",
            "         ...,\n",
            "         [128, 133, 148],\n",
            "         [126, 131, 146],\n",
            "         [126, 131, 145]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 69,  81,  93],\n",
            "         [ 43,  48,  51],\n",
            "         [ 35,  38,  38],\n",
            "         ...,\n",
            "         [100, 109, 120],\n",
            "         [ 93, 104, 120],\n",
            "         [ 92, 103, 121]],\n",
            "\n",
            "        [[ 62,  73,  84],\n",
            "         [ 52,  56,  58],\n",
            "         [ 48,  49,  48],\n",
            "         ...,\n",
            "         [ 89,  98, 114],\n",
            "         [ 88, 100, 118],\n",
            "         [ 93, 104, 122]],\n",
            "\n",
            "        [[ 61,  71,  81],\n",
            "         [ 52,  54,  56],\n",
            "         [ 56,  56,  54],\n",
            "         ...,\n",
            "         [ 86,  93, 110],\n",
            "         [ 90,  99, 117],\n",
            "         [ 84,  95, 112]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[  1,   1,   1],\n",
            "         [  0,   0,   0],\n",
            "         [  0,   0,   0],\n",
            "         ...,\n",
            "         [  0,   0,   0],\n",
            "         [  0,   0,   0],\n",
            "         [  0,   0,   0]],\n",
            "\n",
            "        [[  1,   1,   1],\n",
            "         [  0,   0,   0],\n",
            "         [  0,   0,   0],\n",
            "         ...,\n",
            "         [  0,   0,   0],\n",
            "         [  0,   0,   0],\n",
            "         [  0,   0,   0]],\n",
            "\n",
            "        [[  1,   1,   1],\n",
            "         [  1,   1,   1],\n",
            "         [  0,   0,   0],\n",
            "         ...,\n",
            "         [  0,   0,   0],\n",
            "         [  0,   0,   0],\n",
            "         [  0,   0,   0]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 56,  26,  11],\n",
            "         [ 54,  25,   9],\n",
            "         [ 54,  26,  11],\n",
            "         ...,\n",
            "         [ 68,  35,  14],\n",
            "         [ 90,  52,  27],\n",
            "         [102,  64,  34]],\n",
            "\n",
            "        [[ 77,  40,  19],\n",
            "         [ 81,  43,  21],\n",
            "         [ 90,  49,  23],\n",
            "         ...,\n",
            "         [ 74,  40,  19],\n",
            "         [112,  74,  50],\n",
            "         [140, 110,  87]],\n",
            "\n",
            "        [[155,  97,  63],\n",
            "         [156,  97,  64],\n",
            "         [157,  98,  64],\n",
            "         ...,\n",
            "         [ 70,  38,  20],\n",
            "         [119,  88,  68],\n",
            "         [152, 125, 106]]],\n",
            "\n",
            "\n",
            "       [[[210, 215, 241],\n",
            "         [200, 210, 237],\n",
            "         [198, 209, 235],\n",
            "         ...,\n",
            "         [207, 223, 238],\n",
            "         [210, 221, 233],\n",
            "         [152, 156, 165]],\n",
            "\n",
            "        [[223, 228, 255],\n",
            "         [212, 222, 251],\n",
            "         [210, 221, 247],\n",
            "         ...,\n",
            "         [217, 235, 251],\n",
            "         [221, 235, 247],\n",
            "         [152, 157, 166]],\n",
            "\n",
            "        [[221, 230, 253],\n",
            "         [210, 224, 249],\n",
            "         [207, 221, 243],\n",
            "         ...,\n",
            "         [215, 235, 250],\n",
            "         [218, 234, 248],\n",
            "         [150, 156, 167]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 70,  71,  90],\n",
            "         [ 66,  67,  87],\n",
            "         [ 63,  64,  81],\n",
            "         ...,\n",
            "         [ 64,  69,  89],\n",
            "         [ 65,  70,  86],\n",
            "         [ 78,  81,  88]],\n",
            "\n",
            "        [[ 77,  76,  90],\n",
            "         [ 73,  73,  88],\n",
            "         [ 70,  70,  81],\n",
            "         ...,\n",
            "         [ 72,  74,  89],\n",
            "         [ 72,  75,  87],\n",
            "         [ 82,  85,  88]],\n",
            "\n",
            "        [[114, 114, 121],\n",
            "         [108, 109, 117],\n",
            "         [108, 109, 114],\n",
            "         ...,\n",
            "         [109, 111, 121],\n",
            "         [108, 109, 118],\n",
            "         [116, 117, 119]]],\n",
            "\n",
            "\n",
            "       [[[ 20,  37,  14],\n",
            "         [ 45,  59,  43],\n",
            "         [ 89,  99,  99],\n",
            "         ...,\n",
            "         [  8,   8,   6],\n",
            "         [ 12,   7,   5],\n",
            "         [  8,   8,   3]],\n",
            "\n",
            "        [[ 18,  33,  13],\n",
            "         [ 44,  58,  43],\n",
            "         [ 77,  88,  87],\n",
            "         ...,\n",
            "         [  8,   6,   5],\n",
            "         [ 17,   5,   4],\n",
            "         [  7,   5,   2]],\n",
            "\n",
            "        [[ 28,  43,  17],\n",
            "         [ 43,  59,  35],\n",
            "         [ 63,  77,  67],\n",
            "         ...,\n",
            "         [  9,   4,   4],\n",
            "         [ 25,   6,   5],\n",
            "         [ 12,   6,   4]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[129, 130, 126],\n",
            "         [146, 145, 141],\n",
            "         [128, 127, 122],\n",
            "         ...,\n",
            "         [126, 123, 114],\n",
            "         [139, 137, 126],\n",
            "         [108, 103,  91]],\n",
            "\n",
            "        [[126, 120, 112],\n",
            "         [122, 113, 107],\n",
            "         [101,  90,  85],\n",
            "         ...,\n",
            "         [ 96,  95,  77],\n",
            "         [127, 122, 102],\n",
            "         [128, 123, 103]],\n",
            "\n",
            "        [[119, 105,  94],\n",
            "         [ 65,  46,  40],\n",
            "         [ 42,  20,  17],\n",
            "         ...,\n",
            "         [101,  97,  83],\n",
            "         [119, 112,  94],\n",
            "         [124, 117, 101]]]], dtype=uint8), 'y': array([0, 0, 1, ..., 7, 8, 9], dtype=uint8)}\n",
            "private_test_data[X].shape: (8000, 32, 32, 3)\n",
            "2022-01-12 02:24:12.591050: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "model 0 : CNN_128_256\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 1 : CNN_128_384\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 2 : CNN_128_512\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 14, 14, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 3 : CNN_256_256\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_3 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 14, 14, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 4 : CNN_256_512\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_4 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 14, 14, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 5 : CNN_64_128_256\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_5 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 6 : CNN_64_128_192\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_6 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 7 : CNN_128_192_256\n",
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_7 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 8 : CNN_128_128_128\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_8 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "model 9 : CNN_128_128_192\n",
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape_9 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training model  0\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 14.1359 - accuracy: 0.0990 - val_loss: 14.5627 - val_accuracy: 0.0965\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 8s 96ms/step - loss: 14.5047 - accuracy: 0.1001 - val_loss: 14.5627 - val_accuracy: 0.0965\n",
            "Training model  1\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 8s 97ms/step - loss: 6.9241 - accuracy: 0.1009 - val_loss: 6.6925 - val_accuracy: 0.1080\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 7s 94ms/step - loss: 6.8168 - accuracy: 0.1030 - val_loss: 6.6847 - val_accuracy: 0.1080\n",
            "Training model  2\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 8s 97ms/step - loss: 14.2489 - accuracy: 0.1035 - val_loss: 14.3710 - val_accuracy: 0.1085\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 8s 96ms/step - loss: 14.4684 - accuracy: 0.1025 - val_loss: 14.3693 - val_accuracy: 0.1085\n",
            "Training model  3\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 8s 97ms/step - loss: 14.3341 - accuracy: 0.1028 - val_loss: 14.3773 - val_accuracy: 0.1080\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 7s 95ms/step - loss: 14.4579 - accuracy: 0.1030 - val_loss: 14.3773 - val_accuracy: 0.1080\n",
            "Training model  4\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 8s 97ms/step - loss: 12.1316 - accuracy: 0.0996 - val_loss: 12.2765 - val_accuracy: 0.0990\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 7s 94ms/step - loss: 12.3845 - accuracy: 0.0999 - val_loss: 12.2765 - val_accuracy: 0.0990\n",
            "Training model  5\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 8s 97ms/step - loss: 14.3964 - accuracy: 0.1007 - val_loss: 14.5224 - val_accuracy: 0.0990\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 8s 96ms/step - loss: 14.5025 - accuracy: 0.0999 - val_loss: 14.5224 - val_accuracy: 0.0990\n",
            "Training model  6\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 8s 97ms/step - loss: 8.9574 - accuracy: 0.0941 - val_loss: 12.3893 - val_accuracy: 0.0925\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 8s 95ms/step - loss: 12.4766 - accuracy: 0.0937 - val_loss: 12.3898 - val_accuracy: 0.0925\n",
            "Training model  7\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 11.0026 - accuracy: 0.1020 - val_loss: 11.1861 - val_accuracy: 0.0995\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 8s 96ms/step - loss: 11.2084 - accuracy: 0.1016 - val_loss: 11.1861 - val_accuracy: 0.0995\n",
            "Training model  8\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 12.4101 - accuracy: 0.0925 - val_loss: 12.5344 - val_accuracy: 0.0925\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 12.5118 - accuracy: 0.0937 - val_loss: 12.5344 - val_accuracy: 0.0925\n",
            "Training model  9\n",
            "Epoch 1/2\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 13.2969 - accuracy: 0.1052 - val_loss: 13.5784 - val_accuracy: 0.1120\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 14.0034 - accuracy: 0.1071 - val_loss: 14.5224 - val_accuracy: 0.0990\n",
            "pre-train accuracy: \n",
            "[0.09650000184774399, 0.1080000028014183, 0.10849999636411667, 0.1080000028014183, 0.0989999994635582, 0.0989999994635582, 0.0925000011920929, 0.09950000047683716, 0.0925000011920929, 0.0989999994635582]\n",
            "start model initialization: \n",
            "model  0\n",
            "start full stack training ... \n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 9s 71ms/step - loss: 14.5103 - accuracy: 0.0997 - val_loss: 14.4922 - val_accuracy: 0.1009\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 7s 53ms/step - loss: 14.5103 - accuracy: 0.0997 - val_loss: 14.4922 - val_accuracy: 0.1009\n",
            "full stack training done\n",
            "model  1\n",
            "start full stack training ... \n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 7s 54ms/step - loss: 6.7814 - accuracy: 0.1000 - val_loss: 6.8055 - val_accuracy: 0.0980\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 6s 51ms/step - loss: 6.7814 - accuracy: 0.1000 - val_loss: 6.8055 - val_accuracy: 0.0980\n",
            "full stack training done\n",
            "model  2\n",
            "start full stack training ... \n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 7s 53ms/step - loss: 14.5063 - accuracy: 0.1000 - val_loss: 14.5405 - val_accuracy: 0.0979\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 6s 51ms/step - loss: 14.5063 - accuracy: 0.1000 - val_loss: 14.5405 - val_accuracy: 0.0979\n",
            "full stack training done\n",
            "model  3\n",
            "start full stack training ... \n",
            "Epoch 1/2\n",
            "125/125 [==============================] - 7s 53ms/step - loss: 14.5063 - accuracy: 0.1000 - val_loss: 14.5385 - val_accuracy: 0.0980\n",
            "Epoch 2/2\n",
            "125/125 [==============================] - 6s 51ms/step - loss: 14.5063 - accuracy: 0.1000 - val_loss: 14.5385 - val_accuracy: 0.0980\n",
            "full stack training done\n",
            "model  4\n",
            "start full stack training ... \n",
            "Epoch 1/2\n",
            "124/125 [============================>.] - ETA: 0s - loss: 12.3707 - accuracy: 0.1006"
          ]
        }
      ]
    }
  ]
}
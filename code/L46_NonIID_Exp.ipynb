{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L46_NonIID_Exp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqY1zAZanXBR",
        "outputId": "9b179c32-ef45-4217-89e7-827b42c9dd6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flwr==0.17.0 in /usr/local/lib/python3.7/dist-packages (0.17.0)\n",
            "Requirement already satisfied: google<3.0.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (2.0.3)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.12.1 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (3.17.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (1.19.5)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.27.2 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (1.42.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google<3.0.0,>=2.0.3->flwr==0.17.0) (4.6.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<2.0.0,>=1.27.2->flwr==0.17.0) (1.15.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install flwr==0.17.0\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cifar.py\n",
        "\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from torch import Tensor\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "from typing import List, Tuple, Union, cast\n",
        "import pickle\n",
        "\n",
        "from flwr_experimental.baseline.dataset.dataset import create_partitioned_dataset, XY, XYList, shuffle, sort_by_label_repeating, split_at_fraction, shift, partition, combine_partitions, adjust_xy_shape,sort_by_label\n",
        "\n",
        "import flwr as fl\n",
        "\n",
        "class Net(nn.Module):\n",
        "    \"\"\"Simple CNN adapted from 'PyTorch: A 60 Minute Blitz'.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Compute forward pass.\"\"\"\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def get_weights(self) -> fl.common.Weights:\n",
        "        \"\"\"Get model weights as a list of NumPy ndarrays.\"\"\"\n",
        "        return [val.cpu().numpy() for _, val in self.state_dict().items()]\n",
        "\n",
        "    def set_weights(self, weights: fl.common.Weights) -> None:\n",
        "        \"\"\"Set model weights from a list of NumPy ndarrays.\"\"\"\n",
        "        state_dict = OrderedDict(\n",
        "            {k: torch.Tensor(v) for k, v in zip(self.state_dict().keys(), weights)}\n",
        "        )\n",
        "        self.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def load_model():\n",
        "    return Net()\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Loads CIFAR-10 (training and test set).\"\"\"\n",
        "    data_root = \"/content/data/cifar-10\"\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "    trainset = torchvision.datasets.CIFAR10(root=data_root, train=True, download=True, transform=transform)\n",
        "    testset = torchvision.datasets.CIFAR10(root=data_root, train=False, download=True, transform=transform)\n",
        "    return trainset, testset\n",
        "\n",
        "class PartitionedDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.X[idx], int(self.Y[idx]))\n",
        "\n",
        "def load_local_partitioned_data(client_id, num_partitions: int, iid_fraction: float, global_fraction: float, beta: float, alpha: float, classPerClient: int):\n",
        "    \"\"\"Creates a dataset for each worker, which is a partition of a larger dataset.\"\"\"\n",
        "    \n",
        "    # Each worker loads the entire dataset, and then selects its partition\n",
        "    # determined by its `client_id` (happens internally below)\n",
        "    trainset, testset = load_data()\n",
        "    [g_trainset, l_trainset] = torch.utils.data.random_split(trainset, [int(trainset.data.shape[0] * x) for x in [global_fraction,1-global_fraction]])\n",
        "    [g_testset, l_testset] = torch.utils.data.random_split(testset, [int(testset.data.shape[0] * x) for x in [global_fraction,1-global_fraction]])\n",
        "    \n",
        "    if global_fraction!=0.0:\n",
        "      # Process global data\n",
        "      g_train_loader = DataLoader(g_trainset, batch_size=len(g_trainset))\n",
        "      g_test_loader = DataLoader(g_testset, batch_size=len(g_testset))\n",
        "\n",
        "      (g_x_train, g_y_train), (g_x_test, g_y_test) = next(iter(g_train_loader)), next(iter(g_test_loader))\n",
        "      g_x_train, g_y_train = g_x_train.numpy(), g_y_train.numpy()\n",
        "      g_x_test, g_y_test = g_x_test.numpy(), g_y_test.numpy()\n",
        "\n",
        "      #global shared data must be iid\n",
        "      g_iid_fraction = 1.0 \n",
        "\n",
        "      (g_train_partitions, g_test_partitions), _ = create_partitioned_dataset(\n",
        "          ((g_x_train, g_y_train), (g_x_test, g_y_test)), g_iid_fraction, num_partitions)\n",
        "  \n",
        "      g_x_train, g_y_train = g_train_partitions[client_id]\n",
        "      \n",
        "      g_x_test, g_y_test = g_test_partitions[client_id]\n",
        "\n",
        "      # Process local data\n",
        "      l_train_loader = DataLoader(l_trainset, batch_size=len(l_trainset))\n",
        "      l_test_loader = DataLoader(l_testset, batch_size=len(l_testset))\n",
        "\n",
        "      (l_x_train, l_y_train), (l_x_test, l_y_test) = next(iter(l_train_loader)), next(iter(l_test_loader))\n",
        "      l_x_train, l_y_train = l_x_train.numpy(), l_y_train.numpy()\n",
        "      l_x_test, l_y_test = l_x_test.numpy(), l_y_test.numpy()\n",
        "\n",
        "      l_train_partitions=None\n",
        "      l_test_partitions=None\n",
        "\n",
        "      if classPerClient!=-1:\n",
        "        (l_train_partitions, l_test_partitions), _ = create_partitioned_dataset_by_class(\n",
        "            ((l_x_train, l_y_train), (l_x_test, l_y_test)), classPerClient, num_partitions)\n",
        "      else:\n",
        "        (l_train_partitions, l_test_partitions), _ = create_partitioned_dataset(\n",
        "        ((l_x_train, l_y_train), (l_x_test, l_y_test)), iid_fraction, num_partitions)\n",
        "    \n",
        "      l_x_train, l_y_train = l_train_partitions[client_id]\n",
        "      \n",
        "      l_x_test, l_y_test = l_test_partitions[client_id]\n",
        "      \n",
        "      \n",
        "        \n",
        "      #Set beta\n",
        "      g_train_len = int(len(l_x_train)*beta)\n",
        "      [g_x_train, _] = torch.utils.data.random_split(g_x_train, [g_train_len, len(g_x_train)-g_train_len])\n",
        "      [g_y_train, _] = torch.utils.data.random_split(g_y_train, [g_train_len, len(g_y_train)-g_train_len])\n",
        "      g_torch_partition_trainset = PartitionedDataset(torch.Tensor(np.asarray(g_x_train)), g_y_train)\n",
        "\n",
        "\n",
        "      g_test_len = int(len(l_x_test)*beta)\n",
        "      [g_x_test, _] = torch.utils.data.random_split(g_x_test, [g_test_len, len(g_x_test)-g_test_len])\n",
        "      [g_y_test, _] = torch.utils.data.random_split(g_y_test, [g_test_len, len(g_y_test)-g_test_len])\n",
        "      g_torch_partition_testset = PartitionedDataset(torch.Tensor(np.asarray(g_x_test)), g_y_test )\n",
        "\n",
        "      g_train_info = get_data_info(g_y_train)\n",
        "\n",
        "      if alpha != 0.0:\n",
        "        #Set alpha\n",
        "        g_combined_train_len = int(len(g_x_train)*alpha)\n",
        "        [g_x_train_combined, _] = torch.utils.data.random_split(g_x_train, [g_combined_train_len, len(g_x_train)-g_combined_train_len])\n",
        "        [g_y_train_combined, _] = torch.utils.data.random_split(g_y_train, [g_combined_train_len, len(g_y_train)-g_combined_train_len])\n",
        "\n",
        "        g_combined_test_len = int(len(g_x_test)*alpha)\n",
        "        [g_x_test_combined, _] = torch.utils.data.random_split(g_x_test, [g_combined_test_len, len(g_x_test)-g_combined_test_len])\n",
        "        [g_y_test_combined, _] = torch.utils.data.random_split(g_y_test, [g_combined_test_len, len(g_y_test)-g_combined_test_len])\n",
        "        \n",
        "        l_x_train = np.concatenate((g_x_train_combined, l_x_train))\n",
        "        l_y_train = np.concatenate((g_y_train_combined, l_y_train))\n",
        "        l_x_test = np.concatenate((g_x_test_combined, l_x_test))\n",
        "        l_y_test = np.concatenate((g_y_test_combined, l_y_test))\n",
        "\n",
        "      l_torch_partition_trainset = PartitionedDataset(torch.Tensor(np.asarray(l_x_train)), l_y_train)\n",
        "      l_torch_partition_testset = PartitionedDataset(torch.Tensor(np.asarray(l_x_test)), l_y_test)\n",
        "      l_train_info = get_data_info(l_y_train)\n",
        "    else: #Process local data only\n",
        "      l_train_loader = DataLoader(l_trainset, batch_size=len(l_trainset))\n",
        "      l_test_loader = DataLoader(l_testset, batch_size=len(l_testset))\n",
        "\n",
        "      (l_x_train, l_y_train), (l_x_test, l_y_test) = next(iter(l_train_loader)), next(iter(l_test_loader))\n",
        "      l_x_train, l_y_train = l_x_train.numpy(), l_y_train.numpy()\n",
        "      l_x_test, l_y_test = l_x_test.numpy(), l_y_test.numpy()\n",
        "\n",
        "      l_train_partitions=None\n",
        "      l_test_partitions=None\n",
        "      \n",
        "      if classPerClient!=-1:\n",
        "        (l_train_partitions, l_test_partitions), _ = create_partitioned_dataset_by_class(\n",
        "            ((l_x_train, l_y_train), (l_x_test, l_y_test)), classPerClient, num_partitions)\n",
        "      else:\n",
        "        (l_train_partitions, l_test_partitions), _ = create_partitioned_dataset(\n",
        "        ((l_x_train, l_y_train), (l_x_test, l_y_test)), iid_fraction, num_partitions)\n",
        "  \n",
        "      l_x_train, l_y_train = l_train_partitions[client_id]\n",
        "      l_x_test, l_y_test = l_test_partitions[client_id]\n",
        "\n",
        "      l_torch_partition_trainset = PartitionedDataset(torch.Tensor(np.asarray(l_x_train)), l_y_train)\n",
        "      l_torch_partition_testset = PartitionedDataset(torch.Tensor(np.asarray(l_x_test)), l_y_test)\n",
        "      l_train_info = get_data_info(l_y_train)\n",
        "      g_torch_partition_trainset=None\n",
        "      g_torch_partition_testset=None\n",
        "      g_train_info=None\n",
        "\n",
        "    return g_torch_partition_trainset, g_torch_partition_testset, l_torch_partition_trainset, l_torch_partition_testset, g_train_info, l_train_info\n",
        "\n",
        "\n",
        "def create_partitioned_dataset_by_class(keras_dataset: Tuple[XY, XY], classPerClient: int, num_partitions: int,) -> Tuple[PartitionedDataset, XY]:\n",
        "    xy_train, xy_test = keras_dataset\n",
        "\n",
        "    xy_train_partitions = create_partitions_by_class(\n",
        "        unpartitioned_dataset=xy_train,\n",
        "        classPerClient=classPerClient,\n",
        "        num_partitions=num_partitions,\n",
        "    )\n",
        "\n",
        "    xy_test_partitions = create_partitions_by_class(\n",
        "        unpartitioned_dataset=xy_test,\n",
        "        classPerClient=classPerClient,\n",
        "        num_partitions=num_partitions,\n",
        "    )\n",
        "\n",
        "    return (xy_train_partitions, xy_test_partitions), adjust_xy_shape(xy_test)\n",
        "\n",
        "def create_partitions_by_class(unpartitioned_dataset: XY, classPerClient: int, num_partitions: int,) -> XYList: #10 clients\n",
        "    \"\"\"Create partitioned version of a training or test set.\n",
        "\n",
        "    Currently tested and supported are MNIST, FashionMNIST and\n",
        "    CIFAR-10/100\n",
        "    \"\"\"\n",
        "    x, y = unpartitioned_dataset\n",
        "\n",
        "    x, y = shuffle(x, y)\n",
        "    x, y = sort_by_label(x, y)\n",
        "    u, class_idx = np.unique(y, return_index=True)\n",
        "    x_partitions = np.split(x,class_idx[1:])\n",
        "    y_partitions = np.split(y,class_idx[1:])\n",
        "    xy_partitions = None;\n",
        "    if classPerClient==1:\n",
        "      xy_partitions = list(zip(x_partitions, y_partitions))\n",
        "    else:#classPerClient==2;\n",
        "      two_class_x_partitions = []\n",
        "      two_class_y_partitions = []\n",
        "      for i in list(range(10)):\n",
        "        [rand_1, rand_2] = random.sample(range(0, 10), 2)\n",
        "        two_class_x_partitions.append(np.concatenate((x_partitions[rand_1],x_partitions[rand_2])))\n",
        "        two_class_y_partitions.append(np.concatenate((y_partitions[rand_1],y_partitions[rand_2])))\n",
        "      xy_partitions = list(zip(two_class_x_partitions, two_class_y_partitions))\n",
        "\n",
        "    # Adjust x and y shape\n",
        "    return [adjust_xy_shape(xy) for xy in xy_partitions]\n",
        "\n",
        "# def load_local_partitioned_data(client_id, iid_fraction: float, num_partitions: int, global_fraction: float, beta: float, alpha: float):\n",
        "#     \"\"\"Creates a dataset for each worker, which is a partition of a larger dataset.\"\"\"\n",
        "    \n",
        "#     # Each worker loads the entire dataset, and then selects its partition\n",
        "#     # determined by its `client_id` (happens internally below)\n",
        "#     trainset, testset = load_data()\n",
        "\n",
        "#     [g_trainset, l_trainset] = torch.utils.data.random_split(trainset, [int(trainset.data.shape[0] * x) for x in [global_fraction,1-global_fraction]])\n",
        "#     [g_testset, l_testset] = torch.utils.data.random_split(testset, [int(testset.data.shape[0] * x) for x in [global_fraction,1-global_fraction]])\n",
        "    \n",
        "#     # Process global data\n",
        "#     g_train_loader = DataLoader(g_trainset, batch_size=len(g_trainset))\n",
        "#     g_test_loader = DataLoader(g_testset, batch_size=len(g_testset))\n",
        "\n",
        "#     (g_x_train, g_y_train), (g_x_test, g_y_test) = next(iter(g_train_loader)), next(iter(g_test_loader))\n",
        "#     g_x_train, g_y_train = g_x_train.numpy(), g_y_train.numpy()\n",
        "#     g_x_test, g_y_test = g_x_test.numpy(), g_y_test.numpy()\n",
        "\n",
        "#     #global shared data must be iid\n",
        "#     g_iid_fraction = 1.0 \n",
        "\n",
        "#     (g_train_partitions, g_test_partitions), _ = create_partitioned_dataset(\n",
        "#         ((g_x_train, g_y_train), (g_x_test, g_y_test)), g_iid_fraction, num_partitions)\n",
        " \n",
        "#     g_x_train, g_y_train = g_train_partitions[client_id]\n",
        "    \n",
        "#     g_x_test, g_y_test = g_test_partitions[client_id]\n",
        "\n",
        "#     # Process local data\n",
        "#     l_train_loader = DataLoader(l_trainset, batch_size=len(l_trainset))\n",
        "#     l_test_loader = DataLoader(l_testset, batch_size=len(l_testset))\n",
        "\n",
        "#     (l_x_train, l_y_train), (l_x_test, l_y_test) = next(iter(l_train_loader)), next(iter(l_test_loader))\n",
        "#     l_x_train, l_y_train = l_x_train.numpy(), l_y_train.numpy()\n",
        "#     l_x_test, l_y_test = l_x_test.numpy(), l_y_test.numpy()\n",
        "\n",
        "#     (l_train_partitions, l_test_partitions), _ = create_partitioned_dataset(\n",
        "#         ((l_x_train, l_y_train), (l_x_test, l_y_test)), iid_fraction, num_partitions)\n",
        " \n",
        "#     l_x_train, l_y_train = l_train_partitions[client_id]\n",
        "    \n",
        "#     l_x_test, l_y_test = l_test_partitions[client_id]\n",
        "    \n",
        "\n",
        "#     #Set beta\n",
        "#     g_train_len = int(len(l_x_train)*beta)\n",
        "#     [g_x_train, _] = torch.utils.data.random_split(g_x_train, [g_train_len, len(g_x_train)-g_train_len])\n",
        "#     [g_y_train, _] = torch.utils.data.random_split(g_y_train, [g_train_len, len(g_y_train)-g_train_len])\n",
        "#     g_torch_partition_trainset = PartitionedDataset(torch.Tensor(np.asarray(g_x_train)), g_y_train)\n",
        "\n",
        "\n",
        "#     g_test_len = int(len(l_x_test)*beta)\n",
        "#     [g_x_test, _] = torch.utils.data.random_split(g_x_test, [g_test_len, len(g_x_test)-g_test_len])\n",
        "#     [g_y_test, _] = torch.utils.data.random_split(g_y_test, [g_test_len, len(g_y_test)-g_test_len])\n",
        "#     g_torch_partition_testset = PartitionedDataset(torch.Tensor(np.asarray(g_x_test)), g_y_test )\n",
        "\n",
        "#     g_train_info = get_data_info(g_y_train)\n",
        "\n",
        "#     #Set alpha\n",
        "#     if alpha != 0.0:\n",
        "#       g_combined_train_len = int(len(g_x_train)*alpha)\n",
        "#       [g_x_train_combined, _] = torch.utils.data.random_split(g_x_train, [g_combined_train_len, len(g_x_train)-g_combined_train_len])\n",
        "#       [g_y_train_combined, _] = torch.utils.data.random_split(g_y_train, [g_combined_train_len, len(g_y_train)-g_combined_train_len])\n",
        "\n",
        "#       g_combined_test_len = int(len(g_x_test)*alpha)\n",
        "#       [g_x_test_combined, _] = torch.utils.data.random_split(g_x_test, [g_combined_test_len, len(g_x_test)-g_combined_test_len])\n",
        "#       [g_y_test_combined, _] = torch.utils.data.random_split(g_y_test, [g_combined_test_len, len(g_y_test)-g_combined_test_len])\n",
        "\n",
        "#       l_x_train = np.concatenate((g_x_train_combined, l_x_train))\n",
        "#       l_y_train = np.concatenate((g_y_train_combined, l_y_train))\n",
        "#       l_x_test = np.concatenate((g_x_test_combined, l_x_test))\n",
        "#       l_y_test = np.concatenate((g_y_test_combined, l_y_test))\n",
        "\n",
        "#     l_torch_partition_trainset = PartitionedDataset(torch.Tensor(np.asarray(l_x_train)), l_y_train)\n",
        "#     l_torch_partition_testset = PartitionedDataset(torch.Tensor(np.asarray(l_x_test)), l_y_test)\n",
        "#     l_train_info = get_data_info(l_y_train)\n",
        "\n",
        "#     return g_torch_partition_trainset, g_torch_partition_testset, l_torch_partition_trainset, l_torch_partition_testset, g_train_info, l_train_info\n",
        "\n",
        "\n",
        "def get_data_info(y):\n",
        "    #total amount of data\n",
        "    length = len(y)\n",
        "    #Class - Sample dictionary\n",
        "    (unique, counts) = np.unique(y, return_counts=True)\n",
        "    return (length, dict(zip(unique, counts)))\n",
        "\n",
        "\n",
        "# def get_partitionedDataset(train_partitions, test_partitions, global_partition, client_id):\n",
        "#       [x_train, y_train] = train_partitions[client_id]\n",
        "#       torch_partition_trainset = PartitionedDataset(torch.Tensor(x_train), y_train)\n",
        "#       x_test, y_test = test_partitions[client_id]\n",
        "#       torch_partition_testset = PartitionedDataset(torch.Tensor(x_test), y_test)\n",
        "#       global_x_train, global_y_train = global_partition[client_id]\n",
        "#       torch_partition_global_trainset = PartitionedDataset(torch.Tensor(global_x_train), global_y_train)\n",
        "#       return torch_partition_trainset, torch_partition_testset, torch_partition_global_trainset\n",
        "\n",
        "\n",
        "def train(\n",
        "    net: Net,\n",
        "    trainloader: torch.utils.data.DataLoader,\n",
        "    device: torch.device,\n",
        "    start_epoch: int,\n",
        "    end_epoch: int,\n",
        "    log_progress: bool = True):\n",
        "    \"\"\"Trains a network on provided data from `start_epoch` to `end_epoch` incl. (the training loop).\"\"\"\n",
        "\n",
        "    # Define loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    print(f\"Training from epoch(s) {start_epoch} to {end_epoch} w/ {len(trainloader)} batches each.\", flush=True)\n",
        "    results = []\n",
        "\n",
        "    # Train the network\n",
        "    for epoch in range(start_epoch, end_epoch+1):  # loop over the dataset multiple times, last epoch inclusive\n",
        "        total_loss, total_correct, n_samples = 0.0, 0.0, 0\n",
        "        pbar = tqdm(trainloader, desc=f'TRAIN Epoch {epoch}') if log_progress else trainloader\n",
        "        for data in pbar:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Collected training loss and accuracy statistics\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1) \n",
        "            n_samples += labels.size(0)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if log_progress:\n",
        "                pbar.set_postfix({\n",
        "                    \"train_loss\": total_loss/n_samples, \n",
        "                    \"train_acc\": total_correct/n_samples\n",
        "                })\n",
        "            \n",
        "        results.append((total_loss/n_samples, total_correct/n_samples))    \n",
        "        \n",
        "    return results      \n",
        "    \n",
        "def test(\n",
        "    net: Net,\n",
        "    testloader: torch.utils.data.DataLoader,\n",
        "    device: torch.device,\n",
        "    log_progress: bool = True):\n",
        "    \"\"\"Evaluates the network on test data.\"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    total_loss, total_correct, n_samples = 0.0, 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(testloader, desc=\"TEST\") if log_progress else testloader\n",
        "        for data in pbar:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = net(images)\n",
        "\n",
        "            # Collected testing loss and accuracy statistics\n",
        "            total_loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1) \n",
        "            n_samples += labels.size(0)\n",
        "            total_correct += (predicted == labels).sum().item() \n",
        "    \n",
        "    return (total_loss/n_samples, total_correct/n_samples)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8s3X7yznfMY",
        "outputId": "4c15f322-9cd2-470e-e364-785428831e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cifar.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile client.py\n",
        "import argparse\n",
        "import grpc\n",
        "import timeit\n",
        "import torch\n",
        "import torchvision\n",
        "import flwr as fl\n",
        "import random\n",
        "\n",
        "from collections import OrderedDict\n",
        "from typing import Optional\n",
        "from torch.utils.data import DataLoader\n",
        "from flwr.common import EvaluateIns, EvaluateRes, FitIns, FitRes, ParametersRes, Weights\n",
        "import time\n",
        "\n",
        "\n",
        "import cifar\n",
        "\n",
        "DEFAULT_SERVER_ADDRESS = \"localhost:8099\"\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "\n",
        "class CifarClient(fl.client.Client):\n",
        "    \"\"\"Flower client implementing CIFAR-10 image classification using PyTorch.\"\"\"\n",
        "    def __init__(\n",
        "        self, cid,\n",
        "        model: cifar.Net,\n",
        "        trainset: torchvision.datasets.CIFAR10,\n",
        "        testset: torchvision.datasets.CIFAR10,\n",
        "        exp_name: Optional[str],\n",
        "        iid_fraction: Optional[float]):\n",
        "        self.cid = cid\n",
        "        self.model = model\n",
        "        self.trainset = trainset\n",
        "        self.testset = testset\n",
        "        self.exp_name = exp_name or 'federated_unspecified'\n",
        "        print(f\"Client {self.cid} running experiment {self.exp_name}\")\n",
        "\n",
        "\n",
        "    def get_parameters(self) -> ParametersRes:\n",
        "        print(f\"Client {self.cid}: get_parameters\")\n",
        "\n",
        "        weights: Weights = self.model.get_weights()\n",
        "        parameters = fl.common.weights_to_parameters(weights)\n",
        "        return ParametersRes(parameters=parameters)\n",
        "\n",
        "    def fit(self, ins: FitIns) -> FitRes:\n",
        "        print(f\"Client {self.cid}: fit\")\n",
        "        config = ins.config\n",
        "        weights: Weights = fl.common.parameters_to_weights(ins.parameters)\n",
        "\n",
        "        # Get training config\n",
        "        epochs = int(config[\"epochs\"])\n",
        "        batch_size = int(config[\"batch_size\"])\n",
        "        epoch_global = int(config[\"epoch_global\"])\n",
        "\n",
        "        # Set model parameters\n",
        "        self.model.set_weights(weights)\n",
        "\n",
        "        # Train the model\n",
        "        trainloader = DataLoader(self.trainset, batch_size=batch_size, shuffle=True)\n",
        "        \n",
        "        start_epoch = epoch_global + 1\n",
        "        end_epoch = start_epoch + epochs - 1\n",
        "\n",
        "        fit_begin = timeit.default_timer()\n",
        "        training_log = cifar.train(net=self.model, trainloader=trainloader, device=DEVICE, \n",
        "                                   start_epoch=start_epoch, end_epoch=end_epoch, log_progress=False)\n",
        "        fit_duration = timeit.default_timer() - fit_begin\n",
        "\n",
        "        train_loss, train_acc = training_log[-1]\n",
        "        print(f'Client {self.cid}: train_loss={train_loss:.4f}, train_accuracy={train_acc:.4f}')\n",
        "\n",
        "        # Return the refined weights and the number of examples used for training\n",
        "        weights_prime: Weights = self.model.get_weights()\n",
        "        params_prime = fl.common.weights_to_parameters(weights_prime)\n",
        "        num_examples_train = len(self.trainset)\n",
        "        return FitRes(\n",
        "            parameters=params_prime,\n",
        "            num_examples=num_examples_train,\n",
        "            num_examples_ceil=num_examples_train,\n",
        "            fit_duration=fit_duration,\n",
        "        )\n",
        "\n",
        "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
        "        print(f\"Client {self.cid}: evaluate\")\n",
        "        config = ins.config\n",
        "        epoch_global = int(config[\"epoch_global\"])\n",
        "        \n",
        "        # Use provided weights to update the local model\n",
        "        weights = fl.common.parameters_to_weights(ins.parameters)\n",
        "        self.model.set_weights(weights)\n",
        "\n",
        "        # Evaluate the updated model on the local dataset\n",
        "        testloader = DataLoader(self.testset, batch_size=32, shuffle=False)\n",
        "        test_loss, test_acc = cifar.test(net=self.model, testloader=testloader, \n",
        "                                         device=DEVICE, log_progress=False)\n",
        "        print(f\"Client {self.cid}: test_loss={test_loss:.4f}, test_accuracy={test_acc:.4f}\")\n",
        "\n",
        "        # Return the number of evaluation examples and the evaluation result (loss)\n",
        "        return EvaluateRes(\n",
        "            num_examples=len(self.testset), loss=test_loss, accuracy=test_acc\n",
        "        )\n",
        "\n",
        "def start_client(client_id, num_partitions, iid_fraction=1.0, gtol=0.2, beta=0.25,alpha=0.5,classPerClient=-1,\n",
        "                 server_address=DEFAULT_SERVER_ADDRESS, log_host=None, exp_name=None):\n",
        "\n",
        "\n",
        "    # Configure logger\n",
        "    fl.common.logger.configure(f\"client_{client_id}\", host=log_host)\n",
        "\n",
        "    # Load model and data\n",
        "    print(f\"Loading data for client {client_id}\")\n",
        "\n",
        "    g_trainset, g_testset, l_trainset, l_testset, g_info, l_info = cifar.load_local_partitioned_data(\n",
        "        client_id=client_id, \n",
        "        num_partitions=num_partitions,\n",
        "        iid_fraction=iid_fraction,\n",
        "        global_fraction=gtol,\n",
        "        beta=beta,\n",
        "        alpha=alpha,\n",
        "        classPerClient=classPerClient)\n",
        "    \n",
        "    model = cifar.load_model()\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    if gtol!=0.0:\n",
        "      # Start global model training\n",
        "      print(f\"Start Global traning on Client {client_id}; Global training set size {g_info[0]}; Global training set distribution {str(g_info[1])}\")\n",
        "      globalloader = DataLoader(g_trainset, batch_size=32, shuffle=True)\n",
        "      cifar.train(model,globalloader,DEVICE,0,10,log_progress=False)\n",
        "\n",
        "      testloader = DataLoader(g_testset, batch_size=32, shuffle=True)\n",
        "      loss,acc = cifar.test(model,testloader,DEVICE,log_progress=False)\n",
        "      print(f\"Global traning accuracy: {acc} on Client {client_id}\")\n",
        "\n",
        "    # Start client\n",
        "    print(f\"Starting client {client_id}; Local training set size {l_info[0]}; Local training set distribution {str(l_info[1])}\")\n",
        "    client = CifarClient(client_id, model, l_trainset, l_testset, \n",
        "        f'{exp_name}_iid-fraction_{iid_fraction}', iid_fraction)\n",
        "\n",
        "    print(f\"Connecting to {server_address}\")\n",
        "\n",
        "    try:\n",
        "        # There's no graceful shutdown when gRPC server terminates, so we try/except\n",
        "        fl.client.start_client(server_address, client)\n",
        "    except grpc._channel._MultiThreadedRendezvous:\n",
        "        print(f\"Client {client_id}: shutdown\")\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Flower client\")\n",
        "    parser.add_argument(\"--server_address\", type=str, default=DEFAULT_SERVER_ADDRESS,\n",
        "        help=f\"gRPC server address (default: {DEFAULT_SERVER_ADDRESS})\")\n",
        "    parser.add_argument(\"--cid\", type=int, required=True, help=\"Client CID (no default)\")\n",
        "    parser.add_argument(\"--num_partitions\", type=int, required=True, \n",
        "        help=\"Total number of clients participating in training\")\n",
        "    parser.add_argument(\"--iid_fraction\", type=float, nargs=\"?\", const=1.0, \n",
        "        help=\"Fraction of data [0,1] that is independent and identically distributed.\")\n",
        "    parser.add_argument(\"--gtol\", type=float, required=True, \n",
        "        help=\"Total number of clients participating in training\")\n",
        "    parser.add_argument(\"--beta\", type=float, required=True, \n",
        "        help=\"Total number of clients participating in training\")\n",
        "    parser.add_argument(\"--alpha\", type=float, required=True, \n",
        "        help=\"Total number of clients participating in training\")\n",
        "    parser.add_argument(\"--log_host\", type=str, help=\"Log server address\")\n",
        "    parser.add_argument(\"--exp_name\", type=str, help=\"Friendly experiment name\")\n",
        "    parser.add_argument(\"--classPerClient\", type=int, help=\"Friendly experiment name\")\n",
        "\n",
        "    args, _ = parser.parse_known_args()\n",
        "    start_client(client_id=args.cid,\n",
        "                 num_partitions=args.num_partitions,\n",
        "                 iid_fraction=float(args.iid_fraction),\n",
        "                 log_host=args.log_host,\n",
        "                 server_address=args.server_address,\n",
        "                 exp_name=args.exp_name,\n",
        "                 gtol=float(args.gtol),\n",
        "                 beta=float(args.beta),\n",
        "                 alpha=float(args.alpha),\n",
        "                 classPerClient=int(args.classPerClient))\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_66rm1UmnjnL",
        "outputId": "92c5b6c3-0e6e-44c0-e900-1ba1f06fc75f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting client.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile server.py\n",
        "\n",
        "import argparse\n",
        "from typing import Callable, Dict, Optional, Tuple\n",
        "\n",
        "from logging import INFO\n",
        "from flwr.common.logger import log\n",
        "from flwr.server.grpc_server.grpc_server import start_insecure_grpc_server\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import flwr as fl\n",
        "import cifar\n",
        "import pickle\n",
        "\n",
        "DEFAULT_SERVER_ADDRESS = \"localhost:8099\"\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "def start_server(exp_name=None, \n",
        "                 server_address=DEFAULT_SERVER_ADDRESS, \n",
        "                 rounds=1,\n",
        "                 epochs=10,\n",
        "                 batch_size=32,\n",
        "                 sample_fraction=1.0,\n",
        "                 min_sample_size=2,\n",
        "                 min_num_clients=2,\n",
        "                 log_host=None):\n",
        "\n",
        "    if not exp_name:\n",
        "        exp_name = f\"federated_rounds_{rounds}_\" \\\n",
        "                   f\"epochs_{epochs}_\" \\\n",
        "                   f\"min_num_clients_{min_num_clients}_\" \\\n",
        "                   f\"min_sample_size_{min_sample_size}_\" \\\n",
        "                   f\"sample_fraction_{sample_fraction}\"\n",
        "\n",
        "    # Configure logger\n",
        "    fl.common.logger.configure(\"server\", host=log_host)\n",
        "\n",
        "    # Load evaluation data\n",
        "    _, testset = cifar.load_data()\n",
        "    \n",
        "    # Create client_manager, strategy, and server\n",
        "    client_manager = fl.server.SimpleClientManager()\n",
        "\n",
        "    strategy = fl.server.strategy.FedAvg(\n",
        "        fraction_fit=sample_fraction,\n",
        "        min_fit_clients=min_sample_size,\n",
        "        min_eval_clients=min_sample_size,\n",
        "        min_available_clients=min_num_clients,\n",
        "        eval_fn=get_eval_fn(testset),\n",
        "        on_fit_config_fn=generate_config(epochs, batch_size),\n",
        "        on_evaluate_config_fn=generate_config(epochs, batch_size)\n",
        "    )\n",
        "    server = fl.server.Server(client_manager=client_manager, strategy=strategy)\n",
        "\n",
        "    # Run server \n",
        "    print(f\"Starting gRPC server on {server_address}...\")\n",
        "    grpc_server = start_insecure_grpc_server(\n",
        "        client_manager=server.client_manager(),\n",
        "        server_address=server_address,\n",
        "        max_message_length=fl.common.GRPC_MAX_MESSAGE_LENGTH,\n",
        "    )\n",
        "    \n",
        "    # Fit model\n",
        "    print(\"Fitting the model...\")\n",
        "    hist = server.fit(num_rounds=rounds)\n",
        " \n",
        "    log(INFO, f\"app_fit: losses_centralized={hist.losses_centralized}\")\n",
        "    log(INFO, f\"app_fit: accuracies_centralized={hist.metrics_centralized['accuracy']}\")\n",
        "\n",
        "    # Evaluate the final accuracy on the server\n",
        "    test_loss, test_metrics = server.strategy.evaluate(parameters=server.parameters)\n",
        "    print(f\"Server-side test results after training: test_loss={test_loss:.4f}, \"\n",
        "          f\"test_accuracy={test_metrics['accuracy']:.4f}\")\n",
        "    with open(f'logs/{exp_name}.txt', 'wb') as fp:\n",
        "      pickle.dump([hist.losses_centralized, hist.metrics_centralized['accuracy']], fp)\n",
        "    # Now, apply temporary workaround to force distributed evaluation\n",
        "    server.strategy.eval_fn = None\n",
        "\n",
        "    # Stop the gRPC server\n",
        "    grpc_server.stop(None)    \n",
        "\n",
        "\n",
        "def generate_config(epochs, batch_size):\n",
        "    def fit_config(round: int) -> Dict[str, str]:\n",
        "        print(f\"Configuring round {round}...\")\n",
        "        return {\n",
        "            \"epoch_global\": str((round - 1) * epochs),\n",
        "            \"epochs\": str(epochs),\n",
        "            \"batch_size\": str(batch_size),\n",
        "        }\n",
        "    \n",
        "    return fit_config \n",
        "\n",
        "\n",
        "def get_eval_fn(testset: torchvision.datasets.CIFAR10):\n",
        "    \"\"\"Returns an evaluation function for centralized (server-side) evaluation.\"\"\"\n",
        "    def evaluate(weights: fl.common.Weights):\n",
        "        \"\"\"Use the entire CIFAR-10 test set for evaluation.\"\"\"\n",
        "        model = cifar.load_model()\n",
        "        model.set_weights(weights)\n",
        "        model.to(DEVICE)\n",
        "        testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
        "        loss, accuracy = cifar.test(net=model, testloader=testloader, device=DEVICE, log_progress=False)\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "    return evaluate\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Flower server\")\n",
        "    parser.add_argument(\"--server_address\", type=str, default=DEFAULT_SERVER_ADDRESS,\n",
        "        help=f\"gRPC server address (default: {DEFAULT_SERVER_ADDRESS})\")\n",
        "    parser.add_argument(\"--rounds\", type=int, default=1,\n",
        "        help=\"Number of rounds of federated learning (default: 1)\")\n",
        "    parser.add_argument(\"--sample_fraction\", type=float, default=1.0,\n",
        "        help=\"Fraction of available clients used for fit/evaluate (default: 1.0)\")\n",
        "    parser.add_argument(\"--min_sample_size\", type=int, default=2,\n",
        "        help=\"Minimum number of clients used for fit/evaluate (default: 2)\")\n",
        "    parser.add_argument(\"--min_num_clients\", type=int, default=2,\n",
        "        help=\"Minimum number of available clients needed for sampling (default: 2)\")\n",
        "    parser.add_argument(\"--log_host\", type=str, help=\"Log server address (no default)\")\n",
        "    parser.add_argument(\"--epochs\", type=int, default=10,\n",
        "        help=\"Number of epochs each client will train for (default: 10)\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32,\n",
        "        help=\"Number of samples per batch each client will use (default: 32)\")   \n",
        "    parser.add_argument(\"--exp_name\", type=str,\n",
        "        help=\"Name of the experiment you are running (no default)\")\n",
        "    args, _ = parser.parse_known_args()\n",
        "    \n",
        "    start_server(exp_name=args.exp_name,\n",
        "                 server_address=args.server_address,\n",
        "                 rounds=args.rounds,\n",
        "                 epochs=args.epochs,\n",
        "                 batch_size=args.batch_size,\n",
        "                 sample_fraction=args.sample_fraction,\n",
        "                 min_sample_size=args.min_sample_size,\n",
        "                 min_num_clients=args.min_num_clients,\n",
        "                 log_host=args.log_host)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw5PO4qQDc0u",
        "outputId": "0ba9cf02-84c0-446c-c1a3-2a6aaf901a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/Colab Notebooks/\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSH3GJA8INtD",
        "outputId": "192e7d0b-bc3c-4cfe-e265-09aba280f923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n",
            " cifar.py\n",
            " client.py\n",
            " clients.sh\n",
            "'Copy of 02-02-simulation (1).ipynb'\n",
            "'Copy of 02-02-simulation.ipynb'\n",
            "'Copy of 2021 L46 Practical 1: Keyword spotting model'\n",
            "'Copy of 2021 L46 Practical 2: GPU Training'\n",
            "'Copy of 2021 L46 Practical 3: Federated Learning'\n",
            "'Copy of Dataflow programming using TensorFlow Student  Copy.ipynb'\n",
            "'cyp25 2021 L46 Practical 1: Keyword spotting model'\n",
            " logs\n",
            " Non-iid_0.25.ipynb\n",
            " Non-iid_0.5.ipynb\n",
            " Non-iid_0.75.ipynb\n",
            " Non-iid_1_class.ipynb\n",
            " Non-iid_1.ipynb\n",
            " Non-iid_2_class.ipynb\n",
            " __pycache__\n",
            " server.py\n",
            " server.sh\n",
            " sunspot.ipynb\n",
            " Untitled\n",
            " Untitled0.ipynb\n",
            " Untitled1.ipynb\n",
            " Untitled2.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile server.sh\n",
        "export PYTHONUNBUFFERED=1\n",
        "\n",
        "#noniid, GlobalToLocalRatio, Beta, Alpha, classPerClient\n",
        "# exp='1.0;0.2;0.25;0.5;-1'\n",
        "# exp='0.75;0.2;0.25;0.5;-1'\n",
        "# exp='0.5;0.2;0.25;0.5;-1'\n",
        "# exp='0.25;0.2;0.25;0.5;-1'\n",
        "# exp='1.0;0.2;0.25;0.5;1'\n",
        "exp='1.0;0.2;0.25;0.5;2'\n",
        "\n",
        "server_address='localhost:24339'\n",
        "python3 server.py \\\n",
        "    --rounds=3 \\\n",
        "    --epochs=10 \\\n",
        "    --sample_fraction=1 \\\n",
        "    --min_sample_size=5 \\\n",
        "    --min_num_clients=5 \\\n",
        "    --server_address=$server_address\\\n",
        "    --exp_name=$exp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okyLEn5U8n00",
        "outputId": "77e71290-1c60-4d8e-86c2-03ea2d6b06d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting server.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile clients.sh\n",
        "export PYTHONUNBUFFERED=1\n",
        "NUM_CLIENTS=10\n",
        "\n",
        "#noniid, GlobalToLocalRatio, Beta, Alpha, classPerClient\n",
        "# exp='1.0;0.2;0.25;0.5;-1'\n",
        "# exp='0.75;0.2;0.25;0.5;-1'\n",
        "# exp='0.5;0.2;0.25;0.5;-1'\n",
        "# exp='0.25;0.2;0.25;0.5;-1'\n",
        "# exp='1.0;0.2;0.25;0.5;1'\n",
        "exp='1.0;0.2;0.25;0.5;2'\n",
        "\n",
        "server_address='localhost:24339'\n",
        "IFS=\";\" read -r -a arr <<< \"${exp}\"\n",
        "noniid=\"${arr[0]}\"\n",
        "gtol=\"${arr[1]}\"\n",
        "beta=\"${arr[2]}\"\n",
        "alpha=\"${arr[3]}\"\n",
        "classPerClient=\"${arr[4]}\"\n",
        "\n",
        "for ((i = 0; i < $NUM_CLIENTS; i++))\n",
        "do\n",
        "    echo \"Starting client(cid=$i) with partition $i out of $NUM_CLIENTS clients.\"\n",
        "    sleep 8s  \n",
        "    python3 client.py \\\n",
        "      --cid=$i \\\n",
        "      --num_partitions=${NUM_CLIENTS} \\\n",
        "      --iid_fraction=$noniid \\\n",
        "      --gtol=$gtol\\\n",
        "      --beta=$beta\\\n",
        "      --alpha=$alpha\\\n",
        "      --server_address=$server_address\\\n",
        "      --classPerClient=$classPerClient\\\n",
        "      --exp_name=\"federated_${NUM_CLIENTS}_clients\" &\n",
        "done\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz1vsplG9M7s",
        "outputId": "2244ce36-be6f-47b9-e675-61f237051249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting clients.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x clients.sh server.sh"
      ],
      "metadata": {
        "id": "XhhUR5jgFmfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%killbgscripts\n",
        "!((./server.sh & sleep 5s); ./clients.sh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9sbudoNDuNo",
        "outputId": "88ae66f7-0008-4ba3-f33a-638ae8a13573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All background processes were killed.\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=0) with partition 0 out of 10 clients.\n",
            "Files already downloaded and verified\n",
            "Starting gRPC server on localhost:24339...\n",
            "Fitting the model...\n",
            "INFO flower 2022-01-09 19:39:53,323 | server.py:118 | Initializing global parameters\n",
            "INFO flower 2022-01-09 19:39:53,323 | server.py:304 | Requesting initial parameters from one random client\n",
            "Starting client(cid=1) with partition 1 out of 10 clients.\n",
            "Loading data for client 0\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=2) with partition 2 out of 10 clients.\n",
            "Loading data for client 1\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=3) with partition 3 out of 10 clients.\n",
            "Loading data for client 2\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=4) with partition 4 out of 10 clients.\n",
            "Loading data for client 3\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=5) with partition 5 out of 10 clients.\n",
            "7942\n",
            "Start Global traning on Client 0; Global training set size 1000; Global training set distribution {0: 102, 1: 98, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100}\n",
            "Training from epoch(s) 0 to 10 w/ 32 batches each.\n",
            "Files already downloaded and verified\n",
            "Loading data for client 4\n",
            "Starting client(cid=6) with partition 6 out of 10 clients.\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=7) with partition 7 out of 10 clients.\n",
            "Global traning accuracy: 0.08 on Client 0\n",
            "Starting client 0; Local training set size 8442; Local training set distribution {0: 53, 1: 54, 2: 45, 3: 48, 4: 47, 5: 47, 6: 50, 7: 55, 8: 4009, 9: 4034}\n",
            "Client 0 running experiment federated_10_clients_iid-fraction_1.0\n",
            "Connecting to localhost:24339\n",
            "DEBUG flower 2022-01-09 19:40:48,649 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "INFO flower 2022-01-09 19:40:48,665 | app.py:61 | Opened (insecure) gRPC connection\n",
            "Client 0: get_parameters\n",
            "DEBUG flower 2022-01-09 19:40:48,670 | connection.py:36 | ChannelConnectivity.CONNECTING\n",
            "DEBUG flower 2022-01-09 19:40:48,671 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2022-01-09 19:40:48,671 | server.py:307 | Received initial parameters from one random client\n",
            "INFO flower 2022-01-09 19:40:48,671 | server.py:120 | Evaluating initial parameters\n",
            "Loading data for client 5\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=8) with partition 8 out of 10 clients.\n",
            "Files already downloaded and verified\n",
            "Loading data for client 6\n",
            "Files already downloaded and verified\n",
            "Starting client(cid=9) with partition 9 out of 10 clients.\n",
            "Files already downloaded and verified\n",
            "Loading data for client 7\n",
            "Files already downloaded and verified\n",
            "INFO flower 2022-01-09 19:41:16,501 | server.py:127 | initial parameters (loss, other metrics): 0.07209320573806763, {'accuracy': 0.1198}\n",
            "INFO flower 2022-01-09 19:41:16,510 | server.py:133 | FL starting\n",
            "Configuring round 1...\n",
            "Loading data for client 8\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Loading data for client 9\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "8045\n",
            "Start Global traning on Client 1; Global training set size 1000; Global training set distribution {0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100}\n",
            "Training from epoch(s) 0 to 10 w/ 32 batches each.\n",
            "Files already downloaded and verified\n",
            "Global traning accuracy: 0.14 on Client 1\n",
            "Starting client 1; Local training set size 8545; Local training set distribution {0: 4081, 1: 43, 2: 45, 3: 49, 4: 47, 5: 54, 6: 4063, 7: 54, 8: 55, 9: 54}\n",
            "Client 1 running experiment federated_10_clients_iid-fraction_1.0\n",
            "Connecting to localhost:24339\n",
            "DEBUG flower 2022-01-09 19:41:53,170 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:41:53,176 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2022-01-09 19:41:53,179 | app.py:61 | Opened (insecure) gRPC connection\n",
            "8018\n",
            "Start Global traning on Client 2; Global training set size 1000; Global training set distribution {0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100}\n",
            "Training from epoch(s) 0 to 10 w/ 32 batches each.\n",
            "Global traning accuracy: 0.095 on Client 2\n",
            "Starting client 2; Local training set size 8518; Local training set distribution {0: 47, 1: 46, 2: 49, 3: 4052, 4: 48, 5: 54, 6: 48, 7: 49, 8: 51, 9: 4074}\n",
            "Client 2 running experiment federated_10_clients_iid-fraction_1.0\n",
            "Connecting to localhost:24339\n",
            "DEBUG flower 2022-01-09 19:42:36,597 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:42:36,600 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2022-01-09 19:42:36,607 | app.py:61 | Opened (insecure) gRPC connection\n",
            "8006\n",
            "Start Global traning on Client 3; Global training set size 1000; Global training set distribution {0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100}\n",
            "Training from epoch(s) 0 to 10 w/ 32 batches each.\n",
            "7997\n",
            "Start Global traning on Client 4; Global training set size 1000; Global training set distribution {0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100}\n",
            "Training from epoch(s) 0 to 10 w/ 32 batches each.\n",
            "Global traning accuracy: 0.1 on Client 3\n",
            "Starting client 3; Local training set size 8506; Local training set distribution {0: 4057, 1: 4048, 2: 54, 3: 43, 4: 57, 5: 47, 6: 53, 7: 50, 8: 49, 9: 48}\n",
            "Client 3 running experiment federated_10_clients_iid-fraction_1.0\n",
            "Connecting to localhost:24339\n",
            "DEBUG flower 2022-01-09 19:42:54,903 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "INFO flower 2022-01-09 19:42:54,915 | app.py:61 | Opened (insecure) gRPC connection\n",
            "DEBUG flower 2022-01-09 19:42:54,915 | connection.py:36 | ChannelConnectivity.READY\n",
            "8035\n",
            "Start Global traning on Client 5; Global training set size 1000; Global training set distribution {0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100}\n",
            "Training from epoch(s) 0 to 10 w/ 32 batches each.\n",
            "Global traning accuracy: 0.1 on Client 4\n",
            "Starting client 4; Local training set size 8497; Local training set distribution {0: 58, 1: 4041, 2: 48, 3: 51, 4: 50, 5: 50, 6: 4059, 7: 48, 8: 53, 9: 39}\n",
            "Client 4 running experiment federated_10_clients_iid-fraction_1.0\n",
            "Connecting to localhost:24339\n",
            "DEBUG flower 2022-01-09 19:43:07,840 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:43:07,844 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2022-01-09 19:43:07,850 | app.py:61 | Opened (insecure) gRPC connection\n",
            "DEBUG flower 2022-01-09 19:43:07,857 | server.py:255 | fit_round: strategy sampled 5 clients (out of 5)\n",
            "Client 0: fit\n",
            "Client 3: fit\n",
            "Training from epoch(s) 1 to 10 w/ 264 batches each.Training from epoch(s) 1 to 10 w/ 266 batches each.\n",
            "\n",
            "Client 1: fit\n",
            "Training from epoch(s) 1 to 10 w/ 268 batches each.\n",
            "Client 4: fit\n",
            "Training from epoch(s) 1 to 10 w/ 266 batches each.Client 2: fit\n",
            "\n",
            "Training from epoch(s) 1 to 10 w/ 267 batches each.\n",
            "8068\n",
            "Start Global traning on Client 6; Global training set size 1000; Global training set distribution {0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100}\n",
            "Training from epoch(s) 0 to 10 w/ 32 batches each.\n",
            "7983\n",
            "Start Global traning on Client 7; Global training set size 1000; Global training set distribution {0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100}\n",
            "Training from epoch(s) 0 to 10 w/ 32 batches each.\n",
            "Global traning accuracy: 0.1 on Client 5\n",
            "Starting client 5; Local training set size 8535; Local training set distribution {0: 51, 1: 46, 2: 4058, 3: 49, 4: 4087, 5: 54, 6: 50, 7: 46, 8: 44, 9: 50}\n",
            "Client 5 running experiment federated_10_clients_iid-fraction_1.0\n",
            "Connecting to localhost:24339\n",
            "DEBUG flower 2022-01-09 19:43:24,688 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:43:24,690 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2022-01-09 19:43:24,695 | app.py:61 | Opened (insecure) gRPC connection\n",
            "7953\n",
            "Start Global traning on Client 8; Global training set size 1000; Global training set distribution {0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100}\n",
            "Training from epoch(s) 0 to 10 w/ 32 batches each.\n",
            "Global traning accuracy: 0.105 on Client 6\n",
            "Starting client 6; Local training set size 8568; Local training set distribution {0: 62, 1: 4049, 2: 56, 3: 39, 4: 39, 5: 4126, 6: 49, 7: 48, 8: 48, 9: 52}\n",
            "Client 6 running experiment federated_10_clients_iid-fraction_1.0\n",
            "Connecting to localhost:24339\n",
            "DEBUG flower 2022-01-09 19:43:35,459 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:43:35,464 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2022-01-09 19:43:35,468 | app.py:61 | Opened (insecure) gRPC connection\n",
            "8063\n",
            "Start Global traning on Client 9; Global training set size 1000; Global training set distribution {0: 100, 1: 100, 2: 95, 3: 48, 4: 57, 5: 115, 6: 87, 7: 103, 8: 152, 9: 143}\n",
            "Training from epoch(s) 0 to 10 w/ 32 batches each.\n",
            "Global traning accuracy: 0.095 on Client 7\n",
            "Starting client 7; Local training set size 8483; Local training set distribution {0: 57, 1: 44, 2: 57, 3: 48, 4: 49, 5: 4052, 6: 4031, 7: 43, 8: 45, 9: 57}\n",
            "Client 7 running experiment federated_10_clients_iid-fraction_1.0\n",
            "Connecting to localhost:24339\n",
            "DEBUG flower 2022-01-09 19:43:46,880 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:43:46,884 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2022-01-09 19:43:46,885 | app.py:61 | Opened (insecure) gRPC connection\n",
            "Global traning accuracy: 0.065 on Client 8\n",
            "Starting client 8; Local training set size 8453; Local training set distribution {0: 53, 1: 53, 2: 50, 3: 4014, 4: 4041, 5: 49, 6: 45, 7: 58, 8: 47, 9: 43}\n",
            "Client 8 running experiment federated_10_clients_iid-fraction_1.0\n",
            "Connecting to localhost:24339\n",
            "DEBUG flower 2022-01-09 19:43:51,648 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:43:51,651 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2022-01-09 19:43:51,654 | app.py:61 | Opened (insecure) gRPC connection\n",
            "Global traning accuracy: 0.16 on Client 9\n",
            "Starting client 9; Local training set size 8563; Local training set distribution {0: 44, 1: 53, 2: 4059, 3: 28, 4: 4079, 5: 57, 6: 45, 7: 46, 8: 81, 9: 71}\n",
            "Client 9 running experiment federated_10_clients_iid-fraction_1.0\n",
            "Connecting to localhost:24339\n",
            "DEBUG flower 2022-01-09 19:43:58,550 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:43:58,551 | connection.py:36 | ChannelConnectivity.READY\n",
            "INFO flower 2022-01-09 19:43:58,559 | app.py:61 | Opened (insecure) gRPC connection\n",
            "Client 0: train_loss=0.0176, train_accuracy=0.8281\n",
            "Client 3: train_loss=0.0186, train_accuracy=0.8134\n",
            "Client 2: train_loss=0.0155, train_accuracy=0.8709\n",
            "Client 4: train_loss=0.0134, train_accuracy=0.8971\n",
            "Client 1: train_loss=0.0146, train_accuracy=0.8860\n",
            "DEBUG flower 2022-01-09 19:44:59,438 | server.py:264 | fit_round received 5 results and 0 failures\n",
            "INFO flower 2022-01-09 19:45:03,161 | server.py:154 | fit progress: (1, 0.0727839334487915, {'accuracy': 0.2007}, 226.64675344700026)\n",
            "INFO flower 2022-01-09 19:45:03,161 | server.py:199 | evaluate_round: no clients selected, cancel\n",
            "Configuring round 2...\n",
            "DEBUG flower 2022-01-09 19:45:03,162 | server.py:255 | fit_round: strategy sampled 10 clients (out of 10)\n",
            "Client 4: fit\n",
            "Client 1: fit\n",
            "Training from epoch(s) 11 to 20 w/ 266 batches each.\n",
            "Training from epoch(s) 11 to 20 w/ 268 batches each.\n",
            "Client 6: fit\n",
            "Client 3: fit\n",
            "Training from epoch(s) 11 to 20 w/ 266 batches each.\n",
            "Training from epoch(s) 11 to 20 w/ 268 batches each.\n",
            "Client 2: fit\n",
            "Training from epoch(s) 11 to 20 w/ 267 batches each.\n",
            "Client 5: fit\n",
            "Training from epoch(s) 11 to 20 w/ 267 batches each.\n",
            "Client 8: fit\n",
            "Training from epoch(s) 11 to 20 w/ 265 batches each.\n",
            "Client 0: fit\n",
            "Client 7: fit\n",
            "Training from epoch(s) 11 to 20 w/ 264 batches each.\n",
            "Training from epoch(s) 11 to 20 w/ 266 batches each.\n",
            "Client 9: fit\n",
            "Training from epoch(s) 11 to 20 w/ 268 batches each.\n",
            "Client 3: train_loss=0.0154, train_accuracy=0.8590\n",
            "Client 0: train_loss=0.0152, train_accuracy=0.8589\n",
            "Client 4: train_loss=0.0122, train_accuracy=0.9074\n",
            "Client 8: train_loss=0.0217, train_accuracy=0.7642\n",
            "Client 7: train_loss=0.0174, train_accuracy=0.8271\n",
            "Client 1: train_loss=0.0137, train_accuracy=0.8927\n",
            "Client 2: train_loss=0.0141, train_accuracy=0.8893\n",
            "Client 6: train_loss=0.0121, train_accuracy=0.9116\n",
            "Client 5: train_loss=0.0264, train_accuracy=0.6402\n",
            "Client 9: train_loss=0.0265, train_accuracy=0.6348\n",
            "DEBUG flower 2022-01-09 19:48:12,858 | server.py:264 | fit_round received 10 results and 0 failures\n",
            "INFO flower 2022-01-09 19:48:16,583 | server.py:154 | fit progress: (2, 0.06779030066728592, {'accuracy': 0.241}, 420.06882359600013)\n",
            "INFO flower 2022-01-09 19:48:16,583 | server.py:199 | evaluate_round: no clients selected, cancel\n",
            "Configuring round 3...\n",
            "DEBUG flower 2022-01-09 19:48:16,584 | server.py:255 | fit_round: strategy sampled 10 clients (out of 10)\n",
            "Client 4: fit\n",
            "Client 2: fit\n",
            "Training from epoch(s) 21 to 30 w/ 266 batches each.\n",
            "Training from epoch(s) 21 to 30 w/ 267 batches each.\n",
            "Client 3: fit\n",
            "Training from epoch(s) 21 to 30 w/ 266 batches each.\n",
            "Client 5: fit\n",
            "Client 8: fit\n",
            "Training from epoch(s) 21 to 30 w/ 265 batches each.Training from epoch(s) 21 to 30 w/ 267 batches each.\n",
            "\n",
            "Client 7: fit\n",
            "Training from epoch(s) 21 to 30 w/ 266 batches each.\n",
            "Client 9: fit\n",
            "Client 0: fit\n",
            "Training from epoch(s) 21 to 30 w/ 268 batches each.\n",
            "Client 6: fit\n",
            "Training from epoch(s) 21 to 30 w/ 264 batches each.\n",
            "Client 1: fit\n",
            "Training from epoch(s) 21 to 30 w/ 268 batches each.\n",
            "Training from epoch(s) 21 to 30 w/ 268 batches each.\n",
            "Client 8: train_loss=0.0202, train_accuracy=0.7842\n",
            "Client 3: train_loss=0.0145, train_accuracy=0.8688\n",
            "Client 7: train_loss=0.0161, train_accuracy=0.8412\n",
            "Client 4: train_loss=0.0115, train_accuracy=0.9150\n",
            "Client 2: train_loss=0.0137, train_accuracy=0.8916\n",
            "Client 0: train_loss=0.0145, train_accuracy=0.8683\n",
            "Client 6: train_loss=0.0119, train_accuracy=0.9120\n",
            "Client 9: train_loss=0.0238, train_accuracy=0.7037\n",
            "Client 5: train_loss=0.0240, train_accuracy=0.7015\n",
            "Client 1: train_loss=0.0131, train_accuracy=0.8985\n",
            "DEBUG flower 2022-01-09 19:51:24,777 | server.py:264 | fit_round received 10 results and 0 failures\n",
            "INFO flower 2022-01-09 19:51:28,612 | server.py:154 | fit progress: (3, 0.06450067571401596, {'accuracy': 0.2691}, 612.0973556090003)\n",
            "INFO flower 2022-01-09 19:51:28,612 | server.py:199 | evaluate_round: no clients selected, cancel\n",
            "INFO flower 2022-01-09 19:51:28,612 | server.py:172 | FL finished in 612.0977074080001\n",
            "INFO flower 2022-01-09 19:51:28,613 | server.py:71 | app_fit: losses_centralized=[(0, 0.07209320573806763), (1, 0.0727839334487915), (2, 0.06779030066728592), (3, 0.06450067571401596)]\n",
            "INFO flower 2022-01-09 19:51:28,613 | server.py:72 | app_fit: accuracies_centralized=[(0, 0.1198), (1, 0.2007), (2, 0.241), (3, 0.2691)]\n",
            "Server-side test results after training: test_loss=0.0645, test_accuracy=0.2691\n",
            "DEBUG flower 2022-01-09 19:51:32,620 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:51:32,625 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:51:32,625 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:51:32,622 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:51:32,630 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:51:32,621 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:51:32,624 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:51:32,629 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:51:32,626 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:51:32,632 | connection.py:36 | ChannelConnectivity.IDLE\n",
            "DEBUG flower 2022-01-09 19:51:32,824 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 1: shutdown\n",
            "DEBUG flower 2022-01-09 19:51:32,827 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 0: shutdown\n",
            "DEBUG flower 2022-01-09 19:51:32,834 | connection.py:68 | Insecure gRPC channel closed\n",
            "DEBUG flower 2022-01-09 19:51:32,835 | connection.py:68 | Insecure gRPC channel closed\n",
            "DEBUG flower 2022-01-09 19:51:32,836 | connection.py:68 | Insecure gRPC channel closed\n",
            "DEBUG flower 2022-01-09 19:51:32,836 | connection.py:68 | Insecure gRPC channel closed\n",
            "DEBUG flower 2022-01-09 19:51:32,837 | connection.py:68 | Insecure gRPC channel closed\n",
            "DEBUG flower 2022-01-09 19:51:32,837 | connection.py:68 | Insecure gRPC channel closed\n",
            "DEBUG flower 2022-01-09 19:51:32,838 | connection.py:68 | Insecure gRPC channel closed\n",
            "DEBUG flower 2022-01-09 19:51:32,838 | connection.py:68 | Insecure gRPC channel closed\n",
            "Client 2: shutdownClient 4: shutdownClient 3: shutdownClient 8: shutdownClient 7: shutdownClient 5: shutdownClient 6: shutdownClient 9: shutdown\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment\n",
        "#Global Local Ratio 0.2, Beta=0.25 Alpha=0.5 (Experiment IID)\n",
        "  # noniid-1.0-gtolratio-0.2-beta-0.25-alpha-0.5\n",
        "  #iid=1.0, 0.75, 0.5, 0.25, 1class, 2class\n",
        "#Global Local Ratio 0.2, iid=2class Alpha=0.5 (Experiment Beta)\n",
        "  #Beta=0.25, 0.2, 0.15, 0.1 \n",
        "#Global Local Ratio 0.2, iid=2class Beta=0.25 (Experiemnt Alpha)\n",
        "  #Alpha=1,0.8,0.5,0.2,0.1\n",
        "#iid=2class Beta=0.25 Alpha=0.5\n",
        "  #exp='1.0;0.3;0.25;0.5;2'\n",
        "  #global=0.3,0.2,0.1,0.05"
      ],
      "metadata": {
        "id": "EVtgeZFvHn9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iid_fraction 1.0\n",
        "losses_centralized_iid_1 =[(0, 0.07220932688713073), (1, 0.06973186511993408), (2, 0.058325643408298496), (3, 0.051442525255680084)]\n",
        "accuracies_centralized_iid_1 =[(0, 0.1), (1, 0.2159), (2, 0.3299), (3, 0.408)]\n",
        "\n",
        "# iid_fraction 0.75\n",
        "losses_centralized_iid_75=[(0, 0.07207719354629516), (1, 0.06536008388996124), (2, 0.055578639769554135), (3, 0.05072008833885193)]\n",
        "accuracies_centralized_iid_75 =[(0, 0.0999), (1, 0.2173), (2, 0.3585), (3, 0.4225)]\n",
        "\n",
        "# iid_fraction 0.5\n",
        "losses_centralized_iid_5 =[(0, 0.07239096665382386), (1, 0.0669349681377411), (2, 0.054201741981506346), (3, 0.04927621845006943)]\n",
        "accuracies_centralized_iid_5 =[(0, 0.1), (1, 0.2248), (2, 0.3752), (3, 0.4347)]\n",
        "\n",
        "# iid_fraction 0.25\n",
        "losses_centralized_iid_25 =[(0, 0.07210694007873535), (1, 0.06778777270317078), (2, 0.05507556644678116), (3, 0.05044988602399826)]\n",
        "accuracies_centralized_iid_25 =[(0, 0.0996), (1, 0.2251), (2, 0.36), (3, 0.4165)]\n",
        "\n",
        "# iid 1 class\n",
        "losses_centralized_iid_1_class =[(0, 0.07219128305912018), (1, 0.07358644070625305), (2, 0.07208134472370148), (3, 0.07188054387569427)]\n",
        "accuracies_centralized_iid_1_class =[(0, 0.1), (1, 0.1038), (2, 0.1065), (3, 0.1128)]\n",
        "\n",
        "# iid 2 class\n",
        "losses_centralized_iid_2_class=[(0, 0.07226183662414551), (1, 0.07617147347927093), (2, 0.06890336064100265), (3, 0.06537702754735947)]\n",
        "accuracies_centralized_iid_2_class=[(0, 0.0993), (1, 0.141), (2, 0.1783), (3, 0.2118)]"
      ],
      "metadata": {
        "id": "FmAQi52wIOcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def turn_to_list(ls):\n",
        "  return [t[1] for t in ls]\n",
        "\n",
        "rounds = list(range(4))\n",
        "\n",
        "plt.scatter(rounds,turn_to_list(accuracies_centralized_iid_1))\n",
        "plt.scatter(rounds,turn_to_list(accuracies_centralized_iid_75))\n",
        "plt.scatter(rounds,turn_to_list(accuracies_centralized_iid_5))\n",
        "plt.scatter(rounds,turn_to_list(accuracies_centralized_iid_25))\n",
        "plt.scatter(rounds,turn_to_list(accuracies_centralized_iid_1_class))\n",
        "plt.scatter(rounds,turn_to_list(accuracies_centralized_iid_2_class))\n",
        "\n",
        "plt.plot(rounds, turn_to_list(accuracies_centralized_iid_1), label=\"iid=1.0\")\n",
        "plt.plot(rounds, turn_to_list(accuracies_centralized_iid_75), label=\"iid=0.75\")\n",
        "plt.plot(rounds, turn_to_list(accuracies_centralized_iid_5), label=\"iid=0.5\")\n",
        "plt.plot(rounds, turn_to_list(accuracies_centralized_iid_25), label=\"iid=0.25\")\n",
        "plt.plot(rounds, turn_to_list(accuracies_centralized_iid_1_class), label=\"iid=1 class\")\n",
        "plt.plot(rounds, turn_to_list(accuracies_centralized_iid_2_class), label=\"iid=2 class\")\n",
        "plt.xlabel(\"round\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "cB9V30i6QzPY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "0a216f81-9ed7-4b13-b86b-a7a7df47ea86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "with open(f'logs/1.0;0.2;0.25;0.5;1.txt', 'rb') as fp:\n",
        "  results = np.asarray(pickle.load(fp))\n",
        "  print(results)"
      ],
      "metadata": {
        "id": "SVi65vVNgt20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3f0325-1747-4348-8d8c-d20866639292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.         0.07220737]\n",
            "  [1.         0.07326955]\n",
            "  [2.         0.07196945]\n",
            "  [3.         0.07166226]]\n",
            "\n",
            " [[0.         0.1       ]\n",
            "  [1.         0.1       ]\n",
            "  [2.         0.0988    ]\n",
            "  [3.         0.1308    ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YKX2fdCqJflt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}